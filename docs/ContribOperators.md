## Contrib Operator Schemas
*This file is automatically generated from the registered contrib operator schemas by [this script](https://github.com/microsoft/onnxruntime/blob/main/tools/python/gen_contrib_doc.py).
Do not modify directly.*

* com.microsoft
  * <a href="#com.microsoft.Attention">com.microsoft.Attention</a>
  * <a href="#com.microsoft.AttnLSTM">com.microsoft.AttnLSTM</a>
  * <a href="#com.microsoft.BeamSearch">com.microsoft.BeamSearch</a>
  * <a href="#com.microsoft.BiasAdd">com.microsoft.BiasAdd</a>
  * <a href="#com.microsoft.BiasDropout">com.microsoft.BiasDropout</a>
  * <a href="#com.microsoft.BiasGelu">com.microsoft.BiasGelu</a>
  * <a href="#com.microsoft.BiasSoftmax">com.microsoft.BiasSoftmax</a>
  * <a href="#com.microsoft.BiasSplitGelu">com.microsoft.BiasSplitGelu</a>
  * <a href="#com.microsoft.BifurcationDetector">com.microsoft.BifurcationDetector</a>
  * <a href="#com.microsoft.BitmaskBiasDropout">com.microsoft.BitmaskBiasDropout</a>
  * <a href="#com.microsoft.BitmaskDropout">com.microsoft.BitmaskDropout</a>
  * <a href="#com.microsoft.CDist">com.microsoft.CDist</a>
  * <a href="#com.microsoft.ComplexMul">com.microsoft.ComplexMul</a>
  * <a href="#com.microsoft.ComplexMulConj">com.microsoft.ComplexMulConj</a>
  * <a href="#com.microsoft.ConvTransposeWithDynamicPads">com.microsoft.ConvTransposeWithDynamicPads</a>
  * <a href="#com.microsoft.CropAndResize">com.microsoft.CropAndResize</a>
  * <a href="#com.microsoft.DecoderAttention">com.microsoft.DecoderAttention</a>
  * <a href="#com.microsoft.DecoderMaskedMultiHeadAttention">com.microsoft.DecoderMaskedMultiHeadAttention</a>
  * <a href="#com.microsoft.DecoderMaskedSelfAttention">com.microsoft.DecoderMaskedSelfAttention</a>
  * <a href="#com.microsoft.DequantizeBFP">com.microsoft.DequantizeBFP</a>
  * <a href="#com.microsoft.DequantizeLinear">com.microsoft.DequantizeLinear</a>
  * <a href="#com.microsoft.DequantizeWithOrder">com.microsoft.DequantizeWithOrder</a>
  * <a href="#com.microsoft.DynamicQuantizeLSTM">com.microsoft.DynamicQuantizeLSTM</a>
  * <a href="#com.microsoft.DynamicQuantizeMatMul">com.microsoft.DynamicQuantizeMatMul</a>
  * <a href="#com.microsoft.DynamicTimeWarping">com.microsoft.DynamicTimeWarping</a>
  * <a href="#com.microsoft.EPContext">com.microsoft.EPContext</a>
  * <a href="#com.microsoft.EmbedLayerNormalization">com.microsoft.EmbedLayerNormalization</a>
  * <a href="#com.microsoft.ExpandDims">com.microsoft.ExpandDims</a>
  * <a href="#com.microsoft.FastGelu">com.microsoft.FastGelu</a>
  * <a href="#com.microsoft.FusedConv">com.microsoft.FusedConv</a>
  * <a href="#com.microsoft.FusedGemm">com.microsoft.FusedGemm</a>
  * <a href="#com.microsoft.FusedMatMul">com.microsoft.FusedMatMul</a>
  * <a href="#com.microsoft.FusedMatMulActivation">com.microsoft.FusedMatMulActivation</a>
  * <a href="#com.microsoft.GatedRelativePositionBias">com.microsoft.GatedRelativePositionBias</a>
  * <a href="#com.microsoft.GatherBlockQuantized">com.microsoft.GatherBlockQuantized</a>
  * <a href="#com.microsoft.GatherND">com.microsoft.GatherND</a>
  * <a href="#com.microsoft.Gelu">com.microsoft.Gelu</a>
  * <a href="#com.microsoft.GemmFastGelu">com.microsoft.GemmFastGelu</a>
  * <a href="#com.microsoft.GemmFloat8">com.microsoft.GemmFloat8</a>
  * <a href="#com.microsoft.GemmaRotaryEmbedding">com.microsoft.GemmaRotaryEmbedding</a>
  * <a href="#com.microsoft.GreedySearch">com.microsoft.GreedySearch</a>
  * <a href="#com.microsoft.GridSample">com.microsoft.GridSample</a>
  * <a href="#com.microsoft.GroupNorm">com.microsoft.GroupNorm</a>
  * <a href="#com.microsoft.GroupQueryAttention">com.microsoft.GroupQueryAttention</a>
  * <a href="#com.microsoft.Inverse">com.microsoft.Inverse</a>
  * <a href="#com.microsoft.Irfft">com.microsoft.Irfft</a>
  * <a href="#com.microsoft.LongformerAttention">com.microsoft.LongformerAttention</a>
  * <a href="#com.microsoft.MatMulBnb4">com.microsoft.MatMulBnb4</a>
  * <a href="#com.microsoft.MatMulFpQ4">com.microsoft.MatMulFpQ4</a>
  * <a href="#com.microsoft.MatMulInteger16">com.microsoft.MatMulInteger16</a>
  * <a href="#com.microsoft.MatMulIntegerToFloat">com.microsoft.MatMulIntegerToFloat</a>
  * <a href="#com.microsoft.MatMulNBits">com.microsoft.MatMulNBits</a>
  * <a href="#com.microsoft.MaxpoolWithMask">com.microsoft.MaxpoolWithMask</a>
  * <a href="#com.microsoft.MoE">com.microsoft.MoE</a>
  * <a href="#com.microsoft.MulInteger">com.microsoft.MulInteger</a>
  * <a href="#com.microsoft.MultiHeadAttention">com.microsoft.MultiHeadAttention</a>
  * <a href="#com.microsoft.MurmurHash3">com.microsoft.MurmurHash3</a>
  * <a href="#com.microsoft.NGramRepeatBlock">com.microsoft.NGramRepeatBlock</a>
  * <a href="#com.microsoft.NhwcConv">com.microsoft.NhwcConv</a>
  * <a href="#com.microsoft.NhwcFusedConv">com.microsoft.NhwcFusedConv</a>
  * <a href="#com.microsoft.NhwcMaxPool">com.microsoft.NhwcMaxPool</a>
  * <a href="#com.microsoft.PackedAttention">com.microsoft.PackedAttention</a>
  * <a href="#com.microsoft.PackedMultiHeadAttention">com.microsoft.PackedMultiHeadAttention</a>
  * <a href="#com.microsoft.Pad">com.microsoft.Pad</a>
  * <a href="#com.microsoft.QAttention">com.microsoft.QAttention</a>
  * <a href="#com.microsoft.QGemm">com.microsoft.QGemm</a>
  * <a href="#com.microsoft.QLinearAdd">com.microsoft.QLinearAdd</a>
  * <a href="#com.microsoft.QLinearAveragePool">com.microsoft.QLinearAveragePool</a>
  * <a href="#com.microsoft.QLinearConcat">com.microsoft.QLinearConcat</a>
  * <a href="#com.microsoft.QLinearConv">com.microsoft.QLinearConv</a>
  * <a href="#com.microsoft.QLinearGlobalAveragePool">com.microsoft.QLinearGlobalAveragePool</a>
  * <a href="#com.microsoft.QLinearLeakyRelu">com.microsoft.QLinearLeakyRelu</a>
  * <a href="#com.microsoft.QLinearMul">com.microsoft.QLinearMul</a>
  * <a href="#com.microsoft.QLinearReduceMean">com.microsoft.QLinearReduceMean</a>
  * <a href="#com.microsoft.QLinearSigmoid">com.microsoft.QLinearSigmoid</a>
  * <a href="#com.microsoft.QLinearSoftmax">com.microsoft.QLinearSoftmax</a>
  * <a href="#com.microsoft.QLinearWhere">com.microsoft.QLinearWhere</a>
  * <a href="#com.microsoft.QMoE">com.microsoft.QMoE</a>
  * <a href="#com.microsoft.QOrderedAttention">com.microsoft.QOrderedAttention</a>
  * <a href="#com.microsoft.QOrderedGelu">com.microsoft.QOrderedGelu</a>
  * <a href="#com.microsoft.QOrderedLayerNormalization">com.microsoft.QOrderedLayerNormalization</a>
  * <a href="#com.microsoft.QOrderedLongformerAttention">com.microsoft.QOrderedLongformerAttention</a>
  * <a href="#com.microsoft.QOrderedMatMul">com.microsoft.QOrderedMatMul</a>
  * <a href="#com.microsoft.QuantizeBFP">com.microsoft.QuantizeBFP</a>
  * <a href="#com.microsoft.QuantizeLinear">com.microsoft.QuantizeLinear</a>
  * <a href="#com.microsoft.QuantizeWithOrder">com.microsoft.QuantizeWithOrder</a>
  * <a href="#com.microsoft.QuickGelu">com.microsoft.QuickGelu</a>
  * <a href="#com.microsoft.Range">com.microsoft.Range</a>
  * <a href="#com.microsoft.ReduceSumInteger">com.microsoft.ReduceSumInteger</a>
  * <a href="#com.microsoft.RelativePositionBias">com.microsoft.RelativePositionBias</a>
  * <a href="#com.microsoft.RemovePadding">com.microsoft.RemovePadding</a>
  * <a href="#com.microsoft.RestorePadding">com.microsoft.RestorePadding</a>
  * <a href="#com.microsoft.Rfft">com.microsoft.Rfft</a>
  * <a href="#com.microsoft.RotaryEmbedding">com.microsoft.RotaryEmbedding</a>
  * <a href="#com.microsoft.SampleOp">com.microsoft.SampleOp</a>
  * <a href="#com.microsoft.Sampling">com.microsoft.Sampling</a>
  * <a href="#com.microsoft.SkipGroupNorm">com.microsoft.SkipGroupNorm</a>
  * <a href="#com.microsoft.SkipLayerNormalization">com.microsoft.SkipLayerNormalization</a>
  * <a href="#com.microsoft.SkipSimplifiedLayerNormalization">com.microsoft.SkipSimplifiedLayerNormalization</a>
  * <a href="#com.microsoft.Snpe">com.microsoft.Snpe</a>
  * <a href="#com.microsoft.SparseAttention">com.microsoft.SparseAttention</a>
  * <a href="#com.microsoft.SparseToDenseMatMul">com.microsoft.SparseToDenseMatMul</a>
  * <a href="#com.microsoft.Tokenizer">com.microsoft.Tokenizer</a>
  * <a href="#com.microsoft.TorchEmbedding">com.microsoft.TorchEmbedding</a>
  * <a href="#com.microsoft.TransposeMatMul">com.microsoft.TransposeMatMul</a>
  * <a href="#com.microsoft.Trilu">com.microsoft.Trilu</a>
  * <a href="#com.microsoft.UnfoldTensor">com.microsoft.UnfoldTensor</a>
  * <a href="#com.microsoft.Unique">com.microsoft.Unique</a>
  * <a href="#com.microsoft.WhisperBeamSearch">com.microsoft.WhisperBeamSearch</a>
  * <a href="#com.microsoft.WordConvEmbedding">com.microsoft.WordConvEmbedding</a>
  * <sub>experimental</sub> <a href="#com.microsoft.IsAllFinite">com.microsoft.IsAllFinite</a>
  * <sub>experimental</sub> <a href="#com.microsoft.QEmbedLayerNormalization">com.microsoft.QEmbedLayerNormalization</a>
* com.microsoft.nchwc
  * <a href="#com.microsoft.nchwc.AveragePool">com.microsoft.nchwc.AveragePool</a>
  * <a href="#com.microsoft.nchwc.Conv">com.microsoft.nchwc.Conv</a>
  * <a href="#com.microsoft.nchwc.GlobalAveragePool">com.microsoft.nchwc.GlobalAveragePool</a>
  * <a href="#com.microsoft.nchwc.GlobalMaxPool">com.microsoft.nchwc.GlobalMaxPool</a>
  * <a href="#com.microsoft.nchwc.MaxPool">com.microsoft.nchwc.MaxPool</a>
  * <a href="#com.microsoft.nchwc.ReorderInput">com.microsoft.nchwc.ReorderInput</a>
  * <a href="#com.microsoft.nchwc.ReorderOutput">com.microsoft.nchwc.ReorderOutput</a>
  * <a href="#com.microsoft.nchwc.Upsample">com.microsoft.nchwc.Upsample</a>
* com.ms.internal.nhwc
  * <a href="#com.ms.internal.nhwc.BatchNormalization">com.ms.internal.nhwc.BatchNormalization</a>
  * <a href="#com.ms.internal.nhwc.ConvTranspose">com.ms.internal.nhwc.ConvTranspose</a>
  * <a href="#com.ms.internal.nhwc.DepthToSpace">com.ms.internal.nhwc.DepthToSpace</a>
  * <a href="#com.ms.internal.nhwc.GlobalLpPool">com.ms.internal.nhwc.GlobalLpPool</a>
  * <a href="#com.ms.internal.nhwc.InstanceNormalization">com.ms.internal.nhwc.InstanceNormalization</a>
  * <a href="#com.ms.internal.nhwc.LRN">com.ms.internal.nhwc.LRN</a>
  * <a href="#com.ms.internal.nhwc.LpPool">com.ms.internal.nhwc.LpPool</a>
  * <a href="#com.ms.internal.nhwc.MaxUnpool">com.ms.internal.nhwc.MaxUnpool</a>
  * <a href="#com.ms.internal.nhwc.QLinearConvTranspose">com.ms.internal.nhwc.QLinearConvTranspose</a>
  * <a href="#com.ms.internal.nhwc.Resize">com.ms.internal.nhwc.Resize</a>
  * <a href="#com.ms.internal.nhwc.SpaceToDepth">com.ms.internal.nhwc.SpaceToDepth</a>

## com.microsoft
### <a name="com.microsoft.Attention"></a><a name="com.microsoft.attention">**com.microsoft.Attention**</a>

#### Version

This version of the operator has been available since version 1 of the 'com.microsoft' operator set.

#### Attributes

<dl>
<dt><tt>do_rotary</tt> : int</dt>
<dd>Whether to use rotary position embedding. Default value is 0.</dd>
<dt><tt>mask_filter_value</tt> : float</dt>
<dd>The value to be filled in the attention mask. Default value is -10000.0f</dd>
<dt><tt>num_heads</tt> : int (required)</dt>
<dd>Number of attention heads</dd>
<dt><tt>past_present_share_buffer</tt> : int</dt>
<dd>Corresponding past and present are same tensor, its size is (2, batch_size, num_heads, max_sequence_length, head_size)</dd>
<dt><tt>qkv_hidden_sizes</tt> : list of ints</dt>
<dd>Hidden dimension of Q, K, V: hidden_size, hidden_size and v_hidden_size</dd>
<dt><tt>rotary_embedding_dim</tt> : int</dt>
<dd>Dimension of rotary embedding. Limited to 32, 64 or 128. Default value is head_size</dd>
<dt><tt>scale</tt> : float</dt>
<dd>Custom scale will be used if specified. Default value is 1/sqrt(head_size)</dd>
<dt><tt>unidirectional</tt> : int</dt>
<dd>Whether every token can only attend to previous tokens. Default value is 0.</dd>
</dl>

#### Inputs (2 - 7)

<dl>
<dt><tt>input</tt> : T</dt>
<dd></dd>
<dt><tt>weights</tt> : T</dt>
<dd></dd>
<dt><tt>bias</tt> (optional) : T</dt>
<dd></dd>
<dt><tt>mask_index</tt> (optional) : M</dt>
<dd></dd>
<dt><tt>past</tt> (optional) : T</dt>
<dd></dd>
<dt><tt>attention_bias</tt> (optional) : T</dt>
<dd></dd>
<dt><tt>past_sequence_length</tt> (optional) : M</dt>
<dd></dd>
</dl>

#### Outputs (1 - 2)

<dl>
<dt><tt>output</tt> : T</dt>
<dd></dd>
<dt><tt>present</tt> (optional) : T</dt>
<dd></dd>
</dl>

#### Type Constraints

<dl>
<dt><tt>T</tt> : tensor(float), tensor(float16)</dt>
<dd>Constrain input and output types to float tensors.</dd>
<dt><tt>M</tt> : tensor(int32)</dt>
<dd>Constrain mask index to integer types</dd>
</dl>


### <a name="com.microsoft.AttnLSTM"></a><a name="com.microsoft.attnlstm">**com.microsoft.AttnLSTM**</a>

#### Version

This version of the operator has been available since version 1 of the 'com.microsoft' operator set.

#### Attributes

<dl>
<dt><tt>activation_alpha</tt> : list of floats</dt>
<dd>Optional scaling values used by some activation functions. The values are consumed in the order of activation functions, for example (f, g, h) in LSTM. Default values are the same as of corresponding ONNX operators.For example with LeakyRelu, the default alpha is 0.01.</dd>
<dt><tt>activation_beta</tt> : list of floats</dt>
<dd>Optional scaling values used by some activation functions. The values are consumed in the order of activation functions, for example (f, g, h) in LSTM. Default values are the same as of corresponding ONNX operators.</dd>
<dt><tt>activations</tt> : list of strings</dt>
<dd>A list of 3 (or 6 if bidirectional) activation functions for input, output, forget, cell, and hidden. The activation functions must be one of the activation functions specified above. Optional: See the equations for default if not specified.</dd>
<dt><tt>clip</tt> : float</dt>
<dd>Cell clip threshold. Clipping bounds the elements of a tensor in the range of [-threshold, +threshold] and is applied to the input of activations. No clip if not specified.</dd>
<dt><tt>direction</tt> : string</dt>
<dd>Specify if the RNN is forward, reverse, or bidirectional. Must be one of forward (default), reverse, or bidirectional.</dd>
<dt><tt>hidden_size</tt> : int</dt>
<dd>Number of neurons in the hidden layer.</dd>
<dt><tt>input_forget</tt> : int</dt>
<dd>Couple the input and forget gates if 1, default 0.</dd>
</dl>

#### Inputs (3 - 14)

<dl>
<dt><tt>X</tt> : T</dt>
<dd></dd>
<dt><tt>W</tt> : T</dt>
<dd></dd>
<dt><tt>R</tt> : T</dt>
<dd></dd>
<dt><tt>B</tt> (optional) : T</dt>
<dd></dd>
<dt><tt>sequence_lens</tt> (optional) : T1</dt>
<dd></dd>
<dt><tt>initial_h</tt> (optional) : T</dt>
<dd></dd>
<dt><tt>initial_c</tt> (optional) : T</dt>
<dd></dd>
<dt><tt>P</tt> (optional) : T</dt>
<dd></dd>
<dt><tt>QW</tt> (optional) : T</dt>
<dd></dd>
<dt><tt>MW</tt> (optional) : T</dt>
<dd></dd>
<dt><tt>V</tt> (optional) : T</dt>
<dd></dd>
<dt><tt>M</tt> (optional) : T</dt>
<dd></dd>
<dt><tt>memory_seq_lens</tt> (optional) : T1</dt>
<dd></dd>
<dt><tt>AW</tt> (optional) : T</dt>
<dd></dd>
</dl>

#### Outputs (0 - 3)

<dl>
<dt><tt>Y</tt> (optional) : T</dt>
<dd></dd>
<dt><tt>Y_h</tt> (optional) : T</dt>
<dd></dd>
<dt><tt>Y_c</tt> (optional) : T</dt>
<dd></dd>
</dl>

#### Type Constraints

<dl>
<dt><tt>T</tt> : tensor(float), tensor(double)</dt>
<dd>Constrain input and output types to float tensors.</dd>
<dt><tt>T1</tt> : tensor(int32)</dt>
<dd>Constrain seq_lens to integral tensors.</dd>
</dl>


### <a name="com.microsoft.BeamSearch"></a><a name="com.microsoft.beamsearch">**com.microsoft.BeamSearch**</a>

#### Version

This version of the operator has been available since version 1 of the 'com.microsoft' operator set.

#### Attributes

<dl>
<dt><tt>decoder</tt> : graph (required)</dt>
<dd>Decoder subgraph to execute in a loop.</dd>
<dt><tt>decoder_start_token_id</tt> : int</dt>
<dd>The id of the token that indicates decoding starts.</dd>
<dt><tt>early_stopping</tt> : int</dt>
<dd>early stop or not</dd>
<dt><tt>encoder</tt> : graph</dt>
<dd>The subgraph for initialization of encoder and decoder. It will be called once before decoder subgraph.</dd>
<dt><tt>eos_token_id</tt> : int (required)</dt>
<dd>The id of the end-of-sequence token</dd>
<dt><tt>init_decoder</tt> : graph</dt>
<dd>The subgraph for the first decoding run. It will be called once before `decoder` subgraph. This is relevant only for the GPT2 model. If this attribute is missing, the `decoder` subgraph will be used for all decoding runs</dd>
<dt><tt>model_type</tt> : int</dt>
<dd>model type: 0 for GPT-2; 1 for encoder decoder like T5</dd>
<dt><tt>no_repeat_ngram_size</tt> : int</dt>
<dd>no repeat ngrams size</dd>
<dt><tt>pad_token_id</tt> : int (required)</dt>
<dd>The id of the padding token</dd>
<dt><tt>vocab_size</tt> : int</dt>
<dd>Size of the vocabulary. If not provided, it will be inferred from the decoder subgraph's output shape</dd>
</dl>

#### Inputs (5 - 12)

<dl>
<dt><tt>input_ids</tt> : F</dt>
<dd></dd>
<dt><tt>max_length</tt> : I</dt>
<dd></dd>
<dt><tt>min_length</tt> (optional) : I</dt>
<dd></dd>
<dt><tt>num_beams</tt> : I</dt>
<dd></dd>
<dt><tt>num_return_sequences</tt> : I</dt>
<dd></dd>
<dt><tt>length_penalty</tt> (optional) : T</dt>
<dd></dd>
<dt><tt>repetition_penalty</tt> (optional) : T</dt>
<dd></dd>
<dt><tt>vocab_mask</tt> (optional) : M</dt>
<dd></dd>
<dt><tt>prefix_vocab_mask</tt> (optional) : M</dt>
<dd></dd>
<dt><tt>attention_mask</tt> (optional) : I</dt>
<dd></dd>
<dt><tt>decoder_input_ids</tt> (optional) : I</dt>
<dd></dd>
<dt><tt>logits_processor</tt> (optional) : I</dt>
<dd></dd>
</dl>

#### Outputs (1 - 3)

<dl>
<dt><tt>sequences</tt> : I</dt>
<dd></dd>
<dt><tt>sequences_scores</tt> (optional) : T</dt>
<dd></dd>
<dt><tt>scores</tt> (optional) : T</dt>
<dd></dd>
</dl>

#### Type Constraints

<dl>
<dt><tt>T</tt> : tensor(float), tensor(float16)</dt>
<dd>Constrain to float tensors.</dd>
<dt><tt>F</tt> : tensor(float), tensor(int32), tensor(float16)</dt>
<dd>Constrain input type to float or int tensors.</dd>
<dt><tt>I</tt> : tensor(int32)</dt>
<dd>Constrain to integer types</dd>
<dt><tt>M</tt> : tensor(int32)</dt>
<dd>Constrain mask to integer types</dd>
</dl>


### <a name="com.microsoft.BiasAdd"></a><a name="com.microsoft.biasadd">**com.microsoft.BiasAdd**</a>

#### Version

This version of the operator has been available since version 1 of the 'com.microsoft' operator set.

#### Inputs

<dl>
<dt><tt>X</tt> : T</dt>
<dd></dd>
<dt><tt>bias</tt> : T</dt>
<dd></dd>
<dt><tt>skip</tt> : T</dt>
<dd></dd>
</dl>

#### Outputs

<dl>
<dt><tt>Y</tt> : T</dt>
<dd></dd>
</dl>

#### Type Constraints

<dl>
<dt><tt>T</tt> : tensor(float16), tensor(float)</dt>
<dd>Constrain input and output types to float tensors.</dd>
</dl>


### <a name="com.microsoft.BiasDropout"></a><a name="com.microsoft.biasdropout">**com.microsoft.BiasDropout**</a>

#### Version

This version of the operator has been available since version 1 of the 'com.microsoft' operator set.

#### Attributes

<dl>
<dt><tt>seed</tt> : int</dt>
<dd>(Optional) Seed to the random generator, if not specified we will auto generate one.</dd>
</dl>

#### Inputs (2 - 5)

<dl>
<dt><tt>data</tt> : T</dt>
<dd></dd>
<dt><tt>bias</tt> : T</dt>
<dd></dd>
<dt><tt>residual</tt> (optional) : T</dt>
<dd></dd>
<dt><tt>ratio</tt> (optional) : T1</dt>
<dd></dd>
<dt><tt>training_mode</tt> (optional) : T2</dt>
<dd></dd>
</dl>

#### Outputs (1 - 2)

<dl>
<dt><tt>output</tt> : T</dt>
<dd></dd>
<dt><tt>mask</tt> (optional) : T2</dt>
<dd></dd>
</dl>

#### Type Constraints

<dl>
<dt><tt>T</tt> : tensor(float16), tensor(float), tensor(double), tensor(bfloat16)</dt>
<dd>Constrain input and output types to float tensors.</dd>
<dt><tt>T1</tt> : tensor(float16), tensor(float), tensor(double), tensor(bfloat16)</dt>
<dd>Constrain input 'ratio' types to float tensors.</dd>
<dt><tt>T2</tt> : tensor(bool)</dt>
<dd>Constrain output 'mask' types to boolean tensors.</dd>
</dl>


### <a name="com.microsoft.BiasGelu"></a><a name="com.microsoft.biasgelu">**com.microsoft.BiasGelu**</a>

#### Version

This version of the operator has been available since version 1 of the 'com.microsoft' operator set.

#### Inputs

<dl>
<dt><tt>A</tt> : T</dt>
<dd></dd>
<dt><tt>B</tt> : T</dt>
<dd></dd>
</dl>

#### Outputs

<dl>
<dt><tt>C</tt> : T</dt>
<dd></dd>
</dl>

#### Type Constraints

<dl>
<dt><tt>T</tt> : tensor(float16), tensor(float), tensor(double), tensor(bfloat16)</dt>
<dd>Constrain input and output types to float tensors.</dd>
</dl>


### <a name="com.microsoft.BiasSoftmax"></a><a name="com.microsoft.biassoftmax">**com.microsoft.BiasSoftmax**</a>

#### Version

This version of the operator has been available since version 1 of the 'com.microsoft' operator set.

#### Attributes

<dl>
<dt><tt>axis</tt> : int</dt>
<dd>apply softmax to elements for dimensions axis or higher</dd>
<dt><tt>is_inner_broadcast</tt> : int (required)</dt>
<dd>true if broadcast bias across input for dimensions broadcast_axis to axis-1, otherwise broadcast bias across input for dimensions 0 to broadcast_axis - 1</dd>
</dl>

#### Inputs

<dl>
<dt><tt>data</tt> : T</dt>
<dd></dd>
<dt><tt>bias</tt> : T</dt>
<dd></dd>
</dl>

#### Outputs

<dl>
<dt><tt>output</tt> : T</dt>
<dd></dd>
</dl>

#### Type Constraints

<dl>
<dt><tt>T</tt> : tensor(float16), tensor(float), tensor(double)</dt>
<dd>Constrain input and output types to float tensors.</dd>
</dl>


### <a name="com.microsoft.BiasSplitGelu"></a><a name="com.microsoft.biassplitgelu">**com.microsoft.BiasSplitGelu**</a>

#### Version

This version of the operator has been available since version 1 of the 'com.microsoft' operator set.

#### Inputs

<dl>
<dt><tt>X</tt> : T</dt>
<dd></dd>
<dt><tt>bias</tt> : T</dt>
<dd></dd>
</dl>

#### Outputs

<dl>
<dt><tt>Y</tt> : T</dt>
<dd></dd>
</dl>

#### Type Constraints

<dl>
<dt><tt>T</tt> : tensor(float16), tensor(float)</dt>
<dd>Constrain input X and output Y types to float tensors.</dd>
</dl>


### <a name="com.microsoft.BifurcationDetector"></a><a name="com.microsoft.bifurcationdetector">**com.microsoft.BifurcationDetector**</a>

#### Version

This version of the operator has been available since version 1 of the 'com.microsoft' operator set.

#### Attributes

<dl>
<dt><tt>max_ngram_size</tt> : int</dt>
<dd>The maximum NGram size for suffix matching.</dd>
<dt><tt>min_ngram_size</tt> : int</dt>
<dd>The minimum NGram size for suffix matching.</dd>
</dl>

#### Inputs (3 - 4)

<dl>
<dt><tt>src_tokens</tt> : T</dt>
<dd></dd>
<dt><tt>cur_tokens</tt> : T</dt>
<dd></dd>
<dt><tt>prev_suffix_match_idx</tt> : T</dt>
<dd></dd>
<dt><tt>pred_tokens</tt> (optional) : T</dt>
<dd></dd>
</dl>

#### Outputs

<dl>
<dt><tt>tokens</tt> : T</dt>
<dd></dd>
<dt><tt>suffix_match_idx</tt> : T</dt>
<dd></dd>
</dl>

#### Type Constraints

<dl>
<dt><tt>T</tt> : tensor(int64)</dt>
<dd>Constrain to integer types.</dd>
</dl>


### <a name="com.microsoft.BitmaskBiasDropout"></a><a name="com.microsoft.bitmaskbiasdropout">**com.microsoft.BitmaskBiasDropout**</a>

#### Version

This version of the operator has been available since version 1 of the 'com.microsoft' operator set.

#### Attributes

<dl>
<dt><tt>seed</tt> : int</dt>
<dd>(Optional) Seed to the random generator, if not specified we will auto generate one.</dd>
</dl>

#### Inputs (2 - 5)

<dl>
<dt><tt>data</tt> : T</dt>
<dd></dd>
<dt><tt>bias</tt> : T</dt>
<dd></dd>
<dt><tt>residual</tt> (optional) : T</dt>
<dd></dd>
<dt><tt>ratio</tt> (optional) : T1</dt>
<dd></dd>
<dt><tt>training_mode</tt> (optional) : T2</dt>
<dd></dd>
</dl>

#### Outputs (1 - 2)

<dl>
<dt><tt>output</tt> : T</dt>
<dd></dd>
<dt><tt>mask</tt> (optional) : T3</dt>
<dd></dd>
</dl>

#### Type Constraints

<dl>
<dt><tt>T</tt> : tensor(float16), tensor(float), tensor(double), tensor(bfloat16)</dt>
<dd>Constrain input and output types to float tensors.</dd>
<dt><tt>T1</tt> : tensor(float16), tensor(float), tensor(double), tensor(bfloat16)</dt>
<dd>Constrain input 'ratio' types to float tensors.</dd>
<dt><tt>T2</tt> : tensor(bool)</dt>
<dd>Constrain input 'training_mode' types to boolean tensors.</dd>
<dt><tt>T3</tt> : tensor(uint32)</dt>
<dd>Constrain output 'mask' types to uint32 tensors.</dd>
</dl>


### <a name="com.microsoft.BitmaskDropout"></a><a name="com.microsoft.bitmaskdropout">**com.microsoft.BitmaskDropout**</a>

#### Version

This version of the operator has been available since version 1 of the 'com.microsoft' operator set.

#### Attributes

<dl>
<dt><tt>seed</tt> : int</dt>
<dd>(Optional) Seed to the random generator, if not specified we will auto generate one.</dd>
</dl>

#### Inputs (1 - 3)

<dl>
<dt><tt>data</tt> : T</dt>
<dd></dd>
<dt><tt>ratio</tt> (optional) : T1</dt>
<dd></dd>
<dt><tt>training_mode</tt> (optional) : T2</dt>
<dd></dd>
</dl>

#### Outputs (1 - 2)

<dl>
<dt><tt>output</tt> : T</dt>
<dd></dd>
<dt><tt>mask</tt> (optional) : T3</dt>
<dd></dd>
</dl>

#### Type Constraints

<dl>
<dt><tt>T</tt> : tensor(float16), tensor(float), tensor(double), tensor(bfloat16)</dt>
<dd>Constrain input and output types to float tensors.</dd>
<dt><tt>T1</tt> : tensor(float16), tensor(float), tensor(double), tensor(bfloat16)</dt>
<dd>Constrain input 'ratio' types to float tensors.</dd>
<dt><tt>T2</tt> : tensor(bool)</dt>
<dd>Constrain 'training_mode' to boolean tensor.</dd>
<dt><tt>T3</tt> : tensor(uint32)</dt>
<dd>Constrain output 'mask' types to bit-packed uint32 tensor.</dd>
</dl>


### <a name="com.microsoft.CDist"></a><a name="com.microsoft.cdist">**com.microsoft.CDist**</a>

#### Version

This version of the operator has been available since version 1 of the 'com.microsoft' operator set.

#### Attributes

<dl>
<dt><tt>metric</tt> : string</dt>
<dd>The distance metric to use. If a string, the distance function can be "braycurtis", "canberra", "chebyshev", "cityblock", "correlation", "cosine", "dice", "euclidean", "hamming", "jaccard", "jensenshannon", "kulsinski", "mahalanobis", "matching", "minkowski", "rogerstanimoto", "russellrao", "seuclidean", "sokalmichener", "sokalsneath", "sqeuclidean", "wminkowski", "yule".</dd>
</dl>

#### Inputs

<dl>
<dt><tt>A</tt> : T</dt>
<dd></dd>
<dt><tt>B</tt> : T</dt>
<dd></dd>
</dl>

#### Outputs

<dl>
<dt><tt>C</tt> : T</dt>
<dd></dd>
</dl>

#### Type Constraints

<dl>
<dt><tt>T</tt> : tensor(float), tensor(double)</dt>
<dd>Constrains input to only numeric types.</dd>
</dl>


### <a name="com.microsoft.ComplexMul"></a><a name="com.microsoft.complexmul">**com.microsoft.ComplexMul**</a>

#### Version

This version of the operator has been available since version 1 of the 'com.microsoft' operator set.

#### Inputs

<dl>
<dt><tt>A</tt> : T</dt>
<dd></dd>
<dt><tt>B</tt> : T</dt>
<dd></dd>
</dl>

#### Outputs

<dl>
<dt><tt>C</tt> : T</dt>
<dd></dd>
</dl>

#### Type Constraints

<dl>
<dt><tt>T</tt> : tensor(float), tensor(double), tensor(float16)</dt>
<dd>Constrain input and output types to float or half tensors.</dd>
</dl>


### <a name="com.microsoft.ComplexMulConj"></a><a name="com.microsoft.complexmulconj">**com.microsoft.ComplexMulConj**</a>

#### Version

This version of the operator has been available since version 1 of the 'com.microsoft' operator set.

#### Inputs

<dl>
<dt><tt>A</tt> : T</dt>
<dd></dd>
<dt><tt>B</tt> : T</dt>
<dd></dd>
</dl>

#### Outputs

<dl>
<dt><tt>C</tt> : T</dt>
<dd></dd>
</dl>

#### Type Constraints

<dl>
<dt><tt>T</tt> : tensor(float), tensor(double), tensor(float16)</dt>
<dd>Constrain input and output types to float or half tensors.</dd>
</dl>


### <a name="com.microsoft.ConvTransposeWithDynamicPads"></a><a name="com.microsoft.convtransposewithdynamicpads">**com.microsoft.ConvTransposeWithDynamicPads**</a>

#### Version

This version of the operator has been available since version 1 of the 'com.microsoft' operator set.

#### Attributes

<dl>
<dt><tt>auto_pad</tt> : string</dt>
<dd></dd>
<dt><tt>dilations</tt> : list of ints</dt>
<dd></dd>
<dt><tt>group</tt> : int</dt>
<dd></dd>
<dt><tt>kernel_shape</tt> : list of ints</dt>
<dd></dd>
<dt><tt>output_padding</tt> : list of ints</dt>
<dd></dd>
<dt><tt>strides</tt> : list of ints</dt>
<dd></dd>
</dl>

#### Inputs (2 - 4)

<dl>
<dt><tt>X</tt> : T</dt>
<dd></dd>
<dt><tt>W</tt> : T</dt>
<dd></dd>
<dt><tt>Pads</tt> (optional) : tensor(int64)</dt>
<dd></dd>
<dt><tt>B</tt> (optional) : T</dt>
<dd></dd>
</dl>

#### Outputs

<dl>
<dt><tt>Y</tt> : T</dt>
<dd></dd>
</dl>

#### Type Constraints

<dl>
<dt><tt>T</tt> : tensor(float16), tensor(float), tensor(double)</dt>
<dd>Constrain input and output types to float tensors</dd>
</dl>


### <a name="com.microsoft.CropAndResize"></a><a name="com.microsoft.cropandresize">**com.microsoft.CropAndResize**</a>

#### Version

This version of the operator has been available since version 1 of the 'com.microsoft' operator set.

#### Attributes

<dl>
<dt><tt>extrapolation_value</tt> : float</dt>
<dd>Value used for extrapolation, when applicable. Default is 0.0f. </dd>
<dt><tt>mode</tt> : string</dt>
<dd>The pooling method. Two modes are supported: 'bilinear' and 'nearest'. Default is 'bilinear'.</dd>
</dl>

#### Inputs

<dl>
<dt><tt>X</tt> : T1</dt>
<dd></dd>
<dt><tt>rois</tt> : T1</dt>
<dd></dd>
<dt><tt>batch_indices</tt> : T2</dt>
<dd></dd>
<dt><tt>crop_size</tt> : T2</dt>
<dd></dd>
</dl>

#### Outputs

<dl>
<dt><tt>Y</tt> : T1</dt>
<dd></dd>
</dl>

#### Type Constraints

<dl>
<dt><tt>T1</tt> : tensor(float16), tensor(float), tensor(double)</dt>
<dd>Constrain types to float tensors.</dd>
<dt><tt>T2</tt> : tensor(int32)</dt>
<dd>Constrain types to int tensors.</dd>
</dl>


### <a name="com.microsoft.DecoderAttention"></a><a name="com.microsoft.decoderattention">**com.microsoft.DecoderAttention**</a>

#### Version

This version of the operator has been available since version 1 of the 'com.microsoft' operator set.

#### Attributes

<dl>
<dt><tt>mask_filter_value</tt> : float</dt>
<dd>The value to be filled in the attention mask. Default value is -10000.0f</dd>
<dt><tt>num_heads</tt> : int (required)</dt>
<dd>Number of attention heads</dd>
</dl>

#### Inputs

<dl>
<dt><tt>query</tt> : T</dt>
<dd></dd>
<dt><tt>key</tt> : T</dt>
<dd></dd>
<dt><tt>q_weight</tt> : T</dt>
<dd></dd>
<dt><tt>kv_weight</tt> : T</dt>
<dd></dd>
<dt><tt>bias</tt> : T</dt>
<dd></dd>
<dt><tt>key_padding_mask</tt> (optional) : B</dt>
<dd></dd>
<dt><tt>key_cache</tt> (optional) : T</dt>
<dd></dd>
<dt><tt>value_cache</tt> (optional) : T</dt>
<dd></dd>
<dt><tt>static_kv</tt> : B</dt>
<dd></dd>
<dt><tt>use_past</tt> : B</dt>
<dd></dd>
<dt><tt>has_layer_state</tt> : B</dt>
<dd></dd>
<dt><tt>has_key_padding_mask</tt> : B</dt>
<dd></dd>
</dl>

#### Outputs (1 - 3)

<dl>
<dt><tt>output</tt> : T</dt>
<dd></dd>
<dt><tt>new_key_cache</tt> (optional) : T</dt>
<dd></dd>
<dt><tt>new_value_cache</tt> (optional) : T</dt>
<dd></dd>
</dl>

#### Type Constraints

<dl>
<dt><tt>T</tt> : tensor(float), tensor(float16)</dt>
<dd>Constrain input and output types to float and float16 tensors.</dd>
<dt><tt>B</tt> : tensor(bool)</dt>
<dd>Constrain key_padding_mask to bool tensors.</dd>
</dl>


### <a name="com.microsoft.DecoderMaskedMultiHeadAttention"></a><a name="com.microsoft.decodermaskedmultiheadattention">**com.microsoft.DecoderMaskedMultiHeadAttention**</a>

#### Version

This version of the operator has been available since version 1 of the 'com.microsoft' operator set.

#### Attributes

<dl>
<dt><tt>mask_filter_value</tt> : float</dt>
<dd>The value to be filled in the attention mask. Default value is -10000.0f</dd>
<dt><tt>num_heads</tt> : int (required)</dt>
<dd>Number of attention heads</dd>
<dt><tt>output_qk</tt> : int</dt>
<dd>Need output the cross attention MatMul(Q, K)</dd>
<dt><tt>past_present_share_buffer</tt> : int</dt>
<dd>Corresponding past and present are same tensor, its size is (batch_size, num_heads, max_sequence_length, head_size)</dd>
<dt><tt>scale</tt> : float</dt>
<dd>Custom scale will be used if specified. Default value is 1/sqrt(head_size)</dd>
</dl>

#### Inputs (1 - 11)

<dl>
<dt><tt>query</tt> : T</dt>
<dd></dd>
<dt><tt>key</tt> (optional) : T</dt>
<dd></dd>
<dt><tt>value</tt> (optional) : T</dt>
<dd></dd>
<dt><tt>mask_index</tt> (optional) : M</dt>
<dd></dd>
<dt><tt>attention_bias</tt> (optional) : T</dt>
<dd></dd>
<dt><tt>past_key</tt> (optional) : T</dt>
<dd></dd>
<dt><tt>past_value</tt> (optional) : T</dt>
<dd></dd>
<dt><tt>past_sequence_length</tt> (optional) : M</dt>
<dd></dd>
<dt><tt>beam_width</tt> (optional) : M</dt>
<dd></dd>
<dt><tt>cache_indirection</tt> (optional) : M</dt>
<dd></dd>
<dt><tt>bias</tt> (optional) : T</dt>
<dd></dd>
</dl>

#### Outputs (1 - 4)

<dl>
<dt><tt>output</tt> : T</dt>
<dd></dd>
<dt><tt>present_key</tt> (optional) : T</dt>
<dd></dd>
<dt><tt>present_value</tt> (optional) : T</dt>
<dd></dd>
<dt><tt>qk</tt> (optional) : V</dt>
<dd></dd>
</dl>

#### Type Constraints

<dl>
<dt><tt>V</tt> : tensor(float)</dt>
<dd>Constrain qk output types to float32 tensors.</dd>
<dt><tt>T</tt> : tensor(float), tensor(float16)</dt>
<dd>Constrain input and output types to float tensors.</dd>
<dt><tt>M</tt> : tensor(int32)</dt>
<dd>Constrain mask index to integer types</dd>
</dl>


### <a name="com.microsoft.DecoderMaskedSelfAttention"></a><a name="com.microsoft.decodermaskedselfattention">**com.microsoft.DecoderMaskedSelfAttention**</a>

#### Version

This version of the operator has been available since version 1 of the 'com.microsoft' operator set.

#### Attributes

<dl>
<dt><tt>do_rotary</tt> : int</dt>
<dd>Whether to use rotary position embedding. Default value is 0.</dd>
<dt><tt>mask_filter_value</tt> : float</dt>
<dd>The value to be filled in the attention mask. Default value is -10000.0f</dd>
<dt><tt>num_heads</tt> : int (required)</dt>
<dd>Number of attention heads</dd>
<dt><tt>past_present_share_buffer</tt> : int</dt>
<dd>Corresponding past and present are same tensor, its size is (2, batch_size, num_heads, max_sequence_length, head_size)</dd>
<dt><tt>scale</tt> : float</dt>
<dd>Custom scale will be used if specified. Default value is 1/sqrt(head_size)</dd>
</dl>

#### Inputs (7 - 9)

<dl>
<dt><tt>input</tt> : T</dt>
<dd></dd>
<dt><tt>weights</tt> : T</dt>
<dd></dd>
<dt><tt>bias</tt> : T</dt>
<dd></dd>
<dt><tt>mask_index</tt> (optional) : M</dt>
<dd></dd>
<dt><tt>past</tt> : T</dt>
<dd></dd>
<dt><tt>attention_bias</tt> (optional) : T</dt>
<dd></dd>
<dt><tt>past_sequence_length</tt> : M</dt>
<dd></dd>
<dt><tt>beam_width</tt> (optional) : M</dt>
<dd></dd>
<dt><tt>cache_indirection</tt> (optional) : M</dt>
<dd></dd>
</dl>

#### Outputs

<dl>
<dt><tt>output</tt> : T</dt>
<dd></dd>
<dt><tt>present</tt> : T</dt>
<dd></dd>
</dl>

#### Type Constraints

<dl>
<dt><tt>T</tt> : tensor(float), tensor(float16)</dt>
<dd>Constrain input and output types to float tensors.</dd>
<dt><tt>M</tt> : tensor(int32)</dt>
<dd>Constrain mask index to integer types</dd>
</dl>


### <a name="com.microsoft.DequantizeBFP"></a><a name="com.microsoft.dequantizebfp">**com.microsoft.DequantizeBFP**</a>

#### Version

This version of the operator has been available since version 1 of the 'com.microsoft' operator set.

#### Attributes

<dl>
<dt><tt>bfp_type</tt> : int (required)</dt>
<dd>The type of BFP - must match with the BFPType enum</dd>
<dt><tt>block_dim</tt> : int</dt>
<dd>Each bounding box spans this dimension.Typically, the block dimension corresponds to the reduction dimension of the matrix multipication that consumes the output of this operator.For example, for a 2D matrix multiplication A@W, QuantizeBFP(A) would use block_dim 1 and QuantizeBFP(W) would use block_dim 0.The default is the last dimension.</dd>
<dt><tt>dtype</tt> : int</dt>
<dd>The datatype to dequantize to.</dd>
</dl>

#### Inputs

<dl>
<dt><tt>x</tt> : T1</dt>
<dd></dd>
<dt><tt>shape</tt> : T2</dt>
<dd></dd>
<dt><tt>strides</tt> : T2</dt>
<dd></dd>
</dl>

#### Outputs

<dl>
<dt><tt>y</tt> : T3</dt>
<dd></dd>
</dl>

#### Type Constraints

<dl>
<dt><tt>T1</tt> : tensor(uint8)</dt>
<dd>Constrain the input to uint8.</dd>
<dt><tt>T2</tt> : tensor(int64)</dt>
<dd>Constrain shape and strides to uint64.</dd>
<dt><tt>T3</tt> : tensor(float), tensor(float16), tensor(bfloat16)</dt>
<dd>Constrain y to float and bfloat16.</dd>
</dl>


### <a name="com.microsoft.DequantizeLinear"></a><a name="com.microsoft.dequantizelinear">**com.microsoft.DequantizeLinear**</a>

#### Version

This version of the operator has been available since version 1 of the 'com.microsoft' operator set.

#### Attributes

<dl>
<dt><tt>axis</tt> : int</dt>
<dd>The axis along which same quantization parameters are applied. It's optional.If it's not specified, it means per-tensor quantization and input 'x_scale' and 'x_zero_point' must be scalars.If it's specified, it means per 'axis' quantization and input 'x_scale' and 'x_zero_point' must be 1-D tensors.</dd>
</dl>

#### Inputs (2 - 3)

<dl>
<dt><tt>x</tt> : T1</dt>
<dd></dd>
<dt><tt>x_scale</tt> : T2</dt>
<dd></dd>
<dt><tt>x_zero_point</tt> (optional) : T1</dt>
<dd></dd>
</dl>

#### Outputs

<dl>
<dt><tt>y</tt> : T2</dt>
<dd></dd>
</dl>

#### Type Constraints

<dl>
<dt><tt>T1</tt> : tensor(int8), tensor(uint8), tensor(int16), tensor(uint16), tensor(int32), tensor(int4), tensor(uint4)</dt>
<dd>Constrain 'x' and 'x_zero_point' to 8-bit integer tensors, 16-bit integer tensors, or 32-bit signed integer tensors.</dd>
<dt><tt>T2</tt> : tensor(float16), tensor(float)</dt>
<dd>Constrain 'y', 'x_scale' to float tensors.</dd>
</dl>


### <a name="com.microsoft.DequantizeWithOrder"></a><a name="com.microsoft.dequantizewithorder">**com.microsoft.DequantizeWithOrder**</a>

#### Version

This version of the operator has been available since version 1 of the 'com.microsoft' operator set.

#### Attributes

<dl>
<dt><tt>order_input</tt> : int (required)</dt>
<dd>cublasLt order of input matrix. See the schema of QuantizeWithOrder for order definition.</dd>
<dt><tt>order_output</tt> : int (required)</dt>
<dd>cublasLt order of output matrix</dd>
<dt><tt>to</tt> : int (required)</dt>
<dd>The output data type, only support TensorProto_DataType_FLOAT (1) and TensorProto_DataType_FLOAT16 (10)</dd>
</dl>

#### Inputs

<dl>
<dt><tt>input</tt> : Q</dt>
<dd></dd>
<dt><tt>scale_input</tt> : S</dt>
<dd></dd>
</dl>

#### Outputs

<dl>
<dt><tt>output</tt> : F</dt>
<dd></dd>
</dl>

#### Type Constraints

<dl>
<dt><tt>Q</tt> : tensor(int8)</dt>
<dd>Constrain input and output types to int8 tensors.</dd>
<dt><tt>F</tt> : tensor(float16), tensor(float)</dt>
<dd>Constrain to float types</dd>
<dt><tt>S</tt> : tensor(float)</dt>
<dd>Constrain Scale to float32 types</dd>
</dl>


### <a name="com.microsoft.DynamicQuantizeLSTM"></a><a name="com.microsoft.dynamicquantizelstm">**com.microsoft.DynamicQuantizeLSTM**</a>

#### Version

This version of the operator has been available since version 1 of the 'com.microsoft' operator set.

#### Attributes

<dl>
<dt><tt>activation_alpha</tt> : list of floats</dt>
<dd>Optional scaling values used by some activation functions. The values are consumed in the order of activation functions, for example (f, g, h) in LSTM. Default values are the same as of corresponding ONNX operators.For example with LeakyRelu, the default alpha is 0.01.</dd>
<dt><tt>activation_beta</tt> : list of floats</dt>
<dd>Optional scaling values used by some activation functions. The values are consumed in the order of activation functions, for example (f, g, h) in LSTM. Default values are the same as of corresponding ONNX operators.</dd>
<dt><tt>activations</tt> : list of strings</dt>
<dd>A list of 3 (or 6 if bidirectional) activation functions for input, output, forget, cell, and hidden. The activation functions must be one of the activation functions specified above. Optional: See the equations for default if not specified.</dd>
<dt><tt>clip</tt> : float</dt>
<dd>Cell clip threshold. Clipping bounds the elements of a tensor in the range of [-threshold, +threshold] and is applied to the input of activations. No clip if not specified.</dd>
<dt><tt>direction</tt> : string</dt>
<dd>Specify if the RNN is forward, reverse, or bidirectional. Must be one of forward (default), reverse, or bidirectional.</dd>
<dt><tt>hidden_size</tt> : int</dt>
<dd>Number of neurons in the hidden layer</dd>
<dt><tt>input_forget</tt> : int</dt>
<dd>Couple the input and forget gates if 1.</dd>
</dl>

#### Inputs

<dl>
<dt><tt>X</tt> : T</dt>
<dd></dd>
<dt><tt>W</tt> : T2</dt>
<dd></dd>
<dt><tt>R</tt> : T2</dt>
<dd></dd>
<dt><tt>B</tt> (optional) : T</dt>
<dd></dd>
<dt><tt>sequence_lens</tt> (optional) : T1</dt>
<dd></dd>
<dt><tt>initial_h</tt> (optional) : T</dt>
<dd></dd>
<dt><tt>initial_c</tt> (optional) : T</dt>
<dd></dd>
<dt><tt>P</tt> (optional) : T</dt>
<dd></dd>
<dt><tt>W_scale</tt> : T</dt>
<dd></dd>
<dt><tt>W_zero_point</tt> : T2</dt>
<dd></dd>
<dt><tt>R_scale</tt> : T</dt>
<dd></dd>
<dt><tt>R_zero_point</tt> : T2</dt>
<dd></dd>
</dl>

#### Outputs (0 - 3)

<dl>
<dt><tt>Y</tt> (optional) : T</dt>
<dd></dd>
<dt><tt>Y_h</tt> (optional) : T</dt>
<dd></dd>
<dt><tt>Y_c</tt> (optional) : T</dt>
<dd></dd>
</dl>

#### Type Constraints

<dl>
<dt><tt>T</tt> : tensor(float)</dt>
<dd>Constrain input and output types to float tensors.</dd>
<dt><tt>T1</tt> : tensor(int32)</dt>
<dd>Constrain seq_lens to integer tensor.</dd>
<dt><tt>T2</tt> : tensor(uint8), tensor(int8)</dt>
<dd>Constrain weights types to 8 bit tensors.</dd>
</dl>


### <a name="com.microsoft.DynamicQuantizeMatMul"></a><a name="com.microsoft.dynamicquantizematmul">**com.microsoft.DynamicQuantizeMatMul**</a>

#### Version

This version of the operator has been available since version 1 of the 'com.microsoft' operator set.

#### Inputs (3 - 5)

<dl>
<dt><tt>A</tt> : T1</dt>
<dd></dd>
<dt><tt>B</tt> : T2</dt>
<dd></dd>
<dt><tt>b_scale</tt> : T1</dt>
<dd></dd>
<dt><tt>b_zero_point</tt> (optional) : T2</dt>
<dd></dd>
<dt><tt>bias</tt> (optional) : T1</dt>
<dd></dd>
</dl>

#### Outputs

<dl>
<dt><tt>Y</tt> : T1</dt>
<dd></dd>
</dl>

#### Type Constraints

<dl>
<dt><tt>T1</tt> : tensor(float)</dt>
<dd>Constrain input A, b_scale and output Y data type as float tensor.</dd>
<dt><tt>T2</tt> : tensor(int8), tensor(uint8)</dt>
<dd>Constrain input B data type to 8-bit integer tensor.</dd>
</dl>


### <a name="com.microsoft.DynamicTimeWarping"></a><a name="com.microsoft.dynamictimewarping">**com.microsoft.DynamicTimeWarping**</a>

#### Version

This version of the operator has been available since version 1 of the 'com.microsoft' operator set.

#### Inputs

<dl>
<dt><tt>input</tt> : F</dt>
<dd></dd>
</dl>

#### Outputs

<dl>
<dt><tt>output</tt> : I</dt>
<dd></dd>
</dl>

#### Type Constraints

<dl>
<dt><tt>F</tt> : tensor(float)</dt>
<dd>Constrain to float tensors.</dd>
<dt><tt>I</tt> : tensor(int32)</dt>
<dd>Constrain to integer types.</dd>
</dl>


### <a name="com.microsoft.EPContext"></a><a name="com.microsoft.epcontext">**com.microsoft.EPContext**</a>

#### Version

This version of the operator has been available since version 1 of the 'com.microsoft' operator set.

#### Attributes

<dl>
<dt><tt>embed_mode</tt> : int</dt>
<dd>1: indicate ep_cache_context is the context content. 0: indicate ep_cache_context is the file path to the context content.The path is relative to this Onnx file. Default is 1.</dd>
<dt><tt>ep_cache_context</tt> : string</dt>
<dd>payload of the execution provider context if embed_mode=1, or path to the context file if embed_mode=0.</dd>
<dt><tt>ep_sdk_version</tt> : string</dt>
<dd>(Optional) SDK version used to convert the model.</dd>
<dt><tt>hardware_architecture</tt> : string</dt>
<dd>(Optional) Hardware architecture.</dd>
<dt><tt>main_context</tt> : int</dt>
<dd>Usually each single EPContext associate with a graph partition.But for some case like QNN, it has single EPContext contains all partitions.In that case, the node with ep_cache_context should set main_context=1. Other nodes set main_context=0 and skip ep_cache_context.The path is relative to this Onnx file. Default is 1.</dd>
<dt><tt>max_size</tt> : int</dt>
<dd>max size in the context. Usage depend on the EP.</dd>
<dt><tt>notes</tt> : string</dt>
<dd>(Optional) Some notes for the model</dd>
<dt><tt>onnx_model_filename</tt> : string</dt>
<dd>(Optional) Filename of the original ONNX model.</dd>
<dt><tt>partition_name</tt> : string</dt>
<dd>(Optional) partitioned graph name.</dd>
<dt><tt>source</tt> : string</dt>
<dd>(Optional) the source used to generate the engine/context cache file. Ort EP or native SDK tool chain</dd>
</dl>

#### Inputs (1 - &#8734;)

<dl>
<dt><tt>inputs</tt> (variadic, heterogeneous) : T</dt>
<dd></dd>
</dl>

#### Outputs (1 - &#8734;)

<dl>
<dt><tt>outputs</tt> (variadic, heterogeneous) : T</dt>
<dd></dd>
</dl>

#### Type Constraints

<dl>
<dt><tt>T</tt> : tensor(int8), tensor(int16), tensor(int32), tensor(int64), tensor(bool), tensor(uint8), tensor(uint16), tensor(uint32), tensor(uint64), tensor(float16), tensor(float), tensor(double), tensor(bfloat16)</dt>
<dd>Constrain input and output types.</dd>
</dl>


### <a name="com.microsoft.EmbedLayerNormalization"></a><a name="com.microsoft.embedlayernormalization">**com.microsoft.EmbedLayerNormalization**</a>

#### Version

This version of the operator has been available since version 1 of the 'com.microsoft' operator set.

#### Attributes

<dl>
<dt><tt>epsilon</tt> : float</dt>
<dd>The epsilon value to use to avoid division by zero.</dd>
<dt><tt>mask_index_type</tt> : int</dt>
<dd>The mask index tensor type for shape inference (0: None, 1: 1D mask_index)</dd>
</dl>

#### Inputs (7 - 9)

<dl>
<dt><tt>input_ids</tt> : T1</dt>
<dd></dd>
<dt><tt>segment_ids</tt> (optional) : T1</dt>
<dd></dd>
<dt><tt>word_embedding</tt> : T</dt>
<dd></dd>
<dt><tt>position_embedding</tt> : T</dt>
<dd></dd>
<dt><tt>segment_embedding</tt> (optional) : T</dt>
<dd></dd>
<dt><tt>gamma</tt> : T</dt>
<dd></dd>
<dt><tt>beta</tt> : T</dt>
<dd></dd>
<dt><tt>mask</tt> (optional) : T1</dt>
<dd></dd>
<dt><tt>position_ids</tt> (optional) : T1</dt>
<dd></dd>
</dl>

#### Outputs (1 - 3)

<dl>
<dt><tt>output</tt> : T</dt>
<dd></dd>
<dt><tt>mask_index</tt> (optional) : T1</dt>
<dd></dd>
<dt><tt>embedding_sum</tt> (optional) : T</dt>
<dd></dd>
</dl>

#### Type Constraints

<dl>
<dt><tt>T1</tt> : tensor(int32)</dt>
<dd>Constrain input and output integer tensors types</dd>
<dt><tt>T</tt> : tensor(float), tensor(float16)</dt>
<dd>Constrain input and output float tensors types.</dd>
</dl>


### <a name="com.microsoft.ExpandDims"></a><a name="com.microsoft.expanddims">**com.microsoft.ExpandDims**</a>

#### Version

This version of the operator has been available since version 1 of the 'com.microsoft' operator set.

#### Inputs

<dl>
<dt><tt>X</tt> : T</dt>
<dd></dd>
<dt><tt>axis</tt> : tensor(int32)</dt>
<dd></dd>
</dl>

#### Outputs

<dl>
<dt><tt>Y</tt> : T</dt>
<dd></dd>
</dl>

#### Type Constraints

<dl>
<dt><tt>T</tt> : tensor(uint8), tensor(uint16), tensor(uint32), tensor(uint64), tensor(int8), tensor(int16), tensor(int32), tensor(int64), tensor(float16), tensor(float), tensor(double), tensor(string), tensor(bool), tensor(complex64), tensor(complex128)</dt>
<dd>Constrain to any tensor type. If the dtype attribute is not provided this must be a valid output type.</dd>
</dl>


### <a name="com.microsoft.FastGelu"></a><a name="com.microsoft.fastgelu">**com.microsoft.FastGelu**</a>

#### Version

This version of the operator has been available since version 1 of the 'com.microsoft' operator set.

#### Inputs (1 - 2)

<dl>
<dt><tt>X</tt> : T</dt>
<dd></dd>
<dt><tt>bias</tt> (optional) : T</dt>
<dd></dd>
</dl>

#### Outputs

<dl>
<dt><tt>Y</tt> : T</dt>
<dd></dd>
</dl>

#### Type Constraints

<dl>
<dt><tt>T</tt> : tensor(float), tensor(float16), tensor(bfloat16)</dt>
<dd>Constrain input and output types to float or half tensors.</dd>
</dl>


### <a name="com.microsoft.FusedConv"></a><a name="com.microsoft.fusedconv">**com.microsoft.FusedConv**</a>

#### Version

This version of the operator has been available since version 1 of the 'com.microsoft' operator set.

#### Attributes

<dl>
<dt><tt>activation</tt> : string</dt>
<dd></dd>
<dt><tt>activation_params</tt> : list of floats</dt>
<dd></dd>
<dt><tt>auto_pad</tt> : string</dt>
<dd></dd>
<dt><tt>dilations</tt> : list of ints</dt>
<dd></dd>
<dt><tt>group</tt> : int</dt>
<dd></dd>
<dt><tt>kernel_shape</tt> : list of ints</dt>
<dd></dd>
<dt><tt>pads</tt> : list of ints</dt>
<dd></dd>
<dt><tt>strides</tt> : list of ints</dt>
<dd></dd>
</dl>

#### Inputs (2 - 4)

<dl>
<dt><tt>X</tt> : T</dt>
<dd></dd>
<dt><tt>W</tt> : T</dt>
<dd></dd>
<dt><tt>B</tt> (optional) : T</dt>
<dd></dd>
<dt><tt>Z</tt> (optional) : T</dt>
<dd></dd>
</dl>

#### Outputs

<dl>
<dt><tt>Y</tt> : T</dt>
<dd></dd>
</dl>

#### Type Constraints

<dl>
<dt><tt>T</tt> : tensor(float16), tensor(float), tensor(double)</dt>
<dd>Constrain input and output types to float tensors</dd>
</dl>


### <a name="com.microsoft.FusedGemm"></a><a name="com.microsoft.fusedgemm">**com.microsoft.FusedGemm**</a>

#### Version

This version of the operator has been available since version 1 of the 'com.microsoft' operator set.

#### Attributes

<dl>
<dt><tt>activation</tt> : string</dt>
<dd></dd>
<dt><tt>activation_alpha</tt> : float</dt>
<dd></dd>
<dt><tt>activation_beta</tt> : float</dt>
<dd></dd>
<dt><tt>activation_gamma</tt> : float</dt>
<dd></dd>
<dt><tt>alpha</tt> : float</dt>
<dd>Scalar multiplier for the product of input tensors A * B.</dd>
<dt><tt>beta</tt> : float</dt>
<dd>Scalar multiplier for input tensor C.</dd>
<dt><tt>transA</tt> : int</dt>
<dd>Whether A should be transposed</dd>
<dt><tt>transB</tt> : int</dt>
<dd>Whether B should be transposed</dd>
</dl>

#### Inputs (2 - 3)

<dl>
<dt><tt>A</tt> : T</dt>
<dd></dd>
<dt><tt>B</tt> : T</dt>
<dd></dd>
<dt><tt>C</tt> (optional) : T</dt>
<dd></dd>
</dl>

#### Outputs

<dl>
<dt><tt>Y</tt> : T</dt>
<dd></dd>
</dl>

#### Type Constraints

<dl>
<dt><tt>T</tt> : tensor(float16), tensor(float), tensor(double), tensor(uint32), tensor(uint64), tensor(int32), tensor(int64)</dt>
<dd>Constrain input and output types to float/int tensors.</dd>
</dl>


### <a name="com.microsoft.FusedMatMul"></a><a name="com.microsoft.fusedmatmul">**com.microsoft.FusedMatMul**</a>

#### Version

This version of the operator has been available since version 1 of the 'com.microsoft' operator set.

#### Attributes

<dl>
<dt><tt>alpha</tt> : float</dt>
<dd>Scalar multiplier for the product of the input tensors.</dd>
<dt><tt>transA</tt> : int</dt>
<dd>Whether A should be transposed on the last two dimensions before doing multiplication</dd>
<dt><tt>transB</tt> : int</dt>
<dd>Whether B should be transposed on the last two dimensions before doing multiplication</dd>
<dt><tt>transBatchA</tt> : int</dt>
<dd>Whether A should be transposed on the 1st dimension and batch dimensions (dim-1 to dim-rank-2) before doing multiplication</dd>
<dt><tt>transBatchB</tt> : int</dt>
<dd>Whether B should be transposed on the 1st dimension and batch dimensions (dim-1 to dim-rank-2) before doing multiplication</dd>
</dl>

#### Inputs

<dl>
<dt><tt>A</tt> : T</dt>
<dd></dd>
<dt><tt>B</tt> : T</dt>
<dd></dd>
</dl>

#### Outputs

<dl>
<dt><tt>Y</tt> : T</dt>
<dd></dd>
</dl>

#### Type Constraints

<dl>
<dt><tt>T</tt> : tensor(float16), tensor(float), tensor(double), tensor(bfloat16)</dt>
<dd>Constrain input and output types to float tensors.</dd>
</dl>


### <a name="com.microsoft.FusedMatMulActivation"></a><a name="com.microsoft.fusedmatmulactivation">**com.microsoft.FusedMatMulActivation**</a>

#### Version

This version of the operator has been available since version 1 of the 'com.microsoft' operator set.

#### Attributes

<dl>
<dt><tt>activation</tt> : string (required)</dt>
<dd></dd>
<dt><tt>activation_alpha</tt> : float</dt>
<dd></dd>
<dt><tt>activation_axis</tt> : int</dt>
<dd></dd>
<dt><tt>activation_beta</tt> : float</dt>
<dd></dd>
<dt><tt>activation_gamma</tt> : float</dt>
<dd></dd>
<dt><tt>alpha</tt> : float</dt>
<dd>Scalar multiplier for the product of the input tensors.</dd>
<dt><tt>transA</tt> : int</dt>
<dd>Whether A should be transposed on the last two dimensions before doing multiplication</dd>
<dt><tt>transB</tt> : int</dt>
<dd>Whether B should be transposed on the last two dimensions before doing multiplication</dd>
<dt><tt>transBatchA</tt> : int</dt>
<dd>Whether A should be transposed on the 1st dimension and batch dimensions (dim-1 to dim-rank-2) before doing multiplication</dd>
<dt><tt>transBatchB</tt> : int</dt>
<dd>Whether B should be transposed on the 1st dimension and batch dimensions (dim-1 to dim-rank-2) before doing multiplication</dd>
</dl>

#### Inputs

<dl>
<dt><tt>A</tt> : T</dt>
<dd></dd>
<dt><tt>B</tt> : T</dt>
<dd></dd>
</dl>

#### Outputs

<dl>
<dt><tt>Y</tt> : T</dt>
<dd></dd>
</dl>

#### Type Constraints

<dl>
<dt><tt>T</tt> : tensor(float16), tensor(float), tensor(double), tensor(bfloat16)</dt>
<dd>Constrain input and output types to float tensors.</dd>
</dl>


### <a name="com.microsoft.GatedRelativePositionBias"></a><a name="com.microsoft.gatedrelativepositionbias">**com.microsoft.GatedRelativePositionBias**</a>

#### Version

This version of the operator has been available since version 1 of the 'com.microsoft' operator set.

#### Attributes

<dl>
<dt><tt>num_heads</tt> : int (required)</dt>
<dd>Number of attention heads</dd>
</dl>

#### Inputs (6 - 7)

<dl>
<dt><tt>query_layer</tt> : T</dt>
<dd></dd>
<dt><tt>query_bias</tt> : T</dt>
<dd></dd>
<dt><tt>rel_pos</tt> : T</dt>
<dd></dd>
<dt><tt>weight</tt> : T</dt>
<dd></dd>
<dt><tt>bias</tt> : T</dt>
<dd></dd>
<dt><tt>eco_a</tt> : T</dt>
<dd></dd>
<dt><tt>token_offset</tt> (optional) : M</dt>
<dd></dd>
</dl>

#### Outputs

<dl>
<dt><tt>output</tt> : T</dt>
<dd></dd>
</dl>

#### Type Constraints

<dl>
<dt><tt>T</tt> : tensor(float), tensor(float16)</dt>
<dd>Constrain input and output types to float tensors.</dd>
<dt><tt>M</tt> : tensor(int32)</dt>
<dd>Constrain token_offset to integer types</dd>
</dl>


### <a name="com.microsoft.GatherBlockQuantized"></a><a name="com.microsoft.gatherblockquantized">**com.microsoft.GatherBlockQuantized**</a>

#### Version

This version of the operator has been available since version 1 of the 'com.microsoft' operator set.

#### Attributes

<dl>
<dt><tt>block_size</tt> : int</dt>
<dd>(Optional) block size used for weight quantization. It needs to be a power of 2 and not smaller than 16.</dd>
<dt><tt>gather_axis</tt> : int</dt>
<dd>(Optional) Which axis to gather on. Negative value means counting dimensions from the back. Accepted range is [-r, r-1] where r = rank(data).</dd>
<dt><tt>quantize_axis</tt> : int</dt>
<dd>(Optional) Which axis to block-wise quantize. Negative value means counting dimensions from the back. Accepted range is [-r, r-1] where r = rank(data).</dd>
</dl>

#### Inputs (3 - 4)

<dl>
<dt><tt>data</tt> : T1</dt>
<dd></dd>
<dt><tt>indices</tt> : Tind</dt>
<dd></dd>
<dt><tt>scales</tt> : T2</dt>
<dd></dd>
<dt><tt>zero_points</tt> (optional) : T1</dt>
<dd></dd>
</dl>

#### Outputs

<dl>
<dt><tt>output</tt> : T2</dt>
<dd></dd>
</dl>

#### Type Constraints

<dl>
<dt><tt>T1</tt> : tensor(int4), tensor(uint4)</dt>
<dd>Constrain quantized types.</dd>
<dt><tt>T2</tt> : tensor(float), tensor(float16), tensor(bfloat16)</dt>
<dd>Constrain dequantized types.</dd>
<dt><tt>Tind</tt> : tensor(int32), tensor(int64)</dt>
<dd>Constrain indices to integer types.</dd>
</dl>


### <a name="com.microsoft.GatherND"></a><a name="com.microsoft.gathernd">**com.microsoft.GatherND**</a>

#### Version

This version of the operator has been available since version 1 of the 'com.microsoft' operator set.

#### Inputs

<dl>
<dt><tt>data</tt> : T</dt>
<dd></dd>
<dt><tt>indices</tt> : Tind</dt>
<dd></dd>
</dl>

#### Outputs

<dl>
<dt><tt>output</tt> : T</dt>
<dd></dd>
</dl>

#### Type Constraints

<dl>
<dt><tt>T</tt> : tensor(uint8), tensor(uint16), tensor(uint32), tensor(uint64), tensor(int8), tensor(int16), tensor(int32), tensor(int64), tensor(float16), tensor(float), tensor(double), tensor(string), tensor(bool), tensor(complex64), tensor(complex128)</dt>
<dd>Constrain input and output types to any tensor type.</dd>
<dt><tt>Tind</tt> : tensor(int32), tensor(int64)</dt>
<dd>Constrain indice type to int32 or int64</dd>
</dl>


### <a name="com.microsoft.Gelu"></a><a name="com.microsoft.gelu">**com.microsoft.Gelu**</a>

#### Version

This version of the operator has been available since version 1 of the 'com.microsoft' operator set.

#### Inputs

<dl>
<dt><tt>X</tt> : T</dt>
<dd></dd>
</dl>

#### Outputs

<dl>
<dt><tt>Y</tt> : T</dt>
<dd></dd>
</dl>

#### Type Constraints

<dl>
<dt><tt>T</tt> : tensor(float16), tensor(float), tensor(double), tensor(bfloat16)</dt>
<dd>Constrain input and output types to float tensors.</dd>
</dl>


### <a name="com.microsoft.GemmFastGelu"></a><a name="com.microsoft.gemmfastgelu">**com.microsoft.GemmFastGelu**</a>

#### Version

This version of the operator has been available since version 1 of the 'com.microsoft' operator set.

#### Inputs (2 - 3)

<dl>
<dt><tt>X</tt> : T</dt>
<dd></dd>
<dt><tt>W</tt> : T</dt>
<dd></dd>
<dt><tt>bias</tt> (optional) : T</dt>
<dd></dd>
</dl>

#### Outputs

<dl>
<dt><tt>Y</tt> : T</dt>
<dd></dd>
</dl>

#### Type Constraints

<dl>
<dt><tt>T</tt> : tensor(float), tensor(float16), tensor(bfloat16)</dt>
<dd>Constrain input and output types to float or half tensors.</dd>
</dl>


### <a name="com.microsoft.GemmFloat8"></a><a name="com.microsoft.gemmfloat8">**com.microsoft.GemmFloat8**</a>

#### Version

This version of the operator has been available since version 1 of the 'com.microsoft' operator set.

#### Attributes

<dl>
<dt><tt>activation</tt> : string</dt>
<dd>Activation function, RELU or GELU or NONE (default).</dd>
<dt><tt>alpha</tt> : float</dt>
<dd>Scalar multiplier for the product of input tensors A * B.</dd>
<dt><tt>beta</tt> : float</dt>
<dd>Scalar multiplier for the product of input bias C.</dd>
<dt><tt>dtype</tt> : int</dt>
<dd>Output Type. Same definition as attribute 'to' for operator Cast.</dd>
<dt><tt>transA</tt> : int</dt>
<dd>Whether A should be transposed. Float 8 only supprted transA=0.</dd>
<dt><tt>transB</tt> : int</dt>
<dd>Whether B should be transposed. Float 8 only supprted transB=1.</dd>
</dl>

#### Inputs (2 - 6)

<dl>
<dt><tt>A</tt> : TA</dt>
<dd></dd>
<dt><tt>B</tt> : TB</dt>
<dd></dd>
<dt><tt>C</tt> (optional) : TC</dt>
<dd></dd>
<dt><tt>scaleA</tt> (optional) : TS</dt>
<dd></dd>
<dt><tt>scaleB</tt> (optional) : TS</dt>
<dd></dd>
<dt><tt>scaleY</tt> (optional) : TS</dt>
<dd></dd>
</dl>

#### Outputs

<dl>
<dt><tt>Y</tt> : TR</dt>
<dd></dd>
</dl>

#### Type Constraints

<dl>
<dt><tt>TA</tt> : tensor(float8e4m3fn), tensor(float8e5m2), tensor(float16), tensor(bfloat16), tensor(float)</dt>
<dd>Constrain type to input A.</dd>
<dt><tt>TB</tt> : tensor(float8e4m3fn), tensor(float8e5m2), tensor(float16), tensor(bfloat16), tensor(float)</dt>
<dd>Constrain type to input B.</dd>
<dt><tt>TC</tt> : tensor(float16), tensor(bfloat16), tensor(float)</dt>
<dd>Constrain type to input C.</dd>
<dt><tt>TR</tt> : tensor(float8e4m3fn), tensor(float8e5m2), tensor(float16), tensor(bfloat16), tensor(float)</dt>
<dd>Constrain type to result type.</dd>
<dt><tt>TS</tt> : tensor(float)</dt>
<dd>Constrain type for all input scales (scaleA, scaleB, scaleY).</dd>
</dl>


### <a name="com.microsoft.GemmaRotaryEmbedding"></a><a name="com.microsoft.gemmarotaryembedding">**com.microsoft.GemmaRotaryEmbedding**</a>

#### Version

This version of the operator has been available since version 1 of the 'com.microsoft' operator set.

#### Inputs

<dl>
<dt><tt>emb</tt> : U</dt>
<dd></dd>
<dt><tt>q</tt> : T</dt>
<dd></dd>
<dt><tt>q_rot</tt> : T</dt>
<dd></dd>
<dt><tt>k</tt> : T</dt>
<dd></dd>
<dt><tt>k_rot</tt> : T</dt>
<dd></dd>
</dl>

#### Outputs

<dl>
<dt><tt>output1</tt> : T</dt>
<dd></dd>
<dt><tt>output2</tt> : T</dt>
<dd></dd>
</dl>

#### Type Constraints

<dl>
<dt><tt>T</tt> : tensor(float16)</dt>
<dd>Constrain input and output types to float16 tensors.</dd>
<dt><tt>U</tt> : tensor(float)</dt>
<dd>Constrain input 0 type to float tensors</dd>
</dl>


### <a name="com.microsoft.GreedySearch"></a><a name="com.microsoft.greedysearch">**com.microsoft.GreedySearch**</a>

#### Version

This version of the operator has been available since version 1 of the 'com.microsoft' operator set.

#### Attributes

<dl>
<dt><tt>decoder</tt> : graph (required)</dt>
<dd>Decoder subgraph to execute in a loop.</dd>
<dt><tt>decoder_start_token_id</tt> : int</dt>
<dd>The id of the token that indicates decoding starts.</dd>
<dt><tt>encoder</tt> : graph</dt>
<dd>The subgraph for initialization of encoder and decoder. It will be called once before `decoder` subgraph.</dd>
<dt><tt>eos_token_id</tt> : int (required)</dt>
<dd>The id of the end-of-sequence token</dd>
<dt><tt>init_decoder</tt> : graph</dt>
<dd>The subgraph for the first decoding run. It will be called once before `decoder` subgraph. This is relevant only for the GPT2 model. If this attribute is missing, the `decoder` subgraph will be used for all decoding runs</dd>
<dt><tt>model_type</tt> : int</dt>
<dd>model type: 0 for decoder only like GPT-2; 1 for encoder decoder like Bart</dd>
<dt><tt>no_repeat_ngram_size</tt> : int</dt>
<dd>no repeat ngrams size</dd>
<dt><tt>pad_token_id</tt> : int (required)</dt>
<dd>The id of the padding token</dd>
<dt><tt>vocab_size</tt> : int</dt>
<dd>Size of the vocabulary. If not provided, it will be inferred from the decoder subgraph's output shape</dd>
</dl>

#### Inputs (2 - 7)

<dl>
<dt><tt>input_ids</tt> : I</dt>
<dd></dd>
<dt><tt>max_length</tt> : I</dt>
<dd></dd>
<dt><tt>min_length</tt> (optional) : I</dt>
<dd></dd>
<dt><tt>repetition_penalty</tt> (optional) : T</dt>
<dd></dd>
<dt><tt>vocab_mask</tt> (optional) : I</dt>
<dd></dd>
<dt><tt>prefix_vocab_mask</tt> (optional) : I</dt>
<dd></dd>
<dt><tt>attention_mask</tt> (optional) : I</dt>
<dd></dd>
</dl>

#### Outputs

<dl>
<dt><tt>sequences</tt> : I</dt>
<dd></dd>
</dl>

#### Type Constraints

<dl>
<dt><tt>T</tt> : tensor(float)</dt>
<dd>Constrain input and output types to float tensors.</dd>
<dt><tt>I</tt> : tensor(int32)</dt>
<dd>Constrain to integer types</dd>
</dl>


### <a name="com.microsoft.GridSample"></a><a name="com.microsoft.gridsample">**com.microsoft.GridSample**</a>

#### Version

This version of the operator has been available since version 1 of the 'com.microsoft' operator set.

#### Attributes

<dl>
<dt><tt>align_corners</tt> : int</dt>
<dd>If align_corners=1, the extrema (-1 and 1) are considered as referring to the center points of the input's corner pixels. If align_corners=0, they are instead considered as referring to the corner points of the input's corner pixels, making the sampling more resolution agnostic.</dd>
<dt><tt>mode</tt> : string</dt>
<dd>Three interpolation modes: bilinear (default), nearest and bicubic.</dd>
<dt><tt>padding_mode</tt> : string</dt>
<dd>Support padding modes for outside grid values: `zeros`(default), `border`, `reflection`. zeros: use 0 for out-of-bound grid locations, border: use border values for out-of-bound grid locations, reflection: use values at locations reflected by the border for out-of-bound grid locations.</dd>
</dl>

#### Inputs

<dl>
<dt><tt>X</tt> : T1</dt>
<dd></dd>
<dt><tt>Grid</tt> : T1</dt>
<dd></dd>
</dl>

#### Outputs

<dl>
<dt><tt>Y</tt> : T2</dt>
<dd></dd>
</dl>

#### Type Constraints

<dl>
<dt><tt>T1</tt> : tensor(uint8), tensor(uint16), tensor(uint32), tensor(uint64), tensor(int8), tensor(int16), tensor(int32), tensor(int64), tensor(float16), tensor(float), tensor(double), tensor(string), tensor(bool), tensor(complex64), tensor(complex128)</dt>
<dd>Constrain input types to all tensor types.</dd>
<dt><tt>T2</tt> : tensor(float16), tensor(float), tensor(double)</dt>
<dd>Constrain output types to float tensors.</dd>
</dl>


### <a name="com.microsoft.GroupNorm"></a><a name="com.microsoft.groupnorm">**com.microsoft.GroupNorm**</a>

#### Version

This version of the operator has been available since version 1 of the 'com.microsoft' operator set.

#### Attributes

<dl>
<dt><tt>activation</tt> : int (required)</dt>
<dd>Activation after group normalization: 0 for None, 1 for SiLU</dd>
<dt><tt>channels_last</tt> : int</dt>
<dd>1 if the input and output are in the NHWC layout, 0 if it is in the NCHW layout. Defaults to 1.</dd>
<dt><tt>epsilon</tt> : float</dt>
<dd>The epsilon value to use to avoid division by zero</dd>
<dt><tt>groups</tt> : int (required)</dt>
<dd>The number of groups of channels. It should be a divisor of the number of channels C</dd>
</dl>

#### Inputs

<dl>
<dt><tt>X</tt> : T</dt>
<dd></dd>
<dt><tt>gamma</tt> : M</dt>
<dd></dd>
<dt><tt>beta</tt> : M</dt>
<dd></dd>
</dl>

#### Outputs

<dl>
<dt><tt>Y</tt> : T</dt>
<dd></dd>
</dl>

#### Type Constraints

<dl>
<dt><tt>T</tt> : tensor(float16), tensor(float)</dt>
<dd>Constrain input X and output Y types to float tensors.</dd>
<dt><tt>M</tt> : tensor(float16), tensor(float)</dt>
<dd>Constrain gamma and beta to float tensors.</dd>
</dl>


### <a name="com.microsoft.GroupQueryAttention"></a><a name="com.microsoft.groupqueryattention">**com.microsoft.GroupQueryAttention**</a>

#### Version

This version of the operator has been available since version 1 of the 'com.microsoft' operator set.

#### Attributes

<dl>
<dt><tt>do_rotary</tt> : int</dt>
<dd>Whether to use rotary position embedding. Default value is 0.</dd>
<dt><tt>kv_num_heads</tt> : int (required)</dt>
<dd>Number of attention heads for k and v</dd>
<dt><tt>local_window_size</tt> : int</dt>
<dd>left_window_size for local attention (like Mistral). Default value is -1 meaning unused.</dd>
<dt><tt>num_heads</tt> : int (required)</dt>
<dd>Number of attention heads for q</dd>
<dt><tt>rotary_interleaved</tt> : int</dt>
<dd>Rotate using interleaved pattern. Default value is 0 (False).</dd>
<dt><tt>scale</tt> : float</dt>
<dd>Custom scale will be used if specified. Default value is 1/sqrt(head_size)</dd>
<dt><tt>smooth_softmax</tt> : int</dt>
<dd>Use a smooth factor in softmax.</dd>
<dt><tt>softcap</tt> : float</dt>
<dd>Softcap value for attention weights. Default value is 0.</dd>
</dl>

#### Inputs (7 - 9)

<dl>
<dt><tt>query</tt> : T</dt>
<dd></dd>
<dt><tt>key</tt> (optional) : T</dt>
<dd></dd>
<dt><tt>value</tt> (optional) : T</dt>
<dd></dd>
<dt><tt>past_key</tt> (optional) : T</dt>
<dd></dd>
<dt><tt>past_value</tt> (optional) : T</dt>
<dd></dd>
<dt><tt>seqlens_k</tt> : M</dt>
<dd></dd>
<dt><tt>total_sequence_length</tt> : M</dt>
<dd></dd>
<dt><tt>cos_cache</tt> (optional) : T</dt>
<dd></dd>
<dt><tt>sin_cache</tt> (optional) : T</dt>
<dd></dd>
</dl>

#### Outputs

<dl>
<dt><tt>output</tt> : T</dt>
<dd></dd>
<dt><tt>present_key</tt> : T</dt>
<dd></dd>
<dt><tt>present_value</tt> : T</dt>
<dd></dd>
</dl>

#### Type Constraints

<dl>
<dt><tt>T</tt> : tensor(float16), tensor(bfloat16), tensor(float)</dt>
<dd>Constrain input and output to float tensors.</dd>
<dt><tt>M</tt> : tensor(int32)</dt>
<dd>Constrain mask to int tensor.</dd>
</dl>


### <a name="com.microsoft.Inverse"></a><a name="com.microsoft.inverse">**com.microsoft.Inverse**</a>

#### Version

This version of the operator has been available since version 1 of the 'com.microsoft' operator set.

#### Inputs

<dl>
<dt><tt>X</tt> : T</dt>
<dd></dd>
</dl>

#### Outputs

<dl>
<dt><tt>Y</tt> : T</dt>
<dd></dd>
</dl>

#### Type Constraints

<dl>
<dt><tt>T</tt> : tensor(float16), tensor(float), tensor(double)</dt>
<dd>Constrain input and output types to float tensors.</dd>
</dl>


### <a name="com.microsoft.Irfft"></a><a name="com.microsoft.irfft">**com.microsoft.Irfft**</a>

#### Version

This version of the operator has been available since version 1 of the 'com.microsoft' operator set.

#### Attributes

<dl>
<dt><tt>normalized</tt> : int</dt>
<dd>must be 0, normalization currently not supported</dd>
<dt><tt>onesided</tt> : int</dt>
<dd>must be 1, only one sided FFTs supported</dd>
<dt><tt>signal_ndim</tt> : int (required)</dt>
<dd>number of dimensions comprising the signal</dd>
</dl>

#### Inputs

<dl>
<dt><tt>X</tt> : T</dt>
<dd></dd>
</dl>

#### Outputs

<dl>
<dt><tt>Y</tt> : T</dt>
<dd></dd>
</dl>

#### Type Constraints

<dl>
<dt><tt>T</tt> : tensor(float), tensor(double), tensor(float16)</dt>
<dd>Constrain input and output types to float or half tensors.</dd>
</dl>


### <a name="com.microsoft.LongformerAttention"></a><a name="com.microsoft.longformerattention">**com.microsoft.LongformerAttention**</a>

#### Version

This version of the operator has been available since version 1 of the 'com.microsoft' operator set.

#### Attributes

<dl>
<dt><tt>num_heads</tt> : int (required)</dt>
<dd>Number of attention heads</dd>
<dt><tt>window</tt> : int (required)</dt>
<dd>One sided attention windows length W, or half of total window length</dd>
</dl>

#### Inputs

<dl>
<dt><tt>input</tt> : T</dt>
<dd></dd>
<dt><tt>weight</tt> : T</dt>
<dd></dd>
<dt><tt>bias</tt> : T</dt>
<dd></dd>
<dt><tt>mask</tt> : T</dt>
<dd></dd>
<dt><tt>global_weight</tt> : T</dt>
<dd></dd>
<dt><tt>global_bias</tt> : T</dt>
<dd></dd>
<dt><tt>global</tt> : G</dt>
<dd></dd>
</dl>

#### Outputs

<dl>
<dt><tt>output</tt> : T</dt>
<dd></dd>
</dl>

#### Type Constraints

<dl>
<dt><tt>T</tt> : tensor(float), tensor(float16)</dt>
<dd>Constrain input and output types to float tensors.</dd>
<dt><tt>G</tt> : tensor(int32)</dt>
<dd>Constrain to integer types</dd>
</dl>


### <a name="com.microsoft.MatMulBnb4"></a><a name="com.microsoft.matmulbnb4">**com.microsoft.MatMulBnb4**</a>

#### Version

This version of the operator has been available since version 1 of the 'com.microsoft' operator set.

#### Attributes

<dl>
<dt><tt>K</tt> : int (required)</dt>
<dd>size of each input feature</dd>
<dt><tt>N</tt> : int (required)</dt>
<dd>size of each output feature</dd>
<dt><tt>block_size</tt> : int (required)</dt>
<dd>number of groupsize used for weight quantization. It needs to be a power of 2 and not smaller than 16.</dd>
<dt><tt>quant_type</tt> : int (required)</dt>
<dd>quantization data type. 0 for FP4, 1 for NF4.</dd>
<dt><tt>training_mode</tt> : int</dt>
<dd>Indicate if the ops run in training_mode, by default, False.</dd>
<dt><tt>transB</tt> : int</dt>
<dd>Whether B should be transposed on the last two dimensions before doing multiplication. Default to be 1.</dd>
</dl>

#### Inputs

<dl>
<dt><tt>A</tt> : T1</dt>
<dd></dd>
<dt><tt>B</tt> : T2</dt>
<dd></dd>
<dt><tt>absmax</tt> : T1</dt>
<dd></dd>
</dl>

#### Outputs

<dl>
<dt><tt>Y</tt> : T1</dt>
<dd></dd>
</dl>

#### Type Constraints

<dl>
<dt><tt>T1</tt> : tensor(float), tensor(float16), tensor(bfloat16)</dt>
<dd>Constrain input and output types to float/half_float/brain_float tensors.</dd>
<dt><tt>T2</tt> : tensor(uint8)</dt>
<dd>Constrain quantized weight types to uint8.</dd>
</dl>


### <a name="com.microsoft.MatMulFpQ4"></a><a name="com.microsoft.matmulfpq4">**com.microsoft.MatMulFpQ4**</a>

#### Version

This version of the operator has been available since version 1 of the 'com.microsoft' operator set.

#### Attributes

<dl>
<dt><tt>blk_quant_type</tt> : int</dt>
<dd>Quantization type</dd>
</dl>

#### Inputs

<dl>
<dt><tt>A</tt> : T1</dt>
<dd></dd>
<dt><tt>B</tt> : T2</dt>
<dd></dd>
<dt><tt>B_shape</tt> : T3</dt>
<dd></dd>
</dl>

#### Outputs

<dl>
<dt><tt>Y</tt> : T1</dt>
<dd></dd>
</dl>

#### Type Constraints

<dl>
<dt><tt>T1</tt> : tensor(float)</dt>
<dd>Constrain input matrix data types as single precision float tensor</dd>
<dt><tt>T2</tt> : tensor(uint8)</dt>
<dd>Constrain input B data types as data blob</dd>
<dt><tt>T3</tt> : tensor(int64)</dt>
<dd>Constrain shape of B must be int64 tensor.</dd>
</dl>


### <a name="com.microsoft.MatMulInteger16"></a><a name="com.microsoft.matmulinteger16">**com.microsoft.MatMulInteger16**</a>

#### Version

This version of the operator has been available since version 1 of the 'com.microsoft' operator set.

#### Inputs

<dl>
<dt><tt>A</tt> : T1</dt>
<dd></dd>
<dt><tt>B</tt> : T2</dt>
<dd></dd>
</dl>

#### Outputs

<dl>
<dt><tt>Y</tt> : T3</dt>
<dd></dd>
</dl>

#### Type Constraints

<dl>
<dt><tt>T1</tt> : tensor(int16), tensor(uint16)</dt>
<dd>Constrain input A data types as 16-bit integer tensor</dd>
<dt><tt>T2</tt> : tensor(int16), tensor(uint16)</dt>
<dd>Constrain input B data types as 16-bit integer tensor</dd>
<dt><tt>T3</tt> : tensor(int32), tensor(uint32)</dt>
<dd>Constrain output Y data types as 32-bit integer tensor.T3 must be tensor(uint32) when both T1 and T2 are tensor(uint16),or must be tensor(int32) when either T1 or T2 is tensor(int16).</dd>
</dl>


### <a name="com.microsoft.MatMulIntegerToFloat"></a><a name="com.microsoft.matmulintegertofloat">**com.microsoft.MatMulIntegerToFloat**</a>

#### Version

This version of the operator has been available since version 1 of the 'com.microsoft' operator set.

#### Inputs (4 - 7)

<dl>
<dt><tt>A</tt> : T1</dt>
<dd></dd>
<dt><tt>B</tt> : T2</dt>
<dd></dd>
<dt><tt>a_scale</tt> : T3</dt>
<dd></dd>
<dt><tt>b_scale</tt> : T3</dt>
<dd></dd>
<dt><tt>a_zero_point</tt> (optional) : T1</dt>
<dd></dd>
<dt><tt>b_zero_point</tt> (optional) : T2</dt>
<dd></dd>
<dt><tt>bias</tt> (optional) : T3</dt>
<dd></dd>
</dl>

#### Outputs

<dl>
<dt><tt>Y</tt> : T3</dt>
<dd></dd>
</dl>

#### Type Constraints

<dl>
<dt><tt>T1</tt> : tensor(int8), tensor(uint8)</dt>
<dd>Constrain input A data type to 8-bit integer tensor.</dd>
<dt><tt>T2</tt> : tensor(int8), tensor(uint8)</dt>
<dd>Constrain input B data type to 8-bit integer tensor.</dd>
<dt><tt>T3</tt> : tensor(float), tensor(float16)</dt>
<dd>Constrain input a_scale, b_scale and output Y data type as float tensor.</dd>
</dl>


### <a name="com.microsoft.MatMulNBits"></a><a name="com.microsoft.matmulnbits">**com.microsoft.MatMulNBits**</a>

#### Version

This version of the operator has been available since version 1 of the 'com.microsoft' operator set.

#### Attributes

<dl>
<dt><tt>K</tt> : int (required)</dt>
<dd>size of each input feature</dd>
<dt><tt>N</tt> : int (required)</dt>
<dd>size of each output feature</dd>
<dt><tt>accuracy_level</tt> : int</dt>
<dd>The minimum accuracy level of input A, can be: 0(unset), 1(fp32), 2(fp16), 3(bf16), or 4(int8) (default unset). It is used to control how input A is quantized or downcast internally while doing computation, for example: 0 means input A will not be quantized or downcast while doing computation. 4 means input A can be quantized with the same block_size to int8 internally from type T1.</dd>
<dt><tt>bits</tt> : int (required)</dt>
<dd>number of bits used for weight quantization (default 4)</dd>
<dt><tt>block_size</tt> : int (required)</dt>
<dd>number of groupsize used for weight quantization,(default 128). It needs to be a power of 2 and not smaller than 16.</dd>
</dl>

#### Inputs (3 - 6)

<dl>
<dt><tt>A</tt> : T1</dt>
<dd></dd>
<dt><tt>B</tt> : T2</dt>
<dd></dd>
<dt><tt>scales</tt> : T1</dt>
<dd></dd>
<dt><tt>zero_points</tt> (optional) : T3</dt>
<dd></dd>
<dt><tt>g_idx</tt> (optional) : T4</dt>
<dd></dd>
<dt><tt>bias</tt> (optional) : T1</dt>
<dd></dd>
</dl>

#### Outputs

<dl>
<dt><tt>Y</tt> : T1</dt>
<dd></dd>
</dl>

#### Type Constraints

<dl>
<dt><tt>T1</tt> : tensor(float), tensor(float16)</dt>
<dd>Constrain input and output types to float/half_float tensors.</dd>
<dt><tt>T2</tt> : tensor(uint8), tensor(int32)</dt>
<dd>Constrain quantized weight types to uint8/int32.</dd>
<dt><tt>T3</tt> : tensor(uint8), tensor(int32), tensor(float16), tensor(float)</dt>
<dd>Constrain quantized zero point types to uint8/int32/float16/float.</dd>
<dt><tt>T4</tt> : tensor(int32)</dt>
<dd>the index tensor.</dd>
</dl>


### <a name="com.microsoft.MaxpoolWithMask"></a><a name="com.microsoft.maxpoolwithmask">**com.microsoft.MaxpoolWithMask**</a>

#### Version

This version of the operator has been available since version 1 of the 'com.microsoft' operator set.

#### Attributes

<dl>
<dt><tt>auto_pad</tt> : string</dt>
<dd></dd>
<dt><tt>kernel_shape</tt> : list of ints</dt>
<dd></dd>
<dt><tt>pads</tt> : list of ints</dt>
<dd></dd>
<dt><tt>storage_order</tt> : int</dt>
<dd></dd>
<dt><tt>strides</tt> : list of ints</dt>
<dd></dd>
</dl>

#### Inputs

<dl>
<dt><tt>X</tt> : T</dt>
<dd></dd>
<dt><tt>M</tt> : tensor(int32)</dt>
<dd></dd>
</dl>

#### Outputs

<dl>
<dt><tt>Y</tt> : T</dt>
<dd></dd>
</dl>

#### Type Constraints

<dl>
<dt><tt>T</tt> : tensor(float)</dt>
<dd>Constrain input0 and output types to float tensors</dd>
</dl>


### <a name="com.microsoft.MoE"></a><a name="com.microsoft.moe">**com.microsoft.MoE**</a>

#### Version

This version of the operator has been available since version 1 of the 'com.microsoft' operator set.

#### Attributes

<dl>
<dt><tt>activation_type</tt> : string</dt>
<dd>Activation function to use. Choose from relu, gelu, silu and identity. Default is relu</dd>
<dt><tt>k</tt> : int</dt>
<dd>Number of top experts to select from expert pool</dd>
<dt><tt>normalize_routing_weights</tt> : int</dt>
<dd>Whether to normalize routing weights</dd>
<dt><tt>use_sparse_mixer</tt> : int</dt>
<dd>Whether to use sparse mixer</dd>
</dl>

#### Inputs (5 - 8)

<dl>
<dt><tt>input</tt> : T</dt>
<dd></dd>
<dt><tt>router_probs</tt> : T</dt>
<dd></dd>
<dt><tt>fc1_experts_weights</tt> : T</dt>
<dd></dd>
<dt><tt>fc1_experts_bias</tt> (optional) : T</dt>
<dd></dd>
<dt><tt>fc2_experts_weights</tt> : T</dt>
<dd></dd>
<dt><tt>fc2_experts_bias</tt> (optional) : T</dt>
<dd></dd>
<dt><tt>fc3_experts_weights</tt> (optional) : T</dt>
<dd></dd>
<dt><tt>fc3_experts_bias</tt> (optional) : T</dt>
<dd></dd>
</dl>

#### Outputs

<dl>
<dt><tt>output</tt> : T</dt>
<dd></dd>
</dl>

#### Type Constraints

<dl>
<dt><tt>T</tt> : tensor(float), tensor(float16)</dt>
<dd>Constrain input and output types to float or float16 tensors.</dd>
</dl>


### <a name="com.microsoft.MulInteger"></a><a name="com.microsoft.mulinteger">**com.microsoft.MulInteger**</a>

#### Version

This version of the operator has been available since version 1 of the 'com.microsoft' operator set.

#### Inputs (3 - 4)

<dl>
<dt><tt>A</tt> : T</dt>
<dd></dd>
<dt><tt>A_zero_point</tt> (optional) : T</dt>
<dd></dd>
<dt><tt>B</tt> : T</dt>
<dd></dd>
<dt><tt>B_zero_point</tt> (optional) : T</dt>
<dd></dd>
</dl>

#### Outputs

<dl>
<dt><tt>C</tt> : T1</dt>
<dd></dd>
</dl>

#### Type Constraints

<dl>
<dt><tt>T</tt> : tensor(uint8), tensor(int8)</dt>
<dd>Constrain input types to 8 bit signed and unsigned tensors.</dd>
<dt><tt>T1</tt> : tensor(int32)</dt>
<dd>Constrain output types to 32 bit tensors.</dd>
</dl>


### <a name="com.microsoft.MultiHeadAttention"></a><a name="com.microsoft.multiheadattention">**com.microsoft.MultiHeadAttention**</a>

#### Version

This version of the operator has been available since version 1 of the 'com.microsoft' operator set.

#### Attributes

<dl>
<dt><tt>mask_filter_value</tt> : float</dt>
<dd>The value to be filled in the attention mask. Default value is -10000.0f</dd>
<dt><tt>num_heads</tt> : int (required)</dt>
<dd>Number of attention heads</dd>
<dt><tt>scale</tt> : float</dt>
<dd>Custom scale will be used if specified. Default value is 1/sqrt(head_size)</dd>
<dt><tt>unidirectional</tt> : int</dt>
<dd>Whether every token can only attend to previous tokens. Default value is 0.</dd>
</dl>

#### Inputs (1 - 8)

<dl>
<dt><tt>query</tt> : T</dt>
<dd></dd>
<dt><tt>key</tt> (optional) : T</dt>
<dd></dd>
<dt><tt>value</tt> (optional) : T</dt>
<dd></dd>
<dt><tt>bias</tt> (optional) : T</dt>
<dd></dd>
<dt><tt>key_padding_mask</tt> (optional) : M</dt>
<dd></dd>
<dt><tt>attention_bias</tt> (optional) : T</dt>
<dd></dd>
<dt><tt>past_key</tt> (optional) : T</dt>
<dd></dd>
<dt><tt>past_value</tt> (optional) : T</dt>
<dd></dd>
</dl>

#### Outputs (1 - 3)

<dl>
<dt><tt>output</tt> : T</dt>
<dd></dd>
<dt><tt>present_key</tt> (optional) : T</dt>
<dd></dd>
<dt><tt>present_value</tt> (optional) : T</dt>
<dd></dd>
</dl>

#### Type Constraints

<dl>
<dt><tt>T</tt> : tensor(float), tensor(float16)</dt>
<dd>Constrain input and output to float tensors.</dd>
<dt><tt>M</tt> : tensor(int32)</dt>
<dd>Constrain mask to integer types</dd>
</dl>


### <a name="com.microsoft.MurmurHash3"></a><a name="com.microsoft.murmurhash3">**com.microsoft.MurmurHash3**</a>

#### Version

This version of the operator has been available since version 1 of the 'com.microsoft' operator set.

#### Attributes

<dl>
<dt><tt>positive</tt> : int</dt>
<dd>If value is 1, output type is uint32_t, else int32_t. Default value is 1.</dd>
<dt><tt>seed</tt> : int</dt>
<dd>Seed for the hashing algorithm, unsigned 32-bit integer, default to 0.</dd>
</dl>

#### Inputs

<dl>
<dt><tt>X</tt> : T1</dt>
<dd></dd>
</dl>

#### Outputs

<dl>
<dt><tt>Y</tt> : T2</dt>
<dd></dd>
</dl>

#### Type Constraints

<dl>
<dt><tt>T1</tt> : tensor(uint32), tensor(int32), tensor(uint64), tensor(int64), tensor(float), tensor(double), tensor(string)</dt>
<dd>Constrain input type to unsigned or signed 32-bit integer tensor, or string tensor. It should be utf-8 encoded if using unicode.</dd>
<dt><tt>T2</tt> : tensor(uint32), tensor(int32)</dt>
<dd>Constrain output type to unsigned and signed 32-bit integer tensor.</dd>
</dl>


### <a name="com.microsoft.NGramRepeatBlock"></a><a name="com.microsoft.ngramrepeatblock">**com.microsoft.NGramRepeatBlock**</a>

#### Version

This version of the operator has been available since version 1 of the 'com.microsoft' operator set.

#### Attributes

<dl>
<dt><tt>ngram_size</tt> : int (required)</dt>
<dd>The NGram size.</dd>
</dl>

#### Inputs

<dl>
<dt><tt>input_ids</tt> : Tid</dt>
<dd></dd>
<dt><tt>scores</tt> : T</dt>
<dd></dd>
</dl>

#### Outputs

<dl>
<dt><tt>scores_out</tt> : T</dt>
<dd></dd>
</dl>

#### Type Constraints

<dl>
<dt><tt>Tid</tt> : tensor(int64)</dt>
<dd>Constrain indices to integer types</dd>
<dt><tt>T</tt> : tensor(float)</dt>
<dd>Constrain scores input and output types to float tensors.</dd>
</dl>


### <a name="com.microsoft.NhwcConv"></a><a name="com.microsoft.nhwcconv">**com.microsoft.NhwcConv**</a>

#### Version

This version of the operator has been available since version 1 of the 'com.microsoft' operator set.

#### Attributes

<dl>
<dt><tt>auto_pad</tt> : string</dt>
<dd></dd>
<dt><tt>dilations</tt> : list of ints</dt>
<dd>dilation value along each spatial axis of the filter. If not present, the dilation defaults is 1 along each spatial axis.</dd>
<dt><tt>group</tt> : int</dt>
<dd>number of groups input channels and output channels are divided into.</dd>
<dt><tt>kernel_shape</tt> : list of ints</dt>
<dd>The shape of the convolution kernel. If not present, should be inferred from input W.</dd>
<dt><tt>pads</tt> : list of ints</dt>
<dd></dd>
<dt><tt>strides</tt> : list of ints</dt>
<dd>Stride along each spatial axis. If not present, the stride defaults is 1 along each spatial axis.</dd>
</dl>

#### Inputs (2 - 3)

<dl>
<dt><tt>X</tt> : T</dt>
<dd></dd>
<dt><tt>W</tt> : T</dt>
<dd></dd>
<dt><tt>B</tt> (optional) : T</dt>
<dd></dd>
</dl>

#### Outputs

<dl>
<dt><tt>Y</tt> : T</dt>
<dd></dd>
</dl>

#### Type Constraints

<dl>
<dt><tt>T</tt> : tensor(float16), tensor(float), tensor(double)</dt>
<dd>Constrain input and output types to float tensors.</dd>
</dl>


### <a name="com.microsoft.NhwcFusedConv"></a><a name="com.microsoft.nhwcfusedconv">**com.microsoft.NhwcFusedConv**</a>

#### Version

This version of the operator has been available since version 1 of the 'com.microsoft' operator set.

#### Attributes

<dl>
<dt><tt>activation</tt> : string</dt>
<dd></dd>
<dt><tt>activation_params</tt> : list of floats</dt>
<dd></dd>
<dt><tt>auto_pad</tt> : string</dt>
<dd></dd>
<dt><tt>dilations</tt> : list of ints</dt>
<dd></dd>
<dt><tt>group</tt> : int</dt>
<dd></dd>
<dt><tt>kernel_shape</tt> : list of ints</dt>
<dd></dd>
<dt><tt>pads</tt> : list of ints</dt>
<dd></dd>
<dt><tt>strides</tt> : list of ints</dt>
<dd></dd>
</dl>

#### Inputs (2 - 4)

<dl>
<dt><tt>X</tt> : T</dt>
<dd></dd>
<dt><tt>W</tt> : T</dt>
<dd></dd>
<dt><tt>B</tt> (optional) : T</dt>
<dd></dd>
<dt><tt>Z</tt> (optional) : T</dt>
<dd></dd>
</dl>

#### Outputs

<dl>
<dt><tt>Y</tt> : T</dt>
<dd></dd>
</dl>

#### Type Constraints

<dl>
<dt><tt>T</tt> : tensor(float16)</dt>
<dd>Constrain input and output types to float tensors</dd>
</dl>


### <a name="com.microsoft.NhwcMaxPool"></a><a name="com.microsoft.nhwcmaxpool">**com.microsoft.NhwcMaxPool**</a>

#### Version

This version of the operator has been available since version 1 of the 'com.microsoft' operator set.

#### Attributes

<dl>
<dt><tt>auto_pad</tt> : string</dt>
<dd></dd>
<dt><tt>ceil_mode</tt> : int</dt>
<dd></dd>
<dt><tt>dilations</tt> : list of ints</dt>
<dd></dd>
<dt><tt>kernel_shape</tt> : list of ints (required)</dt>
<dd></dd>
<dt><tt>pads</tt> : list of ints</dt>
<dd></dd>
<dt><tt>strides</tt> : list of ints</dt>
<dd></dd>
</dl>

#### Inputs

<dl>
<dt><tt>x</tt> : T</dt>
<dd></dd>
</dl>

#### Outputs

<dl>
<dt><tt>y</tt> : T</dt>
<dd></dd>
</dl>

#### Type Constraints

<dl>
<dt><tt>T</tt> : tensor(int8), tensor(uint8)</dt>
<dd></dd>
</dl>


### <a name="com.microsoft.PackedAttention"></a><a name="com.microsoft.packedattention">**com.microsoft.PackedAttention**</a>

#### Version

This version of the operator has been available since version 1 of the 'com.microsoft' operator set.

#### Attributes

<dl>
<dt><tt>num_heads</tt> : int (required)</dt>
<dd>Number of attention heads</dd>
<dt><tt>qkv_hidden_sizes</tt> : list of ints</dt>
<dd>Hidden dimension of Q, K, V: hidden_size, hidden_size and v_hidden_size</dd>
<dt><tt>scale</tt> : float</dt>
<dd>Custom scale will be used if specified. Default value is 1/sqrt(head_size)</dd>
</dl>

#### Inputs (5 - 6)

<dl>
<dt><tt>input</tt> : T</dt>
<dd></dd>
<dt><tt>weights</tt> : T</dt>
<dd></dd>
<dt><tt>bias</tt> : T</dt>
<dd></dd>
<dt><tt>token_offset</tt> : M</dt>
<dd></dd>
<dt><tt>cumulative_sequence_length</tt> : M</dt>
<dd></dd>
<dt><tt>attention_bias</tt> (optional) : T</dt>
<dd></dd>
</dl>

#### Outputs

<dl>
<dt><tt>output</tt> : T</dt>
<dd></dd>
</dl>

#### Type Constraints

<dl>
<dt><tt>T</tt> : tensor(float), tensor(float16)</dt>
<dd>Constrain input and output types to float tensors.</dd>
<dt><tt>M</tt> : tensor(int32)</dt>
<dd>Constrain mask index to integer types</dd>
</dl>


### <a name="com.microsoft.PackedMultiHeadAttention"></a><a name="com.microsoft.packedmultiheadattention">**com.microsoft.PackedMultiHeadAttention**</a>

#### Version

This version of the operator has been available since version 1 of the 'com.microsoft' operator set.

#### Attributes

<dl>
<dt><tt>mask_filter_value</tt> : float</dt>
<dd>The value to be filled in the attention mask. Default value is -10000.0f</dd>
<dt><tt>num_heads</tt> : int (required)</dt>
<dd>Number of attention heads</dd>
<dt><tt>scale</tt> : float</dt>
<dd>Custom scale will be used if specified. Default value is 1/sqrt(head_size)</dd>
</dl>

#### Inputs (6 - 7)

<dl>
<dt><tt>query</tt> : T</dt>
<dd></dd>
<dt><tt>key</tt> (optional) : T</dt>
<dd></dd>
<dt><tt>value</tt> (optional) : T</dt>
<dd></dd>
<dt><tt>bias</tt> (optional) : T</dt>
<dd></dd>
<dt><tt>token_offset</tt> : M</dt>
<dd></dd>
<dt><tt>cumulative_sequence_length</tt> : M</dt>
<dd></dd>
<dt><tt>attention_bias</tt> (optional) : T</dt>
<dd></dd>
</dl>

#### Outputs

<dl>
<dt><tt>output</tt> : T</dt>
<dd></dd>
</dl>

#### Type Constraints

<dl>
<dt><tt>T</tt> : tensor(float), tensor(float16)</dt>
<dd>Constrain input and output to float tensors.</dd>
<dt><tt>M</tt> : tensor(int32)</dt>
<dd>Constrain mask, offset and sequence length to integer types</dd>
</dl>


### <a name="com.microsoft.Pad"></a><a name="com.microsoft.pad">**com.microsoft.Pad**</a>

#### Version

This version of the operator has been available since version 1 of the 'com.microsoft' operator set.

#### Attributes

<dl>
<dt><tt>mode</tt> : string</dt>
<dd>Three modes: `constant`(default) - pads with a given constant value, `reflect` - pads with the reflection of the vector mirrored on the first and last values of the vector along each axis, `edge` - pads with the edge values of array</dd>
</dl>

#### Inputs (2 - 3)

<dl>
<dt><tt>data</tt> : T</dt>
<dd></dd>
<dt><tt>pads</tt> : tensor(int64)</dt>
<dd></dd>
<dt><tt>value</tt> (optional) : T</dt>
<dd></dd>
</dl>

#### Outputs

<dl>
<dt><tt>output</tt> : T</dt>
<dd></dd>
</dl>

#### Type Constraints

<dl>
<dt><tt>T</tt> : tensor(float16), tensor(float), tensor(double)</dt>
<dd>Constrain input and output types to float tensors.</dd>
</dl>


### <a name="com.microsoft.QAttention"></a><a name="com.microsoft.qattention">**com.microsoft.QAttention**</a>

#### Version

This version of the operator has been available since version 1 of the 'com.microsoft' operator set.

#### Attributes

<dl>
<dt><tt>do_rotary</tt> : int</dt>
<dd>Whether to use rotary position embedding. Default value is 0.</dd>
<dt><tt>mask_filter_value</tt> : float</dt>
<dd>The value to be filled in the attention mask. Default value is -10000.0f</dd>
<dt><tt>num_heads</tt> : int (required)</dt>
<dd>Number of attention heads</dd>
<dt><tt>past_present_share_buffer</tt> : int</dt>
<dd>Corresponding past and present are same tensor, its shape is (2, batch_size, num_heads, max_sequence_length, head_size)</dd>
<dt><tt>scale</tt> : float</dt>
<dd>Custom scale will be used if specified. Default value is 1/sqrt(head_size)</dd>
<dt><tt>unidirectional</tt> : int</dt>
<dd>Whether every token can only attend to previous tokens. Default value is 0.</dd>
</dl>

#### Inputs (5 - 9)

<dl>
<dt><tt>input</tt> : T1</dt>
<dd></dd>
<dt><tt>weight</tt> : T2</dt>
<dd></dd>
<dt><tt>bias</tt> : T3</dt>
<dd></dd>
<dt><tt>input_scale</tt> : T3</dt>
<dd></dd>
<dt><tt>weight_scale</tt> : T3</dt>
<dd></dd>
<dt><tt>mask_index</tt> (optional) : T4</dt>
<dd></dd>
<dt><tt>input_zero_point</tt> (optional) : T1</dt>
<dd></dd>
<dt><tt>weight_zero_point</tt> (optional) : T2</dt>
<dd></dd>
<dt><tt>past</tt> (optional) : T3</dt>
<dd></dd>
</dl>

#### Outputs (1 - 2)

<dl>
<dt><tt>output</tt> : T3</dt>
<dd></dd>
<dt><tt>present</tt> (optional) : T3</dt>
<dd></dd>
</dl>

#### Type Constraints

<dl>
<dt><tt>T1</tt> : tensor(int8), tensor(uint8)</dt>
<dd>Constrain input and output types to int8 tensors.</dd>
<dt><tt>T2</tt> : tensor(int8), tensor(uint8)</dt>
<dd>Constrain input and output types to int8 tensors.</dd>
<dt><tt>T3</tt> : tensor(float), tensor(float16)</dt>
<dd>Constrain input and output types to float tensors.</dd>
<dt><tt>T4</tt> : tensor(int32)</dt>
<dd>Constrain mask index to integer types</dd>
</dl>


### <a name="com.microsoft.QGemm"></a><a name="com.microsoft.qgemm">**com.microsoft.QGemm**</a>

#### Version

This version of the operator has been available since version 1 of the 'com.microsoft' operator set.

#### Attributes

<dl>
<dt><tt>alpha</tt> : float</dt>
<dd>Scalar multiplier for the product of input tensors A * B.</dd>
<dt><tt>transA</tt> : int</dt>
<dd>Whether A should be transposed</dd>
<dt><tt>transB</tt> : int</dt>
<dd>Whether B should be transposed</dd>
</dl>

#### Inputs (6 - 9)

<dl>
<dt><tt>A</tt> : TA</dt>
<dd></dd>
<dt><tt>a_scale</tt> : T</dt>
<dd></dd>
<dt><tt>a_zero_point</tt> : TA</dt>
<dd></dd>
<dt><tt>B</tt> : TB</dt>
<dd></dd>
<dt><tt>b_scale</tt> : T</dt>
<dd></dd>
<dt><tt>b_zero_point</tt> : TB</dt>
<dd></dd>
<dt><tt>C</tt> (optional) : TC</dt>
<dd></dd>
<dt><tt>y_scale</tt> (optional) : T</dt>
<dd></dd>
<dt><tt>y_zero_point</tt> (optional) : TYZ</dt>
<dd></dd>
</dl>

#### Outputs

<dl>
<dt><tt>Y</tt> : TY</dt>
<dd></dd>
</dl>

#### Type Constraints

<dl>
<dt><tt>T</tt> : tensor(float)</dt>
<dd>Constrain scale types to float tensors.</dd>
<dt><tt>TA</tt> : tensor(uint8), tensor(int8)</dt>
<dd>Constrain input A and its zero point types to 8 bit tensors.</dd>
<dt><tt>TB</tt> : tensor(uint8), tensor(int8)</dt>
<dd>Constrain input B and its zero point types to 8 bit tensors.</dd>
<dt><tt>TC</tt> : tensor(int32)</dt>
<dd>Constrain input C to 32 bit integer tensors.</dd>
<dt><tt>TYZ</tt> : tensor(uint8), tensor(int8)</dt>
<dd>Constrain output zero point types to 8 bit tensors.</dd>
<dt><tt>TY</tt> : tensor(float), tensor(uint8), tensor(int8)</dt>
<dd>Constrain output type to float32 or 8 bit tensors.</dd>
</dl>


### <a name="com.microsoft.QLinearAdd"></a><a name="com.microsoft.qlinearadd">**com.microsoft.QLinearAdd**</a>

#### Version

This version of the operator has been available since version 1 of the 'com.microsoft' operator set.

#### Inputs (7 - 8)

<dl>
<dt><tt>A</tt> : T</dt>
<dd></dd>
<dt><tt>A_scale</tt> : tensor(float)</dt>
<dd></dd>
<dt><tt>A_zero_point</tt> (optional) : T</dt>
<dd></dd>
<dt><tt>B</tt> : T</dt>
<dd></dd>
<dt><tt>B_scale</tt> : tensor(float)</dt>
<dd></dd>
<dt><tt>B_zero_point</tt> (optional) : T</dt>
<dd></dd>
<dt><tt>C_scale</tt> : tensor(float)</dt>
<dd></dd>
<dt><tt>C_zero_point</tt> (optional) : T</dt>
<dd></dd>
</dl>

#### Outputs

<dl>
<dt><tt>C</tt> : T</dt>
<dd></dd>
</dl>

#### Type Constraints

<dl>
<dt><tt>T</tt> : tensor(uint8), tensor(int8)</dt>
<dd>Constrain input and output types to 8 bit signed and unsigned tensors.</dd>
</dl>


### <a name="com.microsoft.QLinearAveragePool"></a><a name="com.microsoft.qlinearaveragepool">**com.microsoft.QLinearAveragePool**</a>

#### Version

This version of the operator has been available since version 1 of the 'com.microsoft' operator set.

#### Attributes

<dl>
<dt><tt>auto_pad</tt> : string</dt>
<dd>auto_pad must be either NOTSET, SAME_UPPER, SAME_LOWER or VALID. Where default value is NOTSET, which means explicit padding is used. SAME_UPPER or SAME_LOWER mean pad the input so that the output spatial size match the input.In case of odd number add the extra padding at the end for SAME_UPPER and at the beginning for SAME_LOWER. VALID mean no padding.</dd>
<dt><tt>ceil_mode</tt> : int</dt>
<dd>Whether to use ceil or floor (default) to compute the output shape.</dd>
<dt><tt>channels_last</tt> : int</dt>
<dd>Works on NHWC layout or not? Default not.</dd>
<dt><tt>count_include_pad</tt> : int</dt>
<dd>Whether include pad pixels when calculating values for the edges. Default is 0, doesn't count include pad.</dd>
<dt><tt>kernel_shape</tt> : list of ints (required)</dt>
<dd>The size of the kernel along each axis.</dd>
<dt><tt>pads</tt> : list of ints</dt>
<dd>Padding for the beginning and ending along each spatial axis, it can take any value greater than or equal to 0. The value represent the number of pixels added to the beginning and end part of the corresponding axis. `pads` format should be as follow [x1_begin, x2_begin...x1_end, x2_end,...], where xi_begin the number of pixels added at the beginning of axis `i` and xi_end, the number of pixels added at the end of axis `i`. This attribute cannot be used simultaneously with auto_pad attribute. If not present, the padding defaults to 0 along start and end of each spatial axis.</dd>
<dt><tt>strides</tt> : list of ints</dt>
<dd>Stride along each spatial axis. If not present, the stride defaults to 1 along each spatial axis.</dd>
</dl>

#### Inputs (4 - 5)

<dl>
<dt><tt>X</tt> : T</dt>
<dd></dd>
<dt><tt>x_scale</tt> : tensor(float)</dt>
<dd></dd>
<dt><tt>x_zero_point</tt> (optional) : T</dt>
<dd></dd>
<dt><tt>y_scale</tt> : tensor(float)</dt>
<dd></dd>
<dt><tt>y_zero_point</tt> (optional) : T</dt>
<dd></dd>
</dl>

#### Outputs

<dl>
<dt><tt>Y</tt> : T</dt>
<dd></dd>
</dl>

#### Type Constraints

<dl>
<dt><tt>T</tt> : tensor(uint8), tensor(int8)</dt>
<dd>Constrain input and output types to 8 bit tensors.</dd>
</dl>


### <a name="com.microsoft.QLinearConcat"></a><a name="com.microsoft.qlinearconcat">**com.microsoft.QLinearConcat**</a>

#### Version

This version of the operator has been available since version 1 of the 'com.microsoft' operator set.

#### Attributes

<dl>
<dt><tt>axis</tt> : int (required)</dt>
<dd>Which axis to concat on</dd>
</dl>

#### Inputs (3 - &#8734;)

<dl>
<dt><tt>Y_scale</tt> : TF</dt>
<dd></dd>
<dt><tt>Y_zero_point</tt> : T8</dt>
<dd></dd>
<dt><tt>inputs</tt> (variadic, heterogeneous) : TV</dt>
<dd></dd>
</dl>

#### Outputs

<dl>
<dt><tt>Y</tt> : T8</dt>
<dd></dd>
</dl>

#### Type Constraints

<dl>
<dt><tt>T8</tt> : tensor(uint8), tensor(int8)</dt>
<dd>Constrain input and output types to 8 bit signed and unsigned tensors.</dd>
<dt><tt>TF</tt> : tensor(float)</dt>
<dd>Constrain scale types to any float tensor type.</dd>
<dt><tt>TV</tt> : tensor(uint8), tensor(int8), tensor(float)</dt>
<dd>Sequence of (Tensor, Scale, ZeroPoint) tuples. The type is sequence of (T8, TF, T8).</dd>
</dl>


### <a name="com.microsoft.QLinearConv"></a><a name="com.microsoft.qlinearconv">**com.microsoft.QLinearConv**</a>

#### Version

This version of the operator has been available since version 1 of the 'com.microsoft' operator set.

#### Attributes

<dl>
<dt><tt>auto_pad</tt> : string</dt>
<dd></dd>
<dt><tt>channels_last</tt> : int</dt>
<dd></dd>
<dt><tt>dilations</tt> : list of ints</dt>
<dd></dd>
<dt><tt>group</tt> : int</dt>
<dd></dd>
<dt><tt>kernel_shape</tt> : list of ints</dt>
<dd></dd>
<dt><tt>pads</tt> : list of ints</dt>
<dd></dd>
<dt><tt>strides</tt> : list of ints</dt>
<dd></dd>
</dl>

#### Inputs (8 - 9)

<dl>
<dt><tt>x</tt> : T1</dt>
<dd></dd>
<dt><tt>x_scale</tt> : tensor(float)</dt>
<dd></dd>
<dt><tt>x_zero_point</tt> : T1</dt>
<dd></dd>
<dt><tt>w</tt> : T2</dt>
<dd></dd>
<dt><tt>w_scale</tt> : tensor(float)</dt>
<dd></dd>
<dt><tt>w_zero_point</tt> : T2</dt>
<dd></dd>
<dt><tt>y_scale</tt> : tensor(float)</dt>
<dd></dd>
<dt><tt>y_zero_point</tt> : T3</dt>
<dd></dd>
<dt><tt>B</tt> (optional) : T4</dt>
<dd></dd>
</dl>

#### Outputs

<dl>
<dt><tt>y</tt> : T3</dt>
<dd></dd>
</dl>

#### Type Constraints

<dl>
<dt><tt>T1</tt> : tensor(int8), tensor(uint8)</dt>
<dd></dd>
<dt><tt>T2</tt> : tensor(int8), tensor(uint8)</dt>
<dd></dd>
<dt><tt>T3</tt> : tensor(int8), tensor(uint8)</dt>
<dd></dd>
<dt><tt>T4</tt> : tensor(int32)</dt>
<dd></dd>
</dl>


### <a name="com.microsoft.QLinearGlobalAveragePool"></a><a name="com.microsoft.qlinearglobalaveragepool">**com.microsoft.QLinearGlobalAveragePool**</a>

#### Version

This version of the operator has been available since version 1 of the 'com.microsoft' operator set.

#### Attributes

<dl>
<dt><tt>channels_last</tt> : int</dt>
<dd></dd>
</dl>

#### Inputs

<dl>
<dt><tt>X</tt> : T</dt>
<dd></dd>
<dt><tt>x_scale</tt> : tensor(float)</dt>
<dd></dd>
<dt><tt>x_zero_point</tt> : T</dt>
<dd></dd>
<dt><tt>y_scale</tt> : tensor(float)</dt>
<dd></dd>
<dt><tt>y_zero_point</tt> : T</dt>
<dd></dd>
</dl>

#### Outputs

<dl>
<dt><tt>Y</tt> : T</dt>
<dd></dd>
</dl>

#### Type Constraints

<dl>
<dt><tt>T</tt> : tensor(uint8), tensor(int8)</dt>
<dd>Constrain input and output types to signed/unsigned int8 tensors.</dd>
</dl>


### <a name="com.microsoft.QLinearLeakyRelu"></a><a name="com.microsoft.qlinearleakyrelu">**com.microsoft.QLinearLeakyRelu**</a>

#### Version

This version of the operator has been available since version 1 of the 'com.microsoft' operator set.

#### Attributes

<dl>
<dt><tt>alpha</tt> : float</dt>
<dd>Coefficient of leakage.</dd>
</dl>

#### Inputs (4 - 5)

<dl>
<dt><tt>X</tt> : T</dt>
<dd></dd>
<dt><tt>X_scale</tt> : tensor(float)</dt>
<dd></dd>
<dt><tt>X_zero_point</tt> (optional) : T</dt>
<dd></dd>
<dt><tt>Y_scale</tt> : tensor(float)</dt>
<dd></dd>
<dt><tt>Y_zero_point</tt> (optional) : T</dt>
<dd></dd>
</dl>

#### Outputs

<dl>
<dt><tt>Y</tt> : T</dt>
<dd></dd>
</dl>

#### Type Constraints

<dl>
<dt><tt>T</tt> : tensor(uint8), tensor(int8)</dt>
<dd>Constrain input and output types to 8 bit tensors.</dd>
</dl>


### <a name="com.microsoft.QLinearMul"></a><a name="com.microsoft.qlinearmul">**com.microsoft.QLinearMul**</a>

#### Version

This version of the operator has been available since version 1 of the 'com.microsoft' operator set.

#### Inputs (7 - 8)

<dl>
<dt><tt>A</tt> : T</dt>
<dd></dd>
<dt><tt>A_scale</tt> : tensor(float)</dt>
<dd></dd>
<dt><tt>A_zero_point</tt> (optional) : T</dt>
<dd></dd>
<dt><tt>B</tt> : T</dt>
<dd></dd>
<dt><tt>B_scale</tt> : tensor(float)</dt>
<dd></dd>
<dt><tt>B_zero_point</tt> (optional) : T</dt>
<dd></dd>
<dt><tt>C_scale</tt> : tensor(float)</dt>
<dd></dd>
<dt><tt>C_zero_point</tt> (optional) : T</dt>
<dd></dd>
</dl>

#### Outputs

<dl>
<dt><tt>C</tt> : T</dt>
<dd></dd>
</dl>

#### Type Constraints

<dl>
<dt><tt>T</tt> : tensor(uint8), tensor(int8)</dt>
<dd>Constrain input and output types to 8 bit signed and unsigned tensors.</dd>
</dl>


### <a name="com.microsoft.QLinearReduceMean"></a><a name="com.microsoft.qlinearreducemean">**com.microsoft.QLinearReduceMean**</a>

#### Version

This version of the operator has been available since version 1 of the 'com.microsoft' operator set.

#### Attributes

<dl>
<dt><tt>axes</tt> : list of ints (required)</dt>
<dd>A list of integers, along which to reduce. The default is to reduce over all the dimensions of the input tensor.</dd>
<dt><tt>keepdims</tt> : int (required)</dt>
<dd>Keep the reduced dimension or not, default 1 mean keep reduced dimension.</dd>
</dl>

#### Inputs (4 - 5)

<dl>
<dt><tt>data</tt> : T</dt>
<dd></dd>
<dt><tt>data_scale</tt> : tensor(float)</dt>
<dd></dd>
<dt><tt>data_zero_point</tt> (optional) : T</dt>
<dd></dd>
<dt><tt>reduced_scale</tt> : tensor(float)</dt>
<dd></dd>
<dt><tt>reduced_zero_point</tt> (optional) : T</dt>
<dd></dd>
</dl>

#### Outputs

<dl>
<dt><tt>reduced</tt> : T</dt>
<dd></dd>
</dl>

#### Type Constraints

<dl>
<dt><tt>T</tt> : tensor(uint8), tensor(int8)</dt>
<dd>Constrain input types to 8 bit signed and unsigned tensors.</dd>
</dl>


### <a name="com.microsoft.QLinearSigmoid"></a><a name="com.microsoft.qlinearsigmoid">**com.microsoft.QLinearSigmoid**</a>

#### Version

This version of the operator has been available since version 1 of the 'com.microsoft' operator set.

#### Inputs (4 - 5)

<dl>
<dt><tt>X</tt> : T</dt>
<dd></dd>
<dt><tt>X_scale</tt> : tensor(float)</dt>
<dd></dd>
<dt><tt>X_zero_point</tt> (optional) : T</dt>
<dd></dd>
<dt><tt>Y_scale</tt> : tensor(float)</dt>
<dd></dd>
<dt><tt>Y_zero_point</tt> (optional) : T</dt>
<dd></dd>
</dl>

#### Outputs

<dl>
<dt><tt>Y</tt> : T</dt>
<dd></dd>
</dl>

#### Type Constraints

<dl>
<dt><tt>T</tt> : tensor(uint8), tensor(int8)</dt>
<dd>Constrain input and output types to 8 bit tensors.</dd>
</dl>


### <a name="com.microsoft.QLinearSoftmax"></a><a name="com.microsoft.qlinearsoftmax">**com.microsoft.QLinearSoftmax**</a>

#### Version

This version of the operator has been available since version 1 of the 'com.microsoft' operator set.

#### Attributes

<dl>
<dt><tt>axis</tt> : int</dt>
<dd>apply softmax to elements for dimensions axis,or all dims along with axis according to op-version</dd>
<dt><tt>opset</tt> : int (required)</dt>
<dd>opset version of corresponding SoftMax.</dd>
</dl>

#### Inputs

<dl>
<dt><tt>X</tt> : T</dt>
<dd></dd>
<dt><tt>X_scale</tt> : tensor(float)</dt>
<dd></dd>
<dt><tt>x_zero_point</tt> (optional) : T</dt>
<dd></dd>
<dt><tt>y_scale</tt> : tensor(float)</dt>
<dd></dd>
<dt><tt>y_zero_point</tt> : T</dt>
<dd></dd>
</dl>

#### Outputs

<dl>
<dt><tt>Y</tt> : T</dt>
<dd></dd>
</dl>

#### Type Constraints

<dl>
<dt><tt>T</tt> : tensor(uint8), tensor(int8)</dt>
<dd>Constrain input and output types to signed/unsigned int8 tensors.</dd>
</dl>


### <a name="com.microsoft.QLinearWhere"></a><a name="com.microsoft.qlinearwhere">**com.microsoft.QLinearWhere**</a>

#### Version

This version of the operator has been available since version 1 of the 'com.microsoft' operator set.

#### Inputs

<dl>
<dt><tt>condition</tt> : B</dt>
<dd></dd>
<dt><tt>X</tt> : T</dt>
<dd></dd>
<dt><tt>x_scale</tt> : TF</dt>
<dd></dd>
<dt><tt>x_zero_point</tt> : T</dt>
<dd></dd>
<dt><tt>Y</tt> : T</dt>
<dd></dd>
<dt><tt>y_scale</tt> : TF</dt>
<dd></dd>
<dt><tt>y_zero_point</tt> : T</dt>
<dd></dd>
<dt><tt>z_scale</tt> : TF</dt>
<dd></dd>
<dt><tt>z_zero_point</tt> : T</dt>
<dd></dd>
</dl>

#### Outputs

<dl>
<dt><tt>Z</tt> : T</dt>
<dd></dd>
</dl>

#### Type Constraints

<dl>
<dt><tt>B</tt> : tensor(bool)</dt>
<dd>Constrain input and output types to 8 bit signed and unsigned tensors.</dd>
<dt><tt>TF</tt> : tensor(float)</dt>
<dd>Constrain scale types to any float tensor type.</dd>
<dt><tt>T</tt> : tensor(uint8), tensor(int8)</dt>
<dd>Constrain input and output types to 8 bit signed and unsigned tensors.</dd>
</dl>


### <a name="com.microsoft.QMoE"></a><a name="com.microsoft.qmoe">**com.microsoft.QMoE**</a>

#### Version

This version of the operator has been available since version 1 of the 'com.microsoft' operator set.

#### Attributes

<dl>
<dt><tt>activation_type</tt> : string</dt>
<dd>Activation function to use. Choose from relu, gelu, silu and identity. Default is relu</dd>
<dt><tt>expert_weight_bits</tt> : int</dt>
<dd>Number of bits used in quantized weights. Default is 4 bits</dd>
<dt><tt>k</tt> : int</dt>
<dd>Number of top experts to select from expert pool</dd>
<dt><tt>normalize_routing_weights</tt> : int</dt>
<dd>Whether to normalize routing weights</dd>
<dt><tt>use_sparse_mixer</tt> : int</dt>
<dd>Whether to use sparse mixer</dd>
</dl>

#### Inputs (7 - 11)

<dl>
<dt><tt>input</tt> : T</dt>
<dd></dd>
<dt><tt>router_probs</tt> : T</dt>
<dd></dd>
<dt><tt>fc1_experts_weights</tt> : T1</dt>
<dd></dd>
<dt><tt>fc1_scales</tt> : T</dt>
<dd></dd>
<dt><tt>fc1_experts_bias</tt> (optional) : T</dt>
<dd></dd>
<dt><tt>fc2_experts_weights</tt> : T1</dt>
<dd></dd>
<dt><tt>fc2_scales</tt> : T</dt>
<dd></dd>
<dt><tt>fc2_experts_bias</tt> (optional) : T</dt>
<dd></dd>
<dt><tt>fc3_experts_weights</tt> (optional) : T1</dt>
<dd></dd>
<dt><tt>fc3_scales</tt> (optional) : T</dt>
<dd></dd>
<dt><tt>fc3_experts_bias</tt> (optional) : T</dt>
<dd></dd>
</dl>

#### Outputs

<dl>
<dt><tt>output</tt> : T</dt>
<dd></dd>
</dl>

#### Type Constraints

<dl>
<dt><tt>T</tt> : tensor(float16)</dt>
<dd>Constrain input and output types to float or float16 tensors.</dd>
<dt><tt>T1</tt> : tensor(uint8)</dt>
<dd>Constrain weights type to uint8 tensors.</dd>
</dl>


### <a name="com.microsoft.QOrderedAttention"></a><a name="com.microsoft.qorderedattention">**com.microsoft.QOrderedAttention**</a>

#### Version

This version of the operator has been available since version 1 of the 'com.microsoft' operator set.

#### Attributes

<dl>
<dt><tt>num_heads</tt> : int (required)</dt>
<dd>Number of attention heads</dd>
<dt><tt>order_input</tt> : int (required)</dt>
<dd>cublasLt order of input matrix. See the schema of QuantizeWithOrder for order definition.</dd>
<dt><tt>order_output</tt> : int (required)</dt>
<dd>cublasLt order of global bias</dd>
<dt><tt>order_weight</tt> : int (required)</dt>
<dd>cublasLt order of weight matrix</dd>
<dt><tt>qkv_hidden_sizes</tt> : list of ints</dt>
<dd>Hidden layer sizes of Q, K, V paths in Attention</dd>
<dt><tt>unidirectional</tt> : int</dt>
<dd>Whether every token can only attend to previous tokens. Default value is 0.</dd>
</dl>

#### Inputs (17 - 20)

<dl>
<dt><tt>input</tt> : Q</dt>
<dd></dd>
<dt><tt>scale_input</tt> : S</dt>
<dd></dd>
<dt><tt>scale_Q_gemm</tt> : S</dt>
<dd></dd>
<dt><tt>scale_K_gemm</tt> : S</dt>
<dd></dd>
<dt><tt>scale_V_gemm</tt> : S</dt>
<dd></dd>
<dt><tt>Q_weight</tt> : Q</dt>
<dd></dd>
<dt><tt>K_weight</tt> : Q</dt>
<dd></dd>
<dt><tt>V_weight</tt> : Q</dt>
<dd></dd>
<dt><tt>scale_Q_weight</tt> : S</dt>
<dd></dd>
<dt><tt>scale_K_weight</tt> : S</dt>
<dd></dd>
<dt><tt>scale_V_weight</tt> : S</dt>
<dd></dd>
<dt><tt>Q_bias</tt> : S</dt>
<dd></dd>
<dt><tt>K_bias</tt> : S</dt>
<dd></dd>
<dt><tt>V_bias</tt> : S</dt>
<dd></dd>
<dt><tt>scale_QKT_gemm</tt> (optional) : S</dt>
<dd></dd>
<dt><tt>scale_QKT_softmax</tt> (optional) : S</dt>
<dd></dd>
<dt><tt>scale_values_gemm</tt> : S</dt>
<dd></dd>
<dt><tt>mask_index</tt> (optional) : G</dt>
<dd></dd>
<dt><tt>past</tt> (optional) : Q</dt>
<dd></dd>
<dt><tt>attention_bias</tt> (optional) : S</dt>
<dd></dd>
</dl>

#### Outputs

<dl>
<dt><tt>output</tt> : Q</dt>
<dd></dd>
</dl>

#### Type Constraints

<dl>
<dt><tt>Q</tt> : tensor(int8)</dt>
<dd>Constrain input and output types to int8 tensors.</dd>
<dt><tt>S</tt> : tensor(float)</dt>
<dd>Constrain scales to float32 tensors.</dd>
<dt><tt>G</tt> : tensor(int32)</dt>
<dd>Constrain to integer types</dd>
</dl>


### <a name="com.microsoft.QOrderedGelu"></a><a name="com.microsoft.qorderedgelu">**com.microsoft.QOrderedGelu**</a>

#### Version

This version of the operator has been available since version 1 of the 'com.microsoft' operator set.

#### Attributes

<dl>
<dt><tt>order_X</tt> : int</dt>
<dd>cublasLt order of input X. Optional. See the schema of QuantizeWithOrder for order definition.</dd>
<dt><tt>order_Y</tt> : int</dt>
<dd>cublasLt order of matrix Y, must be same as order_X if specified together. Optional.</dd>
</dl>

#### Inputs

<dl>
<dt><tt>X</tt> : Q</dt>
<dd></dd>
<dt><tt>scale_X</tt> : S</dt>
<dd></dd>
<dt><tt>scale_Y</tt> : S</dt>
<dd></dd>
</dl>

#### Outputs

<dl>
<dt><tt>Y</tt> : Q</dt>
<dd></dd>
</dl>

#### Type Constraints

<dl>
<dt><tt>Q</tt> : tensor(int8)</dt>
<dd>Constrain input and output types to int8 tensors.</dd>
<dt><tt>S</tt> : tensor(float)</dt>
<dd>Constrain scales to float32</dd>
</dl>


### <a name="com.microsoft.QOrderedLayerNormalization"></a><a name="com.microsoft.qorderedlayernormalization">**com.microsoft.QOrderedLayerNormalization**</a>

#### Version

This version of the operator has been available since version 1 of the 'com.microsoft' operator set.

#### Attributes

<dl>
<dt><tt>axis</tt> : int</dt>
<dd>The first normalization dimension: normalization will be performed along dimensions axis : rank(inputs).</dd>
<dt><tt>epsilon</tt> : float</dt>
<dd>The epsilon value to use to avoid division by zero.</dd>
<dt><tt>order_X</tt> : int</dt>
<dd>cublasLt order of input X. Default is ROW MAJOR. See the schema of QuantizeWithOrder for order definition.</dd>
<dt><tt>order_Y</tt> : int</dt>
<dd>cublasLt order of matrix Y, must be same as order_X. Default is ROW MAJOR.</dd>
</dl>

#### Inputs

<dl>
<dt><tt>X</tt> : Q</dt>
<dd></dd>
<dt><tt>scale_X</tt> : S</dt>
<dd></dd>
<dt><tt>scale</tt> : F</dt>
<dd></dd>
<dt><tt>B</tt> (optional) : F</dt>
<dd></dd>
<dt><tt>scale_Y</tt> : S</dt>
<dd></dd>
</dl>

#### Outputs

<dl>
<dt><tt>Y</tt> : Q</dt>
<dd></dd>
</dl>

#### Type Constraints

<dl>
<dt><tt>F</tt> : tensor(float16), tensor(float)</dt>
<dd>Constrain input gamma and bias could be float16/float tensors. float may get better precision, float16 runs faster.</dd>
<dt><tt>S</tt> : tensor(float)</dt>
<dd>quantization scale must be float tensors.</dd>
<dt><tt>Q</tt> : tensor(int8)</dt>
<dd>quantization tensor must be int8 tensors.</dd>
</dl>


### <a name="com.microsoft.QOrderedLongformerAttention"></a><a name="com.microsoft.qorderedlongformerattention">**com.microsoft.QOrderedLongformerAttention**</a>

#### Version

This version of the operator has been available since version 1 of the 'com.microsoft' operator set.

#### Attributes

<dl>
<dt><tt>num_heads</tt> : int (required)</dt>
<dd>Number of attention heads</dd>
<dt><tt>order_global_weight</tt> : int (required)</dt>
<dd>cublasLt order of weight matrix</dd>
<dt><tt>order_input</tt> : int (required)</dt>
<dd>cublasLt order of input matrix. See the schema of QuantizeWithOrder for order definition.</dd>
<dt><tt>order_output</tt> : int (required)</dt>
<dd>cublasLt order of global bias</dd>
<dt><tt>order_weight</tt> : int (required)</dt>
<dd>cublasLt order of weight matrix</dd>
<dt><tt>window</tt> : int (required)</dt>
<dd>One sided attention windows length W, or half of total window length</dd>
</dl>

#### Inputs

<dl>
<dt><tt>input</tt> : Q</dt>
<dd></dd>
<dt><tt>scale_input</tt> : S</dt>
<dd></dd>
<dt><tt>weight</tt> : Q</dt>
<dd></dd>
<dt><tt>scale_weight</tt> : S</dt>
<dd></dd>
<dt><tt>bias</tt> : S</dt>
<dd></dd>
<dt><tt>scale_bias</tt> : S</dt>
<dd></dd>
<dt><tt>scale_qkv_gemm</tt> : S</dt>
<dd></dd>
<dt><tt>mask</tt> : F</dt>
<dd></dd>
<dt><tt>global_weight</tt> : Q</dt>
<dd></dd>
<dt><tt>scale_global_weight</tt> : S</dt>
<dd></dd>
<dt><tt>global_bias</tt> : S</dt>
<dd></dd>
<dt><tt>scale_global_gemm</tt> : S</dt>
<dd></dd>
<dt><tt>global</tt> : G</dt>
<dd></dd>
<dt><tt>scale_output</tt> : S</dt>
<dd></dd>
</dl>

#### Outputs

<dl>
<dt><tt>output</tt> : Q</dt>
<dd></dd>
</dl>

#### Type Constraints

<dl>
<dt><tt>Q</tt> : tensor(int8)</dt>
<dd>Constrain input and output types to int8 tensors.</dd>
<dt><tt>S</tt> : tensor(float)</dt>
<dd>Constrain scales to float32 tensors.</dd>
<dt><tt>G</tt> : tensor(int32)</dt>
<dd>Constrain to integer types</dd>
<dt><tt>F</tt> : tensor(float16)</dt>
<dd>Be compatible with float version.</dd>
</dl>


### <a name="com.microsoft.QOrderedMatMul"></a><a name="com.microsoft.qorderedmatmul">**com.microsoft.QOrderedMatMul**</a>

#### Version

This version of the operator has been available since version 1 of the 'com.microsoft' operator set.

#### Attributes

<dl>
<dt><tt>order_A</tt> : int (required)</dt>
<dd>cublasLt order of matrix A. See the schema of QuantizeWithOrder for order definition.</dd>
<dt><tt>order_B</tt> : int (required)</dt>
<dd>cublasLt order of matrix B</dd>
<dt><tt>order_Y</tt> : int (required)</dt>
<dd>cublasLt order of matrix Y and optional matrix C</dd>
</dl>

#### Inputs (5 - 8)

<dl>
<dt><tt>A</tt> : Q</dt>
<dd></dd>
<dt><tt>scale_A</tt> : S</dt>
<dd></dd>
<dt><tt>B</tt> : Q</dt>
<dd></dd>
<dt><tt>scale_B</tt> : S</dt>
<dd></dd>
<dt><tt>scale_Y</tt> : S</dt>
<dd></dd>
<dt><tt>bias</tt> (optional) : S</dt>
<dd></dd>
<dt><tt>C</tt> (optional) : Q</dt>
<dd></dd>
<dt><tt>scale_C</tt> (optional) : S</dt>
<dd></dd>
</dl>

#### Outputs

<dl>
<dt><tt>Y</tt> : Q</dt>
<dd></dd>
</dl>

#### Type Constraints

<dl>
<dt><tt>Q</tt> : tensor(int8)</dt>
<dd>Constrain input and output types to int8 tensors.</dd>
<dt><tt>S</tt> : tensor(float)</dt>
<dd>Constrain bias and scales to float32</dd>
</dl>


### <a name="com.microsoft.QuantizeBFP"></a><a name="com.microsoft.quantizebfp">**com.microsoft.QuantizeBFP**</a>

#### Version

This version of the operator has been available since version 1 of the 'com.microsoft' operator set.

#### Attributes

<dl>
<dt><tt>bfp_type</tt> : int (required)</dt>
<dd>The type of BFP - must match with the BFPType enum</dd>
<dt><tt>block_dim</tt> : int</dt>
<dd>Each bounding box spans this dimension.Typically, the block dimension corresponds to the reduction dimension of the matrix multipication that consumes the output of this operator.For example, for a 2D matrix multiplication A@W, QuantizeBFP(A) would use block_dim 1 and QuantizeBFP(W) would use block_dim 0.The default is the last dimension.</dd>
</dl>

#### Inputs

<dl>
<dt><tt>x</tt> : T1</dt>
<dd></dd>
</dl>

#### Outputs

<dl>
<dt><tt>y</tt> : T2</dt>
<dd></dd>
<dt><tt>shape</tt> : T3</dt>
<dd></dd>
<dt><tt>strides</tt> : T3</dt>
<dd></dd>
</dl>

#### Type Constraints

<dl>
<dt><tt>T1</tt> : tensor(float), tensor(float16), tensor(bfloat16)</dt>
<dd>Constrain the input to float and bfloat.</dd>
<dt><tt>T2</tt> : tensor(uint8)</dt>
<dd>Constrain y to uint8.</dd>
<dt><tt>T3</tt> : tensor(int64)</dt>
<dd>Constrain shape and strides to uint64.</dd>
</dl>


### <a name="com.microsoft.QuantizeLinear"></a><a name="com.microsoft.quantizelinear">**com.microsoft.QuantizeLinear**</a>

#### Version

This version of the operator has been available since version 1 of the 'com.microsoft' operator set.

#### Attributes

<dl>
<dt><tt>axis</tt> : int</dt>
<dd>The axis along which same quantization parameters are applied. It's optional.If it's not specified, it means per-tensor quantization and input 'x_scale' and 'x_zero_point' must be scalars.If it's specified, it means per 'axis' quantization and input 'x_scale' and 'x_zero_point' must be 1-D tensors.</dd>
</dl>

#### Inputs (2 - 3)

<dl>
<dt><tt>x</tt> : T1</dt>
<dd></dd>
<dt><tt>y_scale</tt> : T1</dt>
<dd></dd>
<dt><tt>y_zero_point</tt> (optional) : T2</dt>
<dd></dd>
</dl>

#### Outputs

<dl>
<dt><tt>y</tt> : T2</dt>
<dd></dd>
</dl>

#### Type Constraints

<dl>
<dt><tt>T1</tt> : tensor(float16), tensor(float)</dt>
<dd>Constrain 'x', 'y_scale' to float tensors.</dd>
<dt><tt>T2</tt> : tensor(int8), tensor(uint8), tensor(int16), tensor(uint16), tensor(int4), tensor(uint4)</dt>
<dd>Constrain 'y_zero_point' and 'y' to 8-bit and 16-bit integer tensors.</dd>
</dl>


### <a name="com.microsoft.QuantizeWithOrder"></a><a name="com.microsoft.quantizewithorder">**com.microsoft.QuantizeWithOrder**</a>

#### Version

This version of the operator has been available since version 1 of the 'com.microsoft' operator set.

#### Attributes

<dl>
<dt><tt>order_input</tt> : int (required)</dt>
<dd>cublasLt order of input matrix. ORDER_COL = 0, ORDER_ROW = 1, ORDER_COL32 = 2, ORDER_COL4_4R2_8C = 3, ORDER_COL32_2R_4R4 = 4. Please refer https://docs.nvidia.com/cuda/cublas/index.html#cublasLtOrder_t for their meaning.</dd>
<dt><tt>order_output</tt> : int (required)</dt>
<dd>cublasLt order of output matrix.</dd>
</dl>

#### Inputs

<dl>
<dt><tt>input</tt> : F</dt>
<dd></dd>
<dt><tt>scale_input</tt> : S</dt>
<dd></dd>
</dl>

#### Outputs

<dl>
<dt><tt>output</tt> : Q</dt>
<dd></dd>
</dl>

#### Type Constraints

<dl>
<dt><tt>Q</tt> : tensor(int8)</dt>
<dd>Constrain input and output types to int8 tensors.</dd>
<dt><tt>F</tt> : tensor(float16), tensor(float)</dt>
<dd>Constrain to float types</dd>
<dt><tt>S</tt> : tensor(float)</dt>
<dd>Constrain Scale to float32 types</dd>
</dl>


### <a name="com.microsoft.QuickGelu"></a><a name="com.microsoft.quickgelu">**com.microsoft.QuickGelu**</a>

#### Version

This version of the operator has been available since version 1 of the 'com.microsoft' operator set.

#### Attributes

<dl>
<dt><tt>alpha</tt> : float</dt>
<dd>Alpha value.</dd>
</dl>

#### Inputs

<dl>
<dt><tt>X</tt> : T</dt>
<dd></dd>
</dl>

#### Outputs

<dl>
<dt><tt>Y</tt> : T</dt>
<dd></dd>
</dl>

#### Type Constraints

<dl>
<dt><tt>T</tt> : tensor(float16), tensor(float), tensor(double), tensor(bfloat16)</dt>
<dd>Constrain input and output types to float tensors.</dd>
</dl>


### <a name="com.microsoft.Range"></a><a name="com.microsoft.range">**com.microsoft.Range**</a>

#### Version

This version of the operator has been available since version 1 of the 'com.microsoft' operator set.

#### Inputs (2 - 3)

<dl>
<dt><tt>start</tt> : T</dt>
<dd></dd>
<dt><tt>limit</tt> : T</dt>
<dd></dd>
<dt><tt>delta</tt> (optional) : T</dt>
<dd></dd>
</dl>

#### Outputs

<dl>
<dt><tt>Y</tt> : T</dt>
<dd></dd>
</dl>

#### Type Constraints

<dl>
<dt><tt>T</tt> : tensor(float), tensor(double), tensor(int16), tensor(int32), tensor(int64)</dt>
<dd>Constrain input and output types.</dd>
</dl>


### <a name="com.microsoft.ReduceSumInteger"></a><a name="com.microsoft.reducesuminteger">**com.microsoft.ReduceSumInteger**</a>

#### Version

This version of the operator has been available since version 1 of the 'com.microsoft' operator set.

#### Attributes

<dl>
<dt><tt>axes</tt> : list of ints (required)</dt>
<dd>A list of integers, along which to reduce. The default is to reduce over all the dimensions of the input tensor.</dd>
<dt><tt>keepdims</tt> : int (required)</dt>
<dd>Keep the reduced dimension or not, default 1 mean keep reduced dimension.</dd>
</dl>

#### Inputs

<dl>
<dt><tt>data</tt> : T1</dt>
<dd></dd>
</dl>

#### Outputs

<dl>
<dt><tt>reduced</tt> : T2</dt>
<dd></dd>
</dl>

#### Type Constraints

<dl>
<dt><tt>T1</tt> : tensor(int8), tensor(uint8)</dt>
<dd>Constrain input type to 8-bit integer tensor.</dd>
<dt><tt>T2</tt> : tensor(int32), tensor(uint32)</dt>
<dd>Constrain output data type to 32-bit integer tensor.T2 must be tensor(uint32) when T1 is tensor(uint8),or must be tensor(int32) when T1 is tensor(int8).</dd>
</dl>


### <a name="com.microsoft.RelativePositionBias"></a><a name="com.microsoft.relativepositionbias">**com.microsoft.RelativePositionBias**</a>

#### Version

This version of the operator has been available since version 1 of the 'com.microsoft' operator set.

#### Attributes

<dl>
<dt><tt>is_bidirectional</tt> : int</dt>
<dd>Default value is 0.</dd>
<dt><tt>max_distance</tt> : int (required)</dt>
<dd>Max distance</dd>
</dl>

#### Inputs

<dl>
<dt><tt>bias_table</tt> : T</dt>
<dd></dd>
<dt><tt>query_length</tt> : U</dt>
<dd></dd>
<dt><tt>key_length</tt> : U</dt>
<dd></dd>
</dl>

#### Outputs

<dl>
<dt><tt>output</tt> : T</dt>
<dd></dd>
</dl>

#### Type Constraints

<dl>
<dt><tt>T</tt> : tensor(float), tensor(float16)</dt>
<dd>Constrain input and output types to float or half tensors.</dd>
<dt><tt>U</tt> : tensor(int64)</dt>
<dd>Constrain sequence_length to int tensors.</dd>
</dl>


### <a name="com.microsoft.RemovePadding"></a><a name="com.microsoft.removepadding">**com.microsoft.RemovePadding**</a>

#### Version

This version of the operator has been available since version 1 of the 'com.microsoft' operator set.

#### Inputs

<dl>
<dt><tt>input</tt> : T</dt>
<dd></dd>
<dt><tt>sequence_token_count</tt> : M</dt>
<dd></dd>
</dl>

#### Outputs

<dl>
<dt><tt>output</tt> : T</dt>
<dd></dd>
<dt><tt>token_offset</tt> : M</dt>
<dd></dd>
<dt><tt>cumulated_seq_len</tt> : M</dt>
<dd></dd>
<dt><tt>max_seq_len</tt> : M</dt>
<dd></dd>
</dl>

#### Type Constraints

<dl>
<dt><tt>T</tt> : tensor(float), tensor(float16)</dt>
<dd>Constrain input and output types to float tensors.</dd>
<dt><tt>M</tt> : tensor(int32)</dt>
<dd>Constrain sequence_token_count and token_offset to integer types</dd>
</dl>


### <a name="com.microsoft.RestorePadding"></a><a name="com.microsoft.restorepadding">**com.microsoft.RestorePadding**</a>

#### Version

This version of the operator has been available since version 1 of the 'com.microsoft' operator set.

#### Inputs

<dl>
<dt><tt>input</tt> : T</dt>
<dd></dd>
<dt><tt>token_offset</tt> : M</dt>
<dd></dd>
</dl>

#### Outputs

<dl>
<dt><tt>output</tt> : T</dt>
<dd></dd>
</dl>

#### Type Constraints

<dl>
<dt><tt>T</tt> : tensor(float), tensor(float16)</dt>
<dd>Constrain input and output types to float tensors.</dd>
<dt><tt>M</tt> : tensor(int32)</dt>
<dd>Constrain token_offset to integer types</dd>
</dl>


### <a name="com.microsoft.Rfft"></a><a name="com.microsoft.rfft">**com.microsoft.Rfft**</a>

#### Version

This version of the operator has been available since version 1 of the 'com.microsoft' operator set.

#### Attributes

<dl>
<dt><tt>normalized</tt> : int</dt>
<dd>must be 0, normalization currently not supported</dd>
<dt><tt>onesided</tt> : int</dt>
<dd>must be 1, only one sided FFTs supported</dd>
<dt><tt>signal_ndim</tt> : int</dt>
<dd>number of dimensions comprising the signal, collected in reverse order (e.g. 1 = last dimension is the signal)</dd>
</dl>

#### Inputs

<dl>
<dt><tt>X</tt> : T</dt>
<dd></dd>
</dl>

#### Outputs

<dl>
<dt><tt>Y</tt> : T</dt>
<dd></dd>
</dl>

#### Type Constraints

<dl>
<dt><tt>T</tt> : tensor(float), tensor(double), tensor(float16)</dt>
<dd>Constrain input and output types to float or half tensors.</dd>
</dl>


### <a name="com.microsoft.RotaryEmbedding"></a><a name="com.microsoft.rotaryembedding">**com.microsoft.RotaryEmbedding**</a>

#### Version

This version of the operator has been available since version 1 of the 'com.microsoft' operator set.

#### Attributes

<dl>
<dt><tt>interleaved</tt> : int</dt>
<dd>Rotate using interleaved pattern. Default value is 0 (False).</dd>
<dt><tt>is_packed_batching</tt> : int</dt>
<dd>ragged batch inputs or not. Default value is 0</dd>
<dt><tt>num_heads</tt> : int</dt>
<dd>Number of attention heads. Default value is 0. Must use with rotary_embedding_dim</dd>
<dt><tt>rotary_embedding_dim</tt> : int</dt>
<dd>Rotary embedding dimension. Default value is 0.</dd>
<dt><tt>scale</tt> : float</dt>
<dd>Custom scale will be used if specified. Default value is 1.0</dd>
</dl>

#### Inputs

<dl>
<dt><tt>input</tt> : T</dt>
<dd></dd>
<dt><tt>position_ids</tt> : M</dt>
<dd></dd>
<dt><tt>cos_cache</tt> : T</dt>
<dd></dd>
<dt><tt>sin_cache</tt> : T</dt>
<dd></dd>
</dl>

#### Outputs

<dl>
<dt><tt>output</tt> : T</dt>
<dd></dd>
</dl>

#### Type Constraints

<dl>
<dt><tt>T</tt> : tensor(float), tensor(float16), tensor(bfloat16)</dt>
<dd>Constrain input and output types to float tensors.</dd>
<dt><tt>M</tt> : tensor(int64)</dt>
<dd>Constrain input and output types to integer tensors</dd>
</dl>


### <a name="com.microsoft.SampleOp"></a><a name="com.microsoft.sampleop">**com.microsoft.SampleOp**</a>

#### Version

This version of the operator has been available since version 1 of the 'com.microsoft' operator set.

#### Inputs

<dl>
<dt><tt>X</tt> : T</dt>
<dd></dd>
</dl>

#### Outputs

<dl>
<dt><tt>Y</tt> : T</dt>
<dd></dd>
</dl>

#### Type Constraints

<dl>
<dt><tt>T</tt> : tensor(uint32), tensor(uint64), tensor(int32), tensor(int64), tensor(float16), tensor(float), tensor(double)</dt>
<dd>Constrain to any tensor type. If the dtype attribute is not provided this must be a valid output type.</dd>
</dl>


### <a name="com.microsoft.Sampling"></a><a name="com.microsoft.sampling">**com.microsoft.Sampling**</a>

#### Version

This version of the operator has been available since version 1 of the 'com.microsoft' operator set.

#### Attributes

<dl>
<dt><tt>custom</tt> : int</dt>
<dd>If 1 custom sampling logic</dd>
<dt><tt>decoder</tt> : graph (required)</dt>
<dd>Decoder subgraph to execute in a loop.</dd>
<dt><tt>decoder_start_token_id</tt> : int</dt>
<dd>The id of the token that indicates decoding starts.</dd>
<dt><tt>encoder</tt> : graph</dt>
<dd>The subgraph for initialization of encoder and decoder. It will be called once before decoder subgraph.</dd>
<dt><tt>eos_token_id</tt> : int (required)</dt>
<dd>The id of the end-of-sequence token</dd>
<dt><tt>filter_value</tt> : float</dt>
<dd>All filtered values will be set to this float value.</dd>
<dt><tt>init_decoder</tt> : graph</dt>
<dd>The subgraph for the first decoding run. It will be called once before `decoder` subgraph. This is relevant only for the GPT2 model. If this attribute is missing, the `decoder` subgraph will be used for all decoding runs</dd>
<dt><tt>min_tokens_to_keep</tt> : int</dt>
<dd>Minimumber of tokens we keep per batch example in the output.</dd>
<dt><tt>model_type</tt> : int</dt>
<dd>Model type: 0 for decoder only like GPT-2; 1 for encoder decoder like Bart</dd>
<dt><tt>no_repeat_ngram_size</tt> : int</dt>
<dd>no repeat ngrams size</dd>
<dt><tt>pad_token_id</tt> : int (required)</dt>
<dd>The id of the padding token</dd>
<dt><tt>presence_penalty</tt> : float</dt>
<dd>Presence penalty for custom sampling</dd>
<dt><tt>temperature</tt> : float</dt>
<dd>The value used to module the next token probabilities.</dd>
<dt><tt>top_p</tt> : float</dt>
<dd>If set to float < 1, only the smallest set of most probable tokens with probabilities that add up to `top_p` or higher are kept for generation.</dd>
<dt><tt>vocab_size</tt> : int</dt>
<dd>Size of the vocabulary. If not provided, it will be inferred from the decoder subgraph's output shape</dd>
</dl>

#### Inputs (2 - 9)

<dl>
<dt><tt>input_ids</tt> : I</dt>
<dd></dd>
<dt><tt>max_length</tt> : I</dt>
<dd></dd>
<dt><tt>min_length</tt> (optional) : I</dt>
<dd></dd>
<dt><tt>repetition_penalty</tt> (optional) : T</dt>
<dd></dd>
<dt><tt>vocab_mask</tt> (optional) : I</dt>
<dd></dd>
<dt><tt>prefix_vocab_mask</tt> (optional) : I</dt>
<dd></dd>
<dt><tt>attention_mask</tt> (optional) : I</dt>
<dd></dd>
<dt><tt>presence_mask</tt> (optional) : I</dt>
<dd></dd>
<dt><tt>seed</tt> (optional) : I</dt>
<dd></dd>
</dl>

#### Outputs (1 - 2)

<dl>
<dt><tt>sequences</tt> : I</dt>
<dd></dd>
<dt><tt>filtered_logits</tt> (optional) : T</dt>
<dd></dd>
</dl>

#### Type Constraints

<dl>
<dt><tt>T</tt> : tensor(float)</dt>
<dd>Constrain input and output types to float tensors.</dd>
<dt><tt>I</tt> : tensor(int32)</dt>
<dd>Constrain to integer types</dd>
</dl>


### <a name="com.microsoft.SkipGroupNorm"></a><a name="com.microsoft.skipgroupnorm">**com.microsoft.SkipGroupNorm**</a>

#### Version

This version of the operator has been available since version 1 of the 'com.microsoft' operator set.

#### Attributes

<dl>
<dt><tt>activation</tt> : int (required)</dt>
<dd>Activation after group normalization: 0 for None, 1 for SiLU</dd>
<dt><tt>channels_last</tt> : int</dt>
<dd>1 if the input and output are in the NHWC layout, 0 if it is in the NCHW layout. Defaults to 1.</dd>
<dt><tt>epsilon</tt> : float</dt>
<dd>The epsilon value to use to avoid division by zero</dd>
<dt><tt>groups</tt> : int (required)</dt>
<dd>The number of groups of channels. It should be a divisor of the number of channels C</dd>
</dl>

#### Inputs (4 - 5)

<dl>
<dt><tt>X</tt> : T</dt>
<dd></dd>
<dt><tt>gamma</tt> : M</dt>
<dd></dd>
<dt><tt>beta</tt> : M</dt>
<dd></dd>
<dt><tt>skip</tt> : T</dt>
<dd></dd>
<dt><tt>bias</tt> (optional) : T</dt>
<dd></dd>
</dl>

#### Outputs (1 - 2)

<dl>
<dt><tt>Y</tt> : T</dt>
<dd></dd>
<dt><tt>S</tt> (optional) : T</dt>
<dd></dd>
</dl>

#### Type Constraints

<dl>
<dt><tt>T</tt> : tensor(float16), tensor(float)</dt>
<dd>Constrain input X, skip, bias and output Y, S types to float tensors.</dd>
<dt><tt>M</tt> : tensor(float16), tensor(float)</dt>
<dd>Constrain gamma and beta to float tensors.</dd>
</dl>


### <a name="com.microsoft.SkipLayerNormalization"></a><a name="com.microsoft.skiplayernormalization">**com.microsoft.SkipLayerNormalization**</a>

#### Version

This version of the operator has been available since version 1 of the 'com.microsoft' operator set.

#### Attributes

<dl>
<dt><tt>epsilon</tt> : float</dt>
<dd>The epsilon value to use to avoid division by zero.</dd>
</dl>

#### Inputs (3 - 5)

<dl>
<dt><tt>input</tt> : T</dt>
<dd></dd>
<dt><tt>skip</tt> : T</dt>
<dd></dd>
<dt><tt>gamma</tt> : T</dt>
<dd></dd>
<dt><tt>beta</tt> (optional) : T</dt>
<dd></dd>
<dt><tt>bias</tt> (optional) : T</dt>
<dd></dd>
</dl>

#### Outputs (1 - 4)

<dl>
<dt><tt>output</tt> : T</dt>
<dd></dd>
<dt><tt>mean</tt> (optional) : U</dt>
<dd></dd>
<dt><tt>inv_std_var</tt> (optional) : U</dt>
<dd></dd>
<dt><tt>input_skip_bias_sum</tt> (optional) : T</dt>
<dd></dd>
</dl>

#### Type Constraints

<dl>
<dt><tt>T</tt> : tensor(float), tensor(float16)</dt>
<dd>Constrain input and output types to float or half tensors.</dd>
<dt><tt>U</tt> : tensor(float)</dt>
<dd>Constrain mean and inv_std_var to float tensors.</dd>
</dl>


### <a name="com.microsoft.SkipSimplifiedLayerNormalization"></a><a name="com.microsoft.skipsimplifiedlayernormalization">**com.microsoft.SkipSimplifiedLayerNormalization**</a>

#### Version

This version of the operator has been available since version 1 of the 'com.microsoft' operator set.

#### Attributes

<dl>
<dt><tt>epsilon</tt> : float</dt>
<dd>The epsilon value to use to avoid division by zero.</dd>
</dl>

#### Inputs (3 - 4)

<dl>
<dt><tt>input</tt> : T</dt>
<dd></dd>
<dt><tt>skip</tt> : T</dt>
<dd></dd>
<dt><tt>gamma</tt> : T</dt>
<dd></dd>
<dt><tt>bias</tt> (optional) : T</dt>
<dd></dd>
</dl>

#### Outputs (1 - 4)

<dl>
<dt><tt>output</tt> : T</dt>
<dd></dd>
<dt><tt>mean</tt> (optional) : U</dt>
<dd></dd>
<dt><tt>inv_std_var</tt> (optional) : U</dt>
<dd></dd>
<dt><tt>input_skip_bias_sum</tt> (optional) : T</dt>
<dd></dd>
</dl>

#### Type Constraints

<dl>
<dt><tt>T</tt> : tensor(float), tensor(float16)</dt>
<dd>Constrain input and output types to float or half tensors.</dd>
<dt><tt>U</tt> : tensor(float)</dt>
<dd>Constrain mean and inv_std_var to float tensors.</dd>
</dl>


### <a name="com.microsoft.Snpe"></a><a name="com.microsoft.snpe">**com.microsoft.Snpe**</a>

#### Version

This version of the operator has been available since version 1 of the 'com.microsoft' operator set.

#### Attributes

<dl>
<dt><tt>DLC</tt> : string (required)</dt>
<dd>payload of the SNPE DLC file.</dd>
<dt><tt>notes</tt> : string</dt>
<dd>(Optional) Some notes for the model</dd>
<dt><tt>snpe_version</tt> : string</dt>
<dd>(Optional) SNPE version used to convert the model.</dd>
<dt><tt>target_device</tt> : string</dt>
<dd>(Optional) Target device like CPU, DSP, etc.</dd>
</dl>

#### Inputs (1 - &#8734;)

<dl>
<dt><tt>inputs</tt> (variadic) : T</dt>
<dd></dd>
</dl>

#### Outputs (1 - &#8734;)

<dl>
<dt><tt>outputs</tt> (variadic) : T</dt>
<dd></dd>
</dl>

#### Type Constraints

<dl>
<dt><tt>T</tt> : tensor(uint8), tensor(uint16), tensor(float)</dt>
<dd>Constrain input and output types to uint8, uint16, float tensors.</dd>
</dl>


### <a name="com.microsoft.SparseAttention"></a><a name="com.microsoft.sparseattention">**com.microsoft.SparseAttention**</a>

#### Version

This version of the operator has been available since version 1 of the 'com.microsoft' operator set.

#### Attributes

<dl>
<dt><tt>do_rotary</tt> : int</dt>
<dd>Whether to use rotary position embedding. Default value is 0.</dd>
<dt><tt>kv_num_heads</tt> : int (required)</dt>
<dd>Number of attention heads for key and value</dd>
<dt><tt>num_heads</tt> : int (required)</dt>
<dd>Number of attention heads for query</dd>
<dt><tt>rotary_interleaved</tt> : int</dt>
<dd>Rotary use interleaved pattern or not. Default value is 0.</dd>
<dt><tt>scale</tt> : float</dt>
<dd>Scaling factor applied prior to softmax. The default value is 1/sqrt(head_size)</dd>
<dt><tt>sparse_block_size</tt> : int (required)</dt>
<dd>Number of tokens per sparse block. Choices: 16, 32, 64, 128</dd>
</dl>

#### Inputs (9 - 11)

<dl>
<dt><tt>query</tt> : T</dt>
<dd></dd>
<dt><tt>key</tt> (optional) : T</dt>
<dd></dd>
<dt><tt>value</tt> (optional) : T</dt>
<dd></dd>
<dt><tt>past_key</tt> : T</dt>
<dd></dd>
<dt><tt>past_value</tt> : T</dt>
<dd></dd>
<dt><tt>block_row_indices</tt> : M</dt>
<dd></dd>
<dt><tt>block_col_indices</tt> : M</dt>
<dd></dd>
<dt><tt>total_sequence_length</tt> : M</dt>
<dd></dd>
<dt><tt>key_total_sequence_lengths</tt> : M</dt>
<dd></dd>
<dt><tt>cos_cache</tt> (optional) : T</dt>
<dd></dd>
<dt><tt>sin_cache</tt> (optional) : T</dt>
<dd></dd>
</dl>

#### Outputs

<dl>
<dt><tt>output</tt> : T</dt>
<dd></dd>
<dt><tt>present_key</tt> : T</dt>
<dd></dd>
<dt><tt>present_value</tt> : T</dt>
<dd></dd>
</dl>

#### Type Constraints

<dl>
<dt><tt>T</tt> : tensor(float), tensor(float16), tensor(bfloat16)</dt>
<dd>Constrain input and output to float tensors.</dd>
<dt><tt>M</tt> : tensor(int32)</dt>
<dd>Constrain integer type.</dd>
</dl>


### <a name="com.microsoft.SparseToDenseMatMul"></a><a name="com.microsoft.sparsetodensematmul">**com.microsoft.SparseToDenseMatMul**</a>

#### Version

This version of the operator has been available since version 1 of the 'com.microsoft' operator set.

#### Attributes

<dl>
<dt><tt>alpha</tt> : float</dt>
<dd>Scalar multiplier for the product of the input tensors.</dd>
<dt><tt>transA</tt> : int</dt>
<dd>Whether A should be transposed on the last two dimensions before doing multiplication</dd>
<dt><tt>transB</tt> : int</dt>
<dd>Whether B should be transposed on the last two dimensions before doing multiplication</dd>
</dl>

#### Inputs

<dl>
<dt><tt>A</tt> : T</dt>
<dd></dd>
<dt><tt>B</tt> : T1</dt>
<dd></dd>
</dl>

#### Outputs

<dl>
<dt><tt>Y</tt> : T1</dt>
<dd></dd>
</dl>

#### Type Constraints

<dl>
<dt><tt>T</tt> : sparse_tensor(float), sparse_tensor(double), sparse_tensor(int64), sparse_tensor(int32), sparse_tensor(uint64), sparse_tensor(uint32)</dt>
<dd>Constrain input and output types to float tensors.</dd>
<dt><tt>T1</tt> : tensor(float), tensor(double), tensor(int64), tensor(int32), tensor(uint64), tensor(uint32)</dt>
<dd>Constrain input and output types to float tensors.</dd>
</dl>


### <a name="com.microsoft.Tokenizer"></a><a name="com.microsoft.tokenizer">**com.microsoft.Tokenizer**</a>

#### Version

This version of the operator has been available since version 1 of the 'com.microsoft' operator set.

#### Attributes

<dl>
<dt><tt>mark</tt> : int (required)</dt>
<dd>Boolean whether to mark the beginning/end character with start of text character (0x02)/end of text character (0x03).</dd>
<dt><tt>mincharnum</tt> : int (required)</dt>
<dd>Minimum number of characters allowed in the output. For example, if mincharnum is 2, tokens such as "A" and "B" would be ignored</dd>
<dt><tt>pad_value</tt> : string (required)</dt>
<dd>The string used to pad output tensors when the tokens extracted doesn't match the maximum number of tokens found. If start/end markers are needed, padding will appear outside the markers.</dd>
<dt><tt>separators</tt> : list of strings</dt>
<dd>an optional list of strings attribute that contains a list of separators - regular expressions to match separators Two consecutive segments in X connected by a separator would be divided into two tokens. For example, if the input is "Hello World!" and this attribute contains only one space character, the corresponding output would be ["Hello", "World!"]. To achieve character-level tokenization, one should set the 'separators' to [""], which contains an empty string.</dd>
<dt><tt>tokenexp</tt> : string</dt>
<dd>An optional string. Token's regular expression in basic POSIX format (pubs.opengroup.org/onlinepubs/9699919799/basedefs/V1_chap09.html#tag_09_03). If set, tokenizer may produce tokens matching the specified pattern. Note that one and only of 'tokenexp' and 'separators' should be set.</dd>
</dl>

#### Inputs

<dl>
<dt><tt>X</tt> : T</dt>
<dd></dd>
</dl>

#### Outputs

<dl>
<dt><tt>Y</tt> : T</dt>
<dd></dd>
</dl>

#### Type Constraints

<dl>
<dt><tt>T</tt> : tensor(string)</dt>
<dd>Input/Output is a string tensor</dd>
</dl>


### <a name="com.microsoft.TorchEmbedding"></a><a name="com.microsoft.torchembedding">**com.microsoft.TorchEmbedding**</a>

#### Version

This version of the operator has been available since version 1 of the 'com.microsoft' operator set.

#### Inputs (2 - 4)

<dl>
<dt><tt>weight</tt> : T</dt>
<dd></dd>
<dt><tt>indices</tt> : tensor(int64)</dt>
<dd></dd>
<dt><tt>padding_idx</tt> (optional) : tensor(int64)</dt>
<dd></dd>
<dt><tt>scale_grad_by_freq</tt> (optional) : tensor(bool)</dt>
<dd></dd>
</dl>

#### Outputs

<dl>
<dt><tt>Y</tt> : T</dt>
<dd></dd>
</dl>

#### Type Constraints

<dl>
<dt><tt>T</tt> : tensor(float16), tensor(float), tensor(double), tensor(bfloat16), tensor(uint8), tensor(uint16), tensor(uint32), tensor(uint64), tensor(int8), tensor(int16), tensor(int32), tensor(int64)</dt>
<dd>Constrain input and output types to all numeric tensors.</dd>
</dl>


### <a name="com.microsoft.TransposeMatMul"></a><a name="com.microsoft.transposematmul">**com.microsoft.TransposeMatMul**</a>

#### Version

This version of the operator has been available since version 1 of the 'com.microsoft' operator set.

#### Attributes

<dl>
<dt><tt>alpha</tt> : float</dt>
<dd>Scalar multiplier for the product of the input tensors.</dd>
<dt><tt>transA</tt> : int</dt>
<dd>Whether A should be transposed on the last two dimensions before doing multiplication</dd>
<dt><tt>transB</tt> : int</dt>
<dd>Whether B should be transposed on the last two dimensions before doing multiplication</dd>
</dl>

#### Inputs

<dl>
<dt><tt>A</tt> : T</dt>
<dd></dd>
<dt><tt>B</tt> : T</dt>
<dd></dd>
</dl>

#### Outputs

<dl>
<dt><tt>Y</tt> : T</dt>
<dd></dd>
</dl>

#### Type Constraints

<dl>
<dt><tt>T</tt> : tensor(float16), tensor(float), tensor(double), tensor(bfloat16)</dt>
<dd>Constrain input and output types to float tensors.</dd>
</dl>


### <a name="com.microsoft.Trilu"></a><a name="com.microsoft.trilu">**com.microsoft.Trilu**</a>

#### Version

This version of the operator has been available since version 1 of the 'com.microsoft' operator set.

#### Attributes

<dl>
<dt><tt>upper</tt> : int</dt>
<dd>Boolean. Indicates whether upper or lower part of matrix is retained. Default is true.</dd>
</dl>

#### Inputs (1 - 2)

<dl>
<dt><tt>X</tt> : T</dt>
<dd></dd>
<dt><tt>k</tt> (optional) : tensor(int64)</dt>
<dd></dd>
</dl>

#### Outputs

<dl>
<dt><tt>Y</tt> : T</dt>
<dd></dd>
</dl>

#### Type Constraints

<dl>
<dt><tt>T</tt> : tensor(float16), tensor(float), tensor(double), tensor(bfloat16), tensor(uint8), tensor(uint16), tensor(uint32), tensor(uint64), tensor(int8), tensor(int16), tensor(int32), tensor(int64), tensor(bool)</dt>
<dd>Constrain input and output types to all numeric tensors and bool tensors.</dd>
</dl>


### <a name="com.microsoft.UnfoldTensor"></a><a name="com.microsoft.unfoldtensor">**com.microsoft.UnfoldTensor**</a>

#### Version

This version of the operator has been available since version 1 of the 'com.microsoft' operator set.

#### Attributes

<dl>
<dt><tt>dim</tt> : int</dt>
<dd>specify the dimension to unfold</dd>
<dt><tt>size</tt> : int (required)</dt>
<dd>specify the size</dd>
<dt><tt>step</tt> : int</dt>
<dd>specify the step.</dd>
</dl>

#### Inputs

<dl>
<dt><tt>input</tt> : T</dt>
<dd></dd>
</dl>

#### Outputs

<dl>
<dt><tt>output</tt> : T</dt>
<dd></dd>
</dl>

#### Type Constraints

<dl>
<dt><tt>T</tt> : tensor(uint8), tensor(uint16), tensor(uint32), tensor(uint64), tensor(int8), tensor(int16), tensor(int32), tensor(int64), tensor(bfloat16), tensor(float16), tensor(float), tensor(double), tensor(string), tensor(bool), tensor(complex64), tensor(complex128)</dt>
<dd>Allow inputs and outputs to be any kind of tensor.</dd>
</dl>


### <a name="com.microsoft.Unique"></a><a name="com.microsoft.unique">**com.microsoft.Unique**</a>

#### Version

This version of the operator has been available since version 1 of the 'com.microsoft' operator set.

#### Inputs

<dl>
<dt><tt>x</tt> : T</dt>
<dd></dd>
</dl>

#### Outputs

<dl>
<dt><tt>y</tt> : T</dt>
<dd></dd>
<dt><tt>idx</tt> : tensor(int64)</dt>
<dd></dd>
<dt><tt>counts</tt> : tensor(int64)</dt>
<dd></dd>
</dl>

#### Type Constraints

<dl>
<dt><tt>T</tt> : tensor(uint8), tensor(uint16), tensor(uint32), tensor(uint64), tensor(int8), tensor(int16), tensor(int32), tensor(int64), tensor(float16), tensor(float), tensor(double), tensor(string), tensor(bool), tensor(complex64), tensor(complex128)</dt>
<dd>Input can be of any tensor type.</dd>
</dl>


### <a name="com.microsoft.WhisperBeamSearch"></a><a name="com.microsoft.whisperbeamsearch">**com.microsoft.WhisperBeamSearch**</a>

#### Version

This version of the operator has been available since version 1 of the 'com.microsoft' operator set.

#### Attributes

<dl>
<dt><tt>beginning_timestamp_token_id</tt> : int</dt>
<dd>The id of the first timestamp</dd>
<dt><tt>decoder</tt> : graph (required)</dt>
<dd>Decoder subgraph to execute in a loop.</dd>
<dt><tt>decoder_output_cross_qk</tt> : int</dt>
<dd>If nozero, decoder subgraph contains output Q*K from cross attentions. Default 0.</dd>
<dt><tt>decoder_start_token_id</tt> : int</dt>
<dd>The id of the token that indicates decoding starts (i.e. the start of transcription token id)</dd>
<dt><tt>early_stopping</tt> : int</dt>
<dd>early stop or not</dd>
<dt><tt>encoder</tt> : graph</dt>
<dd>The subgraph for initialization of encoder and decoder. It will be called once before decoder subgraph.</dd>
<dt><tt>eos_token_id</tt> : int (required)</dt>
<dd>The id of the end-of-sequence token</dd>
<dt><tt>init_decoder</tt> : graph</dt>
<dd>The subgraph for the first decoding run. It will be called once before `decoder` subgraph. This is relevant only for the GPT2 model. If this attribute is missing, the `decoder` subgraph will be used for all decoding runs</dd>
<dt><tt>model_type</tt> : int</dt>
<dd>Must be 2 for whisper</dd>
<dt><tt>no_repeat_ngram_size</tt> : int</dt>
<dd>no repeat ngrams size</dd>
<dt><tt>no_speech_token_id</tt> : int</dt>
<dd>The token in whisper model that marks all sequence empty. With this model, whisper could output no_speech_prob after. Default -1.</dd>
<dt><tt>no_timestamps_token_id</tt> : int</dt>
<dd>The id of the token that indicates no timestamps</dd>
<dt><tt>pad_token_id</tt> : int (required)</dt>
<dd>The id of the padding token</dd>
<dt><tt>start_of_lm_token_id</tt> : int</dt>
<dd>The id of the token that indicates LM starts</dd>
<dt><tt>transcribe_token_id</tt> : int</dt>
<dd>The id of the transcribe task</dd>
<dt><tt>translate_token_id</tt> : int</dt>
<dd>The id of the translate task</dd>
<dt><tt>vocab_size</tt> : int</dt>
<dd>Size of the vocabulary. If not provided, it will be inferred from the decoder subgraph's output shape</dd>
</dl>

#### Inputs (5 - 15)

<dl>
<dt><tt>input_ids</tt> : F</dt>
<dd></dd>
<dt><tt>max_length</tt> : I</dt>
<dd></dd>
<dt><tt>min_length</tt> (optional) : I</dt>
<dd></dd>
<dt><tt>num_beams</tt> : I</dt>
<dd></dd>
<dt><tt>num_return_sequences</tt> : I</dt>
<dd></dd>
<dt><tt>length_penalty</tt> (optional) : T</dt>
<dd></dd>
<dt><tt>repetition_penalty</tt> (optional) : T</dt>
<dd></dd>
<dt><tt>vocab_mask</tt> (optional) : M</dt>
<dd></dd>
<dt><tt>prefix_vocab_mask</tt> (optional) : M</dt>
<dd></dd>
<dt><tt>attention_mask</tt> (optional) : I</dt>
<dd></dd>
<dt><tt>decoder_input_ids</tt> (optional) : I</dt>
<dd></dd>
<dt><tt>logits_processor</tt> (optional) : I</dt>
<dd></dd>
<dt><tt>cross_qk_layer_head</tt> (optional) : I</dt>
<dd></dd>
<dt><tt>extra_decoding_ids</tt> (optional) : I</dt>
<dd></dd>
<dt><tt>temperature</tt> (optional) : T</dt>
<dd></dd>
</dl>

#### Outputs (1 - 5)

<dl>
<dt><tt>sequences</tt> : I</dt>
<dd></dd>
<dt><tt>sequences_scores</tt> (optional) : T</dt>
<dd></dd>
<dt><tt>scores</tt> (optional) : T</dt>
<dd></dd>
<dt><tt>cross_qk</tt> (optional) : V</dt>
<dd></dd>
<dt><tt>non_speech_probs</tt> (optional) : T</dt>
<dd></dd>
</dl>

#### Type Constraints

<dl>
<dt><tt>T</tt> : tensor(float), tensor(float16)</dt>
<dd>Constrain to float tensors.</dd>
<dt><tt>F</tt> : tensor(float), tensor(int32), tensor(float16)</dt>
<dd>Constrain input type to float or int tensors.</dd>
<dt><tt>I</tt> : tensor(int32)</dt>
<dd>Constrain to integer types</dd>
<dt><tt>M</tt> : tensor(int32)</dt>
<dd>Constrain mask to integer types</dd>
<dt><tt>V</tt> : tensor(float)</dt>
<dd>Constrain cross_qk to float32 tensors.</dd>
</dl>


### <a name="com.microsoft.WordConvEmbedding"></a><a name="com.microsoft.wordconvembedding">**com.microsoft.WordConvEmbedding**</a>

#### Version

This version of the operator has been available since version 1 of the 'com.microsoft' operator set.

#### Attributes

<dl>
<dt><tt>char_embedding_size</tt> : int</dt>
<dd>Integer representing the embedding vector size for each char.If not provide, use the char embedding size of embedding vector.</dd>
<dt><tt>conv_window_size</tt> : int</dt>
<dd>This operator applies convolution to word from left to right with window equal to conv_window_size and stride to 1.Take word 'example' for example, with conv_window_size equal to 2, conv is applied to [ex],[xa], [am], [mp]...If not provide, use the first dimension of conv kernel shape.</dd>
<dt><tt>embedding_size</tt> : int</dt>
<dd>Integer representing the embedding vector size for each word.If not provide, use the filter size of conv weight</dd>
</dl>

#### Inputs

<dl>
<dt><tt>Sequence</tt> : T</dt>
<dd></dd>
<dt><tt>W</tt> : T1</dt>
<dd></dd>
<dt><tt>B</tt> : T1</dt>
<dd></dd>
<dt><tt>C</tt> : T1</dt>
<dd></dd>
</dl>

#### Outputs

<dl>
<dt><tt>Y</tt> : T1</dt>
<dd></dd>
</dl>

#### Type Constraints

<dl>
<dt><tt>T</tt> : tensor(int32)</dt>
<dd>Constrain to tensor(int32).</dd>
<dt><tt>T1</tt> : tensor(float)</dt>
<dd>Constrain to tensor(float).</dd>
</dl>


### <sub>experimental</sub> <a name="com.microsoft.IsAllFinite"></a><a name="com.microsoft.isallfinite">**com.microsoft.IsAllFinite**</a>

#### Version

No versioning maintained for experimental ops.
#### Attributes

<dl>
<dt><tt>isinf_only</tt> : int</dt>
<dd>If true, check only for Inf, -Inf.</dd>
<dt><tt>isnan_only</tt> : int</dt>
<dd>If true, check only for NaN.</dd>
</dl>

#### Inputs (1 - &#8734;)

<dl>
<dt><tt>input</tt> (variadic) : V</dt>
<dd></dd>
</dl>

#### Outputs

<dl>
<dt><tt>output</tt> : T</dt>
<dd></dd>
</dl>

#### Type Constraints

<dl>
<dt><tt>V</tt> : tensor(float16), tensor(float), tensor(double), tensor(bfloat16)</dt>
<dd>Constrain input and output types to float tensors.</dd>
<dt><tt>T</tt> : tensor(bool)</dt>
<dd>Constrain the output to a boolean tensor.</dd>
</dl>


### <sub>experimental</sub> <a name="com.microsoft.QEmbedLayerNormalization"></a><a name="com.microsoft.qembedlayernormalization">**com.microsoft.QEmbedLayerNormalization**</a>

#### Version

No versioning maintained for experimental ops.
#### Attributes

<dl>
<dt><tt>epsilon</tt> : float</dt>
<dd>The epsilon value to use to avoid division by zero.</dd>
</dl>

#### Inputs

<dl>
<dt><tt>input_ids</tt> : T1</dt>
<dd></dd>
<dt><tt>segment_ids</tt> (optional) : T1</dt>
<dd></dd>
<dt><tt>word_embedding_quant</tt> : T2</dt>
<dd></dd>
<dt><tt>position_embedding_quant</tt> : T2</dt>
<dd></dd>
<dt><tt>segment_embedding</tt> (optional) : T2</dt>
<dd></dd>
<dt><tt>gamma_quant</tt> : T2</dt>
<dd></dd>
<dt><tt>beta_quant</tt> : T2</dt>
<dd></dd>
<dt><tt>mask</tt> (optional) : T1</dt>
<dd></dd>
<dt><tt>word_embedding_scale</tt> : T</dt>
<dd></dd>
<dt><tt>position_embedding_scale</tt> : T</dt>
<dd></dd>
<dt><tt>segment_embedding_scale</tt> (optional) : T</dt>
<dd></dd>
<dt><tt>gamma_scale</tt> : T</dt>
<dd></dd>
<dt><tt>beta_scale</tt> : T</dt>
<dd></dd>
<dt><tt>word_embedding_zero_point</tt> : T2</dt>
<dd></dd>
<dt><tt>position_embedding_zero_point</tt> : T2</dt>
<dd></dd>
<dt><tt>segment_embedding_zero_point</tt> (optional) : T2</dt>
<dd></dd>
<dt><tt>gamma_zero_point</tt> : T2</dt>
<dd></dd>
<dt><tt>beta_zero_point</tt> : T2</dt>
<dd></dd>
</dl>

#### Outputs

<dl>
<dt><tt>layernorm_out</tt> : T</dt>
<dd></dd>
<dt><tt>mask_index_out</tt> : T1</dt>
<dd></dd>
</dl>

#### Type Constraints

<dl>
<dt><tt>T1</tt> : tensor(int32)</dt>
<dd>Constrain mask index to integer types</dd>
<dt><tt>T2</tt> : tensor(int8), tensor(uint8)</dt>
<dd>Constrain input and output types to int8 tensors.</dd>
<dt><tt>T</tt> : tensor(float)</dt>
<dd>Constrain input and output types to float32 tensors.</dd>
</dl>


## com.microsoft.nchwc
### <a name="com.microsoft.nchwc.AveragePool"></a><a name="com.microsoft.nchwc.averagepool">**com.microsoft.nchwc.AveragePool**</a>

#### Version

This version of the operator has been available since version 1 of the 'com.microsoft.nchwc' operator set.

#### Attributes

<dl>
<dt><tt>auto_pad</tt> : string</dt>
<dd></dd>
<dt><tt>ceil_mode</tt> : int</dt>
<dd></dd>
<dt><tt>count_include_pad</tt> : int</dt>
<dd></dd>
<dt><tt>dilations</tt> : list of ints</dt>
<dd></dd>
<dt><tt>kernel_shape</tt> : list of ints (required)</dt>
<dd></dd>
<dt><tt>pads</tt> : list of ints</dt>
<dd></dd>
<dt><tt>strides</tt> : list of ints</dt>
<dd></dd>
</dl>

#### Inputs

<dl>
<dt><tt>X</tt> : T</dt>
<dd></dd>
</dl>

#### Outputs

<dl>
<dt><tt>Y</tt> : T</dt>
<dd></dd>
</dl>

#### Type Constraints

<dl>
<dt><tt>T</tt> : tensor(float)</dt>
<dd>Constrain input and output types to float tensors</dd>
</dl>


### <a name="com.microsoft.nchwc.Conv"></a><a name="com.microsoft.nchwc.conv">**com.microsoft.nchwc.Conv**</a>

#### Version

This version of the operator has been available since version 1 of the 'com.microsoft.nchwc' operator set.

#### Attributes

<dl>
<dt><tt>activation</tt> : string</dt>
<dd></dd>
<dt><tt>activation_params</tt> : list of floats</dt>
<dd></dd>
<dt><tt>auto_pad</tt> : string</dt>
<dd></dd>
<dt><tt>dilations</tt> : list of ints</dt>
<dd></dd>
<dt><tt>group</tt> : int</dt>
<dd></dd>
<dt><tt>kernel_shape</tt> : list of ints</dt>
<dd></dd>
<dt><tt>pads</tt> : list of ints</dt>
<dd></dd>
<dt><tt>strides</tt> : list of ints</dt>
<dd></dd>
</dl>

#### Inputs (2 - 4)

<dl>
<dt><tt>X</tt> : T</dt>
<dd></dd>
<dt><tt>W</tt> : T</dt>
<dd></dd>
<dt><tt>B</tt> (optional) : T</dt>
<dd></dd>
<dt><tt>Sum</tt> (optional) : T</dt>
<dd></dd>
</dl>

#### Outputs

<dl>
<dt><tt>Y</tt> : T</dt>
<dd></dd>
</dl>

#### Type Constraints

<dl>
<dt><tt>T</tt> : tensor(float)</dt>
<dd>Constrain input and output types to float tensors</dd>
</dl>


### <a name="com.microsoft.nchwc.GlobalAveragePool"></a><a name="com.microsoft.nchwc.globalaveragepool">**com.microsoft.nchwc.GlobalAveragePool**</a>

#### Version

This version of the operator has been available since version 1 of the 'com.microsoft.nchwc' operator set.

#### Inputs

<dl>
<dt><tt>X</tt> : T</dt>
<dd></dd>
</dl>

#### Outputs

<dl>
<dt><tt>Y</tt> : T</dt>
<dd></dd>
</dl>

#### Type Constraints

<dl>
<dt><tt>T</tt> : tensor(float)</dt>
<dd>Constrain input and output types to float tensors</dd>
</dl>


### <a name="com.microsoft.nchwc.GlobalMaxPool"></a><a name="com.microsoft.nchwc.globalmaxpool">**com.microsoft.nchwc.GlobalMaxPool**</a>

#### Version

This version of the operator has been available since version 1 of the 'com.microsoft.nchwc' operator set.

#### Inputs

<dl>
<dt><tt>X</tt> : T</dt>
<dd></dd>
</dl>

#### Outputs

<dl>
<dt><tt>Y</tt> : T</dt>
<dd></dd>
</dl>

#### Type Constraints

<dl>
<dt><tt>T</tt> : tensor(float)</dt>
<dd>Constrain input and output types to float tensors</dd>
</dl>


### <a name="com.microsoft.nchwc.MaxPool"></a><a name="com.microsoft.nchwc.maxpool">**com.microsoft.nchwc.MaxPool**</a>

#### Version

This version of the operator has been available since version 1 of the 'com.microsoft.nchwc' operator set.

#### Attributes

<dl>
<dt><tt>auto_pad</tt> : string</dt>
<dd></dd>
<dt><tt>ceil_mode</tt> : int</dt>
<dd></dd>
<dt><tt>dilations</tt> : list of ints</dt>
<dd></dd>
<dt><tt>kernel_shape</tt> : list of ints (required)</dt>
<dd></dd>
<dt><tt>pads</tt> : list of ints</dt>
<dd></dd>
<dt><tt>storage_order</tt> : int</dt>
<dd></dd>
<dt><tt>strides</tt> : list of ints</dt>
<dd></dd>
</dl>

#### Inputs

<dl>
<dt><tt>X</tt> : T</dt>
<dd></dd>
</dl>

#### Outputs

<dl>
<dt><tt>Y</tt> : T</dt>
<dd></dd>
</dl>

#### Type Constraints

<dl>
<dt><tt>T</tt> : tensor(float)</dt>
<dd>Constrain input and output types to float tensors</dd>
</dl>


### <a name="com.microsoft.nchwc.ReorderInput"></a><a name="com.microsoft.nchwc.reorderinput">**com.microsoft.nchwc.ReorderInput**</a>

#### Version

This version of the operator has been available since version 1 of the 'com.microsoft.nchwc' operator set.

#### Attributes

<dl>
<dt><tt>channels_last</tt> : int</dt>
<dd></dd>
</dl>

#### Inputs

<dl>
<dt><tt>X</tt> : T</dt>
<dd></dd>
</dl>

#### Outputs

<dl>
<dt><tt>Y</tt> : T</dt>
<dd></dd>
</dl>

#### Type Constraints

<dl>
<dt><tt>T</tt> : tensor(float)</dt>
<dd>Constrain input and output types to float tensors</dd>
</dl>


### <a name="com.microsoft.nchwc.ReorderOutput"></a><a name="com.microsoft.nchwc.reorderoutput">**com.microsoft.nchwc.ReorderOutput**</a>

#### Version

This version of the operator has been available since version 1 of the 'com.microsoft.nchwc' operator set.

#### Attributes

<dl>
<dt><tt>channels</tt> : int</dt>
<dd></dd>
<dt><tt>channels_last</tt> : int</dt>
<dd></dd>
</dl>

#### Inputs

<dl>
<dt><tt>X</tt> : T</dt>
<dd></dd>
</dl>

#### Outputs

<dl>
<dt><tt>Y</tt> : T</dt>
<dd></dd>
</dl>

#### Type Constraints

<dl>
<dt><tt>T</tt> : tensor(float)</dt>
<dd>Constrain input and output types to float tensors</dd>
</dl>


### <a name="com.microsoft.nchwc.Upsample"></a><a name="com.microsoft.nchwc.upsample">**com.microsoft.nchwc.Upsample**</a>

#### Version

This version of the operator has been available since version 1 of the 'com.microsoft.nchwc' operator set.

#### Attributes

<dl>
<dt><tt>coordinate_transformation_mode</tt> : string</dt>
<dd></dd>
<dt><tt>mode</tt> : string</dt>
<dd></dd>
<dt><tt>scales</tt> : list of ints</dt>
<dd></dd>
</dl>

#### Inputs

<dl>
<dt><tt>X</tt> : T</dt>
<dd></dd>
</dl>

#### Outputs

<dl>
<dt><tt>Y</tt> : T</dt>
<dd></dd>
</dl>

#### Type Constraints

<dl>
<dt><tt>T</tt> : tensor(float)</dt>
<dd>Constrain input and output types to float tensors</dd>
</dl>


## com.ms.internal.nhwc
### <a name="com.ms.internal.nhwc.BatchNormalization"></a><a name="com.ms.internal.nhwc.batchnormalization">**com.ms.internal.nhwc.BatchNormalization**</a>

#### Version

This version of the operator has been available since version 15 of the 'com.ms.internal.nhwc' operator set.

Other versions of this operator: com.ms.internal.nhwc.BatchNormalization-7, com.ms.internal.nhwc.BatchNormalization-9, com.ms.internal.nhwc.BatchNormalization-14

#### Attributes

<dl>
<dt><tt>activation</tt> : string</dt>
<dd></dd>
<dt><tt>activation_params</tt> : list of floats</dt>
<dd></dd>
<dt><tt>epsilon</tt> : float</dt>
<dd>The epsilon value to use to avoid division by zero.</dd>
<dt><tt>momentum</tt> : float</dt>
<dd>Factor used in computing the running mean and variance.e.g., running_mean = running_mean * momentum + mean * (1 - momentum).</dd>
<dt><tt>training_mode</tt> : int</dt>
<dd>If set to true, it indicates BatchNormalization is being used for training, and outputs 1 and 2 are to be computed.</dd>
</dl>

#### Inputs

<dl>
<dt><tt>X</tt> : T</dt>
<dd></dd>
<dt><tt>scale</tt> : T1</dt>
<dd></dd>
<dt><tt>B</tt> : T1</dt>
<dd></dd>
<dt><tt>input_mean</tt> : T2</dt>
<dd></dd>
<dt><tt>input_var</tt> : T2</dt>
<dd></dd>
</dl>

#### Outputs (1 - 3)

<dl>
<dt><tt>Y</tt> : T</dt>
<dd></dd>
<dt><tt>running_mean</tt> (optional) : T2</dt>
<dd></dd>
<dt><tt>running_var</tt> (optional) : T2</dt>
<dd></dd>
</dl>

#### Type Constraints

<dl>
<dt><tt>T</tt> : tensor(float16), tensor(float), tensor(double), tensor(bfloat16)</dt>
<dd>Constrain input and output types to float tensors.</dd>
<dt><tt>T1</tt> : tensor(float16), tensor(float), tensor(double), tensor(bfloat16)</dt>
<dd>Constrain scale and bias types to float tensors.</dd>
<dt><tt>T2</tt> : tensor(float16), tensor(float), tensor(double), tensor(bfloat16)</dt>
<dd>Constrain mean and variance types to float tensors.</dd>
</dl>


### <a name="com.ms.internal.nhwc.ConvTranspose"></a><a name="com.ms.internal.nhwc.convtranspose">**com.ms.internal.nhwc.ConvTranspose**</a>

#### Version

This version of the operator has been available since version 11 of the 'com.ms.internal.nhwc' operator set.

Other versions of this operator: com.ms.internal.nhwc.ConvTranspose-1

#### Attributes

<dl>
<dt><tt>activation</tt> : string</dt>
<dd></dd>
<dt><tt>activation_params</tt> : list of floats</dt>
<dd></dd>
<dt><tt>auto_pad</tt> : string</dt>
<dd>auto_pad must be either NOTSET, SAME_UPPER, SAME_LOWER or VALID. Where default value is NOTSET, which means explicit padding is used. SAME_UPPER or SAME_LOWER mean pad the input so that `output_shape[i] = input_shape[i] * strides[i]` for each axis `i`. The padding is split between the two sides equally or almost equally (depending on whether it is even or odd). In case the padding is an odd number, the extra padding is added at the end for SAME_UPPER and at the beginning for SAME_LOWER.</dd>
<dt><tt>dilations</tt> : list of ints</dt>
<dd>dilation value along each spatial axis of the filter. If not present, the dilation defaults to 1 along each spatial axis.</dd>
<dt><tt>group</tt> : int</dt>
<dd>number of groups input channels and output channels are divided into.</dd>
<dt><tt>kernel_shape</tt> : list of ints</dt>
<dd>The shape of the convolution kernel. If not present, should be inferred from input W.</dd>
<dt><tt>output_padding</tt> : list of ints</dt>
<dd>Additional elements added to the side with higher coordinate indices in the output. Each padding value in "output_padding" must be less than the corresponding stride/dilation dimension. By default, this attribute is a zero vector. Note that this attribute doesn't directly affect the computed output values. It only controls the selection of the computed values, so changing this attribute only adds or removes output elements. If "output_shape" is explicitly provided, "output_padding" does not contribute additional size to "output_shape" but participates in the computation of the needed padding amount. This is also called adjs or adjustment in some frameworks.</dd>
<dt><tt>output_shape</tt> : list of ints</dt>
<dd>The shape of the output can be explicitly set which will cause pads values to be auto generated. If output_shape is specified pads values are ignored. See doc for details for equations to generate pads. Note that the output_shape attribute value should not include dimensions for batch size and channels, which are automatically inferred.</dd>
<dt><tt>pads</tt> : list of ints</dt>
<dd>Padding for the beginning and ending along each spatial axis, it can take any value greater than or equal to 0. The value represent the number of pixels added to the beginning and end part of the corresponding axis. `pads` format should be as follow [x1_begin, x2_begin...x1_end, x2_end,...], where xi_begin the number of pixels added at the beginning of axis `i` and xi_end, the number of pixels added at the end of axis `i`. This attribute cannot be used simultaneously with auto_pad attribute. If not present, the padding defaults to 0 along start and end of each spatial axis.</dd>
<dt><tt>strides</tt> : list of ints</dt>
<dd>Stride along each spatial axis. If not present, the stride defaults to 1 along each spatial axis.</dd>
</dl>

#### Inputs (2 - 3)

<dl>
<dt><tt>X</tt> : T</dt>
<dd></dd>
<dt><tt>W</tt> : T</dt>
<dd></dd>
<dt><tt>B</tt> (optional) : T</dt>
<dd></dd>
</dl>

#### Outputs

<dl>
<dt><tt>Y</tt> : T</dt>
<dd></dd>
</dl>

#### Type Constraints

<dl>
<dt><tt>T</tt> : tensor(float16), tensor(float), tensor(double)</dt>
<dd>Constrain input and output types to float tensors.</dd>
</dl>


### <a name="com.ms.internal.nhwc.DepthToSpace"></a><a name="com.ms.internal.nhwc.depthtospace">**com.ms.internal.nhwc.DepthToSpace**</a>

#### Version

This version of the operator has been available since version 13 of the 'com.ms.internal.nhwc' operator set.

Other versions of this operator: com.ms.internal.nhwc.DepthToSpace-1, com.ms.internal.nhwc.DepthToSpace-11

#### Attributes

<dl>
<dt><tt>blocksize</tt> : int (required)</dt>
<dd>Blocks of [blocksize, blocksize] are moved.</dd>
<dt><tt>mode</tt> : string</dt>
<dd>DCR (default) for depth-column-row order re-arrangement. Use CRD for column-row-depth order.</dd>
</dl>

#### Inputs

<dl>
<dt><tt>input</tt> : T</dt>
<dd></dd>
</dl>

#### Outputs

<dl>
<dt><tt>output</tt> : T</dt>
<dd></dd>
</dl>

#### Type Constraints

<dl>
<dt><tt>T</tt> : tensor(uint8), tensor(uint16), tensor(uint32), tensor(uint64), tensor(int8), tensor(int16), tensor(int32), tensor(int64), tensor(bfloat16), tensor(float16), tensor(float), tensor(double), tensor(string), tensor(bool), tensor(complex64), tensor(complex128)</dt>
<dd>Constrain input and output types to all tensor types.</dd>
</dl>


### <a name="com.ms.internal.nhwc.GlobalLpPool"></a><a name="com.ms.internal.nhwc.globallppool">**com.ms.internal.nhwc.GlobalLpPool**</a>

#### Version

This version of the operator has been available since version 2 of the 'com.ms.internal.nhwc' operator set.

#### Attributes

<dl>
<dt><tt>p</tt> : int</dt>
<dd>p value of the Lp norm used to pool over the input data.</dd>
</dl>

#### Inputs

<dl>
<dt><tt>X</tt> : T</dt>
<dd></dd>
</dl>

#### Outputs

<dl>
<dt><tt>Y</tt> : T</dt>
<dd></dd>
</dl>

#### Type Constraints

<dl>
<dt><tt>T</tt> : tensor(bfloat16), tensor(float16), tensor(float), tensor(double)</dt>
<dd>Constrain input and output types to float tensors.</dd>
</dl>


### <a name="com.ms.internal.nhwc.InstanceNormalization"></a><a name="com.ms.internal.nhwc.instancenormalization">**com.ms.internal.nhwc.InstanceNormalization**</a>

#### Version

This version of the operator has been available since version 6 of the 'com.ms.internal.nhwc' operator set.

#### Attributes

<dl>
<dt><tt>activation</tt> : string</dt>
<dd></dd>
<dt><tt>activation_params</tt> : list of floats</dt>
<dd></dd>
<dt><tt>epsilon</tt> : float</dt>
<dd>The epsilon value to use to avoid division by zero.</dd>
</dl>

#### Inputs

<dl>
<dt><tt>input</tt> : T</dt>
<dd></dd>
<dt><tt>scale</tt> : T</dt>
<dd></dd>
<dt><tt>B</tt> : T</dt>
<dd></dd>
</dl>

#### Outputs

<dl>
<dt><tt>output</tt> : T</dt>
<dd></dd>
</dl>

#### Type Constraints

<dl>
<dt><tt>T</tt> : tensor(float16), tensor(float), tensor(double)</dt>
<dd>Constrain input and output types to float tensors.</dd>
</dl>


### <a name="com.ms.internal.nhwc.LRN"></a><a name="com.ms.internal.nhwc.lrn">**com.ms.internal.nhwc.LRN**</a>

#### Version

This version of the operator has been available since version 13 of the 'com.ms.internal.nhwc' operator set.

Other versions of this operator: com.ms.internal.nhwc.LRN-1

#### Attributes

<dl>
<dt><tt>alpha</tt> : float</dt>
<dd>Scaling parameter.</dd>
<dt><tt>beta</tt> : float</dt>
<dd>The exponent.</dd>
<dt><tt>bias</tt> : float</dt>
<dd></dd>
<dt><tt>size</tt> : int (required)</dt>
<dd>The number of channels to sum over</dd>
</dl>

#### Inputs

<dl>
<dt><tt>X</tt> : T</dt>
<dd></dd>
</dl>

#### Outputs

<dl>
<dt><tt>Y</tt> : T</dt>
<dd></dd>
</dl>

#### Type Constraints

<dl>
<dt><tt>T</tt> : tensor(float16), tensor(float), tensor(double), tensor(bfloat16)</dt>
<dd>Constrain input and output  types to float tensors.</dd>
</dl>


### <a name="com.ms.internal.nhwc.LpPool"></a><a name="com.ms.internal.nhwc.lppool">**com.ms.internal.nhwc.LpPool**</a>

#### Version

This version of the operator has been available since version 18 of the 'com.ms.internal.nhwc' operator set.

Other versions of this operator: com.ms.internal.nhwc.LpPool-11

#### Attributes

<dl>
<dt><tt>auto_pad</tt> : string</dt>
<dd>auto_pad must be either NOTSET, SAME_UPPER, SAME_LOWER or VALID. Where default value is NOTSET, which means explicit padding is used. SAME_UPPER or SAME_LOWER mean pad the input so that `output_shape[i] = ceil(input_shape[i] / strides[i])` for each axis `i`. The padding is split between the two sides equally or almost equally (depending on whether it is even or odd). In case the padding is an odd number, the extra padding is added at the end for SAME_UPPER and at the beginning for SAME_LOWER.</dd>
<dt><tt>ceil_mode</tt> : int</dt>
<dd>Whether to use ceil or floor (default) to compute the output shape.</dd>
<dt><tt>dilations</tt> : list of ints</dt>
<dd>dilation value along each spatial axis of the filter. If not present, the dilation defaults is 1 along each spatial axis.</dd>
<dt><tt>kernel_shape</tt> : list of ints (required)</dt>
<dd>The size of the kernel along each axis.</dd>
<dt><tt>p</tt> : int</dt>
<dd>p value of the Lp norm used to pool over the input data.</dd>
<dt><tt>pads</tt> : list of ints</dt>
<dd>Padding for the beginning and ending along each spatial axis, it can take any value greater than or equal to 0. The value represent the number of pixels added to the beginning and end part of the corresponding axis. `pads` format should be as follow [x1_begin, x2_begin...x1_end, x2_end,...], where xi_begin the number of pixels added at the beginning of axis `i` and xi_end, the number of pixels added at the end of axis `i`. This attribute cannot be used simultaneously with auto_pad attribute. If not present, the padding defaults to 0 along start and end of each spatial axis.</dd>
<dt><tt>strides</tt> : list of ints</dt>
<dd>Stride along each spatial axis. If not present, the stride defaults to 1 along each spatial axis.</dd>
</dl>

#### Inputs

<dl>
<dt><tt>X</tt> : T</dt>
<dd></dd>
</dl>

#### Outputs

<dl>
<dt><tt>Y</tt> : T</dt>
<dd></dd>
</dl>

#### Type Constraints

<dl>
<dt><tt>T</tt> : tensor(float16), tensor(float), tensor(double)</dt>
<dd>Constrain input and output types to float tensors.</dd>
</dl>


### <a name="com.ms.internal.nhwc.MaxUnpool"></a><a name="com.ms.internal.nhwc.maxunpool">**com.ms.internal.nhwc.MaxUnpool**</a>

#### Version

This version of the operator has been available since version 11 of the 'com.ms.internal.nhwc' operator set.

Other versions of this operator: com.ms.internal.nhwc.MaxUnpool-9

#### Attributes

<dl>
<dt><tt>activation</tt> : string</dt>
<dd></dd>
<dt><tt>activation_params</tt> : list of floats</dt>
<dd></dd>
<dt><tt>kernel_shape</tt> : list of ints (required)</dt>
<dd>The size of the kernel along each axis.</dd>
<dt><tt>pads</tt> : list of ints</dt>
<dd>Padding for the beginning and ending along each spatial axis, it can take any value greater than or equal to 0. The value represent the number of pixels added to the beginning and end part of the corresponding axis. `pads` format should be as follow [x1_begin, x2_begin...x1_end, x2_end,...], where xi_begin the number of pixels added at the beginning of axis `i` and xi_end, the number of pixels added at the end of axis `i`. This attribute cannot be used simultaneously with auto_pad attribute. If not present, the padding defaults to 0 along start and end of each spatial axis.</dd>
<dt><tt>strides</tt> : list of ints</dt>
<dd>Stride along each spatial axis. If not present, the stride defaults to 1 along each spatial axis.</dd>
</dl>

#### Inputs (2 - 3)

<dl>
<dt><tt>X</tt> : T1</dt>
<dd></dd>
<dt><tt>I</tt> : T2</dt>
<dd></dd>
<dt><tt>output_shape</tt> (optional) : T2</dt>
<dd></dd>
</dl>

#### Outputs

<dl>
<dt><tt>output</tt> : T1</dt>
<dd></dd>
</dl>

#### Type Constraints

<dl>
<dt><tt>T1</tt> : tensor(float16), tensor(float), tensor(double)</dt>
<dd>Constrain input and output types to float tensors.</dd>
<dt><tt>T2</tt> : tensor(int64)</dt>
<dd>Constrain index tensor to int64</dd>
</dl>


### <a name="com.ms.internal.nhwc.QLinearConvTranspose"></a><a name="com.ms.internal.nhwc.qlinearconvtranspose">**com.ms.internal.nhwc.QLinearConvTranspose**</a>

#### Version

This version of the operator has been available since version 1 of the 'com.ms.internal.nhwc' operator set.

#### Attributes

<dl>
<dt><tt>auto_pad</tt> : string</dt>
<dd>auto_pad must be either NOTSET, SAME_UPPER, SAME_LOWER or VALID. Where default value is NOTSET</dd>
<dt><tt>dilations</tt> : list of ints</dt>
<dd>dilation value along each spatial axis of the filter. If not present, the dilation defaults to 1 along each spatial axis.</dd>
<dt><tt>group</tt> : int</dt>
<dd>number of groups input channels and output channels are divided into.</dd>
<dt><tt>kernel_shape</tt> : list of ints</dt>
<dd>The shape of the convolution kernel. If not present, should be inferred from input W.</dd>
<dt><tt>output_padding</tt> : list of ints</dt>
<dd>Additional elements added to the side with higher coordinate indices in the output. Each padding value in "output_padding" must be less than the corresponding stride/dilation dimension. By default, this attribute is a zero vector. Note that this attribute doesn't directly affect the computed output values. It only controls the selection of the computed values, so changing this attribute only adds or removes output elements. If "output_shape" is explicitly provided, "output_padding" does not contribute additional size to "output_shape" but participates in the computation of the needed padding amount. This is also called adjs or adjustment in some frameworks.</dd>
<dt><tt>output_shape</tt> : list of ints</dt>
<dd>The shape of the output can be explicitly set which will cause pads values to be auto generated. If output_shape is specified pads values are ignored. See doc for details for equations to generate pads</dd>
<dt><tt>pads</tt> : list of ints</dt>
<dd>Padding for the beginning and ending along each spatial axis</dd>
<dt><tt>strides</tt> : list of ints</dt>
<dd>Stride along each spatial axis. If not present, the stride defaults to 1 along each spatial axis.</dd>
</dl>

#### Inputs (8 - 9)

<dl>
<dt><tt>x</tt> : T1</dt>
<dd></dd>
<dt><tt>x_scale</tt> : tensor(float)</dt>
<dd></dd>
<dt><tt>x_zero_point</tt> : T1</dt>
<dd></dd>
<dt><tt>w</tt> : T2</dt>
<dd></dd>
<dt><tt>w_scale</tt> : tensor(float)</dt>
<dd></dd>
<dt><tt>w_zero_point</tt> : T2</dt>
<dd></dd>
<dt><tt>y_scale</tt> : tensor(float)</dt>
<dd></dd>
<dt><tt>y_zero_point</tt> : T3</dt>
<dd></dd>
<dt><tt>B</tt> (optional) : T4</dt>
<dd></dd>
</dl>

#### Outputs

<dl>
<dt><tt>y</tt> : T3</dt>
<dd></dd>
</dl>

#### Type Constraints

<dl>
<dt><tt>T1</tt> : tensor(int8), tensor(uint8)</dt>
<dd>Constrain input type to 8-bit integer tensor.</dd>
<dt><tt>T2</tt> : tensor(int8), tensor(uint8)</dt>
<dd>Constrain filter type to 8-bit integer tensor.</dd>
<dt><tt>T3</tt> : tensor(int8), tensor(uint8)</dt>
<dd>Constrain output type to 8-bit integer tensor.</dd>
<dt><tt>T4</tt> : tensor(int32)</dt>
<dd>Constrain bias type to 32-bit integer tensor.</dd>
</dl>


### <a name="com.ms.internal.nhwc.Resize"></a><a name="com.ms.internal.nhwc.resize">**com.ms.internal.nhwc.Resize**</a>

#### Version

This version of the operator has been available since version 19 of the 'com.ms.internal.nhwc' operator set.

Other versions of this operator: com.ms.internal.nhwc.Resize-11, com.ms.internal.nhwc.Resize-13, com.ms.internal.nhwc.Resize-18

#### Attributes

<dl>
<dt><tt>antialias</tt> : int</dt>
<dd>If set to 1, "linear" and "cubic" interpolation modes will use an antialiasing filter when downscaling. Antialiasing is achieved by stretching the resampling filter by a factor max(1, 1 / scale), which means that when downsampling, more input pixels contribute to an output pixel.</dd>
<dt><tt>axes</tt> : list of ints</dt>
<dd>If provided, it specifies a subset of axes that 'roi', 'scales' and 'sizes' refer to. If not provided, all axes are assumed [0, 1, ..., r-1], where r = rank(data). Non-specified dimensions are interpreted as non-resizable. Negative value means counting dimensions from the back. Accepted range is [-r, r-1], where r = rank(data). Behavior is undefined if an axis is repeated.</dd>
<dt><tt>coordinate_transformation_mode</tt> : string</dt>
<dd>
This attribute describes how to transform the coordinate in the resized tensor to the coordinate in the original tensor.

The coordinate of each dimension is transformed individually. Let's describe a case using axis x as an example.
Denote `x_resized` as the coordinate of axis x in the resized tensor,
 `x_original` as the coordinate of axis x in the original tensor,
 `length_original` as the length of the original tensor in axis x,
 `length_resized` as the length of the resized tensor in axis x,
 `scale = length_resized / length_original`,
 `output_width` the target length on the axis x which can be a fractional number when it is calculated out of a scale factor,
 and `output_width_int` the effective output width as an integer.

if coordinate_transformation_mode is `"half_pixel"`,
```
x_original = (x_resized + 0.5) / scale - 0.5
```

if coordinate_transformation_mode is `"half_pixel_symmetric"`,
```
adjustment = output_width_int / output_width
center = input_width / 2
offset = center * (1 - adjustment)
x_ori = offset + (x + 0.5) / scale - 0.5
```

if coordinate_transformation_mode is `"pytorch_half_pixel"`,
```
x_original = length_resized > 1 ? (x_resized + 0.5) / scale - 0.5 : 0
```

if coordinate_transformation_mode is `"align_corners"`,
```
x_original = x_resized * (length_original - 1) / (length_resized - 1)
```

if coordinate_transformation_mode is `"asymmetric"`,
```
x_original = x_resized / scale
```

if coordinate_transformation_mode is `"tf_crop_and_resize"`,
```
x_original = length_resized > 1 ? start_x * (length_original - 1) + x_resized * (end_x - start_x) * (length_original - 1) / (length_resized - 1) : 0.5 * (start_x + end_x) * (length_original - 1)
```
.</dd>
<dt><tt>cubic_coeff_a</tt> : float</dt>
<dd>The coefficient 'a' used in cubic interpolation. Two common choice are -0.5 (in some cases of TensorFlow) and -0.75 (in PyTorch). Check out Equation (4) in https://ieeexplore.ieee.org/document/1163711 for the details. This attribute is valid only if mode is "cubic".</dd>
<dt><tt>exclude_outside</tt> : int</dt>
<dd>If set to 1, the weight of sampling locations outside the tensor will be set to 0 and the weight will be renormalized so that their sum is 1.0. The default value is 0.</dd>
<dt><tt>extrapolation_value</tt> : float</dt>
<dd>When coordinate_transformation_mode is "tf_crop_and_resize" and x_original is outside the range [0, length_original - 1], this value is used as the corresponding output value. Default is 0.0f.</dd>
<dt><tt>keep_aspect_ratio_policy</tt> : string</dt>
<dd>
This attribute describes how to interpret the `sizes` input with regard to keeping the original aspect ratio of the input, and it is not applicable when
the `scales` input is used.

Given a set of `sizes`, associated with a subset of `axes` (explicitly provided or default), and assuming `d = axes[i]`, with `i` being the index of the provided `sizes`.

If `keep_aspect_ratio_policy` is `"stretch"`, the original aspect ratio is disregarded, and the input is resized to the specified size:
`out_size[d] = sizes[i]`

If `keep_aspect_ratio_policy` is `"not_larger"`, the sizes are adjusted so that no extent of the output is larger than the specified size, while keeping the original aspect ratio:
```
scale = Min(sizes[i] / in_size[d])
out_size[d] = round_int(scale * in_size[i])
```

If `keep_aspect_ratio_policy` is `"not_smaller"`, the sizes are adjusted so that no extent of the output is smaller than the specified size, while keeping the original aspect ratio:
```
scale = Max(sizes[i] / in_size[d])
out_size[d] = round_int(scale * in_size[i])
```

For non-resizable axes (those not specified in `axes`), the output size will be equal to the input size.

Note: `round_int` stands for computing the nearest integer value, rounding halfway cases up.</dd>
<dt><tt>mode</tt> : string</dt>
<dd>Three interpolation modes: "nearest" (default), "linear" and "cubic". The "linear" mode includes linear interpolation for 1D tensor and N-linear interpolation for N-D tensor (for example, bilinear interpolation for 2D tensor). The "cubic" mode includes cubic interpolation for 1D tensor and N-cubic interpolation for N-D tensor (for example, bicubic interpolation for 2D tensor).</dd>
<dt><tt>nearest_mode</tt> : string</dt>
<dd>Four modes: "round_prefer_floor" (default, as known as round half down), "round_prefer_ceil" (as known as round half up), "floor", "ceil". Only used by nearest interpolation. It indicates how to get "nearest" pixel in input tensor from x_original, so this attribute is valid only if "mode" is "nearest".</dd>
</dl>

#### Inputs (1 - 4)

<dl>
<dt><tt>X</tt> : T1</dt>
<dd></dd>
<dt><tt>roi</tt> (optional) : T2</dt>
<dd></dd>
<dt><tt>scales</tt> (optional) : tensor(float)</dt>
<dd></dd>
<dt><tt>sizes</tt> (optional) : tensor(int64)</dt>
<dd></dd>
</dl>

#### Outputs

<dl>
<dt><tt>Y</tt> : T1</dt>
<dd></dd>
</dl>

#### Type Constraints

<dl>
<dt><tt>T1</tt> : tensor(uint8), tensor(uint16), tensor(uint32), tensor(uint64), tensor(int8), tensor(int16), tensor(int32), tensor(int64), tensor(bfloat16), tensor(float16), tensor(float), tensor(double), tensor(string), tensor(bool), tensor(complex64), tensor(complex128)</dt>
<dd>Constrain input 'X' and output 'Y' to all tensor types.</dd>
<dt><tt>T2</tt> : tensor(float16), tensor(float), tensor(double)</dt>
<dd>Constrain roi type to float or double.</dd>
</dl>


### <a name="com.ms.internal.nhwc.SpaceToDepth"></a><a name="com.ms.internal.nhwc.spacetodepth">**com.ms.internal.nhwc.SpaceToDepth**</a>

#### Version

This version of the operator has been available since version 13 of the 'com.ms.internal.nhwc' operator set.

Other versions of this operator: com.ms.internal.nhwc.SpaceToDepth-1

#### Attributes

<dl>
<dt><tt>blocksize</tt> : int (required)</dt>
<dd>Blocks of [blocksize, blocksize] are moved.</dd>
</dl>

#### Inputs

<dl>
<dt><tt>input</tt> : T</dt>
<dd></dd>
</dl>

#### Outputs

<dl>
<dt><tt>output</tt> : T</dt>
<dd></dd>
</dl>

#### Type Constraints

<dl>
<dt><tt>T</tt> : tensor(uint8), tensor(uint16), tensor(uint32), tensor(uint64), tensor(int8), tensor(int16), tensor(int32), tensor(int64), tensor(bfloat16), tensor(float16), tensor(float), tensor(double), tensor(string), tensor(bool), tensor(complex64), tensor(complex128)</dt>
<dd>Constrain input and output types to all tensor types.</dd>
</dl>


